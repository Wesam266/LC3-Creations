{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Information\n",
    "###############################################################################\n",
    "# Created by Linwood Creekmore \n",
    "\n",
    "# https://github.com/linwoodc3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "#shameless copy paste from json/decoder.py\n",
    "FLAGS = re.VERBOSE | re.MULTILINE | re.DOTALL\n",
    "WHITESPACE = re.compile(r'[ \\t\\n\\r]*', FLAGS)\n",
    "\n",
    "class ConcatJSONDecoder(json.JSONDecoder):\n",
    "    def decode(self, s, _w=WHITESPACE.match):\n",
    "        s_len = len(s)\n",
    "\n",
    "        objs = []\n",
    "        end = 0\n",
    "        while end != s_len:\n",
    "            obj, end = self.raw_decode(s, idx=_w(s, end).end())\n",
    "            end = _w(s, end).end()\n",
    "            objs.append(obj)\n",
    "        return objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#**********************************************************************\n",
    "# Keys for API and application keys....DO NOT add this file to git\n",
    "#**********************************************************************\n",
    "\n",
    "# I created a nested dictionary with my API keys, then wrote that json to disk.  Now, I load the json and just pass the keys into the application\n",
    "import json\n",
    "TwitterOauth = json.load(open('/Users/linwood/projects/LC3-Creations/notebooks/twittertest/twitterapikeys.txt'), cls=ConcatJSONDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#**********************************************************************\n",
    "# Code to use Twitter API stream to pull data\n",
    "#**********************************************************************\n",
    "\n",
    "# Import the necessary package to process data in JSON format\n",
    "try:\n",
    "    import json\n",
    "except ImportError:\n",
    "    import simplejson as json\n",
    "\n",
    "# Import the necessary methods from \"twitter\" library\n",
    "from twitter import Twitter, OAuth, TwitterHTTPError, TwitterStream\n",
    "\n",
    "# Variables that contains the user credentials to access Twitter API \n",
    "ACCESS_TOKEN = str(TwitterOauth[0]['accesstoken'])\n",
    "ACCESS_SECRET = str(TwitterOauth[0]['accesssecret'])\n",
    "CONSUMER_KEY = str(TwitterOauth[0]['consumerkey'])\n",
    "CONSUMER_SECRET = str(TwitterOauth[0]['consumersecret'])\n",
    "\n",
    "oauth = OAuth(ACCESS_TOKEN, ACCESS_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "# Initiate the connection to Twitter Streaming API\n",
    "twitter_stream = TwitterStream(auth=oauth)\n",
    "\n",
    "# Get a sample of the public data following through Twitter\n",
    "iterator = twitter_stream.statuses.filter(locations = '-76.871724,38.902399, -76.859321,38.911399')\n",
    "\n",
    "# Print each tweet in the stream to the screen \n",
    "# Here we set it to stop after getting 1000 tweets. \n",
    "# You don't have to set it to stop, but can continue running \n",
    "# the Twitter API to collect data for days or even longer. \n",
    "\n",
    "with open('data.txt', 'w+') as outfile:\n",
    "    for tweet in iterator:\n",
    "        \n",
    "        # Twitter Python Tool wraps the data returned by Twitter \n",
    "        # as a TwitterDictResponse object.\n",
    "        # We convert it back to the JSON format to print/score\n",
    "        #print json.dumps(tweet)  \n",
    "\n",
    "        # The command below will do pretty printing for JSON data, try it out\n",
    "        # print json.dumps(tweet, indent=4)\n",
    "        print tweet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viks_vs_hawks = json.load(open('/Users/linwood/projects/LC3-Creations/notebooks/twittertest/viks_vs_hawks.txt'), cls=ConcatJSONDecoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viks_vs_hawks = [json.loads(l) for l in viks_vs_hawks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Seattle\n",
      "CCAT347HUEA3A49H\n",
      "None\n",
      "N. Minneapolis & Brooklyn Park\n",
      "Minnesota\n",
      "Minnesota, USA\n",
      "CCAT347HUEA3A49H\n",
      "None\n",
      "N. Minneapolis & Brooklyn Park\n",
      "Minneapolis\n",
      "None\n",
      "quebec city\n",
      "PA\n",
      "Minneapolis, MN\n",
      "None\n",
      "ÜT: 44.951105,-92.956853\n",
      "Eastside Toronto\n",
      "minneapolis, mn\n",
      "Montreal\n",
      "Farmington High School '16\n",
      "Minnesota, USA\n",
      "Minneapolis, MN\n",
      "MPLS - Ames\n",
      "Minneapolis, MN \n",
      "Maple Grove, MN\n",
      "Minneapolis, MN\n",
      "None\n",
      "Ontario, Canada\n",
      "Inver Grove Heights, Minnesota\n",
      "Twin Cities\n",
      "Minnesota\n",
      "Montreal\n",
      "None\n",
      "Minneapolis, MN\n",
      "Kenyon, MN\n",
      "None\n",
      "Minneapolis, MN\n",
      "St. Paul, MN\n",
      "The Scorch\n",
      "Minnesota\n",
      "None\n",
      "Minneapolis, MN\n",
      "Oak Grove,  MN \n",
      "Perham, Minnesota\n",
      "Minnesota\n",
      "Monterey, California\n",
      "None\n",
      "PA\n"
     ]
    }
   ],
   "source": [
    "for l in b[1:50]:\n",
    "    print json.loads(l)['user']['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goal = [\"PHS |⚡️804⚡️ | RVA \",\"Virginia, USA\", \"Washington, DC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re \n",
    "p=re.compile('^(.*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seattle\n",
      "CCAT\n",
      "Minnesota\n",
      "Minnesota, USA\n",
      "CCAT\n",
      "Minneapolis\n",
      "quebec city\n",
      "PA\n",
      "Minneapolis, MN\n",
      "Eastside Toronto\n",
      "minneapolis, mn\n",
      "Montreal\n",
      "Farmington High\n",
      "Minnesota, USA\n",
      "Minneapolis, MN\n",
      "MPLS\n",
      "Minneapolis, MN\n",
      "Maple Grove\n",
      "Minneapolis, MN\n",
      "Ontario, Canada\n",
      "Inver Grove\n",
      "Twin Cities\n",
      "Minnesota\n",
      "Montreal\n",
      "Minneapolis, MN\n",
      "Kenyon, MN\n",
      "Minneapolis, MN\n",
      "St\n",
      "The Scorch\n",
      "Minnesota\n",
      "Minneapolis, MN\n",
      "Oak Grove\n",
      "Perham, Minnesota\n",
      "Minnesota\n",
      "Monterey, California\n",
      "PA\n"
     ]
    }
   ],
   "source": [
    "for l in b[1:50]:\n",
    "    try:\n",
    "        print re.search('^ ?[^ ]?[A-Za-z]+ ?(,)?[ ]?[A-Za-z]+',json.loads(l)['user']['location']).group(0).strip()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHS |⚡️804⚡️ | RVA \n",
      "Virginia, USA\n",
      "Washington, DC\n"
     ]
    }
   ],
   "source": [
    "for l in goal:\n",
    "    print l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skins_vs_pack_locs = [l['user']['location'] for l in b]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8452"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skins_vs_pack_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in set(skins_vs_pack_locs):\n",
    "    try:\n",
    "        print geolocator.geocode(l)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skins_vs_pack_locs[1:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geolocator.geocode('Richmond, Virginia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location((38.2910251, -121.31106, 0.0))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(geolocator.geocode('Twin Cities'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skins_vs_pack_truelocs = []\n",
    "for l['user']['location'] in b:\n",
    "    try:\n",
    "        if len(geolocator.geocode(l['user']['location'])) > 0:\n",
    "            skins_vs_pack_truelocs.append(l['user']['location'])\n",
    "    except:\n",
    "        pass   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skins_vs_pack_truelocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-33e961e0e4ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for l in b[1:10]:\n",
    "    print l['user']['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('twitterapikeys.txt', 'w+') as outfile:\n",
    "    json.dump(TwitterOauth, outfile)\n",
    "outfile.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
