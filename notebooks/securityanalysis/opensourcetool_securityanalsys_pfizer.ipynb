{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MorningStar](files/images/TitleImage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook provides value investor-based analysis for [Pfizer, Inc., an American multinational pharmaceutical corporation](http://www.pfizer.com/). Outside of demonstrating one approach to breaking down a company's financials to determine its intrinsic value, this work also demonstrates the utility of modern data analysis tools like [Python](https://www.python.org/), [iPython](http://ipython.org/), Anaconda, and [scikit-learn](http://scikit-learn.org/stable/) (i.e. machine learning tool) to create repeatable analytic workflows.  If you download this notebook, you can recreate this analysis for any company by using your ticker symbol of choice in the \"good-morning\" module below.  \n",
    "\n",
    "![Disclaimer](http://www.ravenht.org.uk/data/images/Data_Protection/disclaimer.jpg)\n",
    "\n",
    "Now, before you read any further, know this:\n",
    "* *I am not a certified financial analyst*\n",
    "* *I do not have a degree or certification from one of the world's [top business schools](http://www.topmba.com/mba-rankings/specialization/finance)...and I'm not working on one either; my degree is in Physics*\n",
    "* *I do not receive any payment or compensation for financial advice or services*\n",
    "* *I am not liable for any decisions that result from this analysis*\n",
    "* *I did not own any shares in [PFE](http://www.morningstar.com/stocks/XNYS/PFE/quote.html) at the time of writing.*\n",
    "\n",
    "Now,with the disclaimer out of the way, let's cover some of my realities.  \n",
    "\n",
    "What I do have is a strong desire to gradually achieve financial independence by acquiring assets at a discount [(if you don't know what an asset is, click here to learn)](http://www.investinganswers.com/financial-dictionary/financial-statement-analysis/asset-2278).  Add to that my insatiable curiosity to learn new and smarter ways of using data to improve my situation (i.e. learn more, grow net worth, or automate something).  In this case, the goal is to purchase assets -- after careful analysis -- at every possible opportunity.  Thus, securities hold a significant portion of my net worth.  More importantly, the analysis I share today is a part of what I do to grow my resources for the future. What's the point? There's no agenda here, outside of sharing a repeatable analytic workflow, helping other value investors along the way, and showing how data analytics impacts nearly every career field. Plain and simple, this exercise will demonstrate how information availability and open source technologies expand the world of possibilities to the common man.  An added benefit is, we'll learn to break down a company like Warren Buffett. \n",
    "\n",
    "![Priorities](https://www.bayzat.com/static/images/media/13%2003%2016%20-%20Smart%20tips%20for%20personal%20finance%20-%20v2.jpg)\n",
    "\n",
    "Before we delve into the analysis, it's only proper that we address or at least provide resources for some of the terms thrown out so far. Let's start with value investing.  Value investing is the [strategy of selecting stocks that sell for less than their intrinsic values](http://www.investopedia.com/terms/v/valueinvesting.asp).  In layman's terms, that translates to \"buying something on sale\".  At the core of value investing is the need to do some financial analysis.  It only make sense; in order to understand that something is selling at a discount you must first understand what it is worth.  So, while value investing involves rigourous analysis of facts and figures, it's still more of an art than a science. \n",
    "\n",
    "The greatest value investing artist of this age is [Warren Buffett](https://en.wikipedia.org/wiki/Warren_Buffett).  In truth, the greatest \"artist\" is actually a tandem of artists, featuring Warren Buffett and [Charlie Munger](https://en.wikipedia.org/wiki/Charlie_Munger), but Mr. Buffett is easily the more visible and vocal of the two.  Warren Buffett has left a wealth of knowledge on value investing in letters to [Berkshire Hathaway shareholders](http://www.berkshirehathaway.com/letters/letters.html), [his autobiography](https://en.wikipedia.org/wiki/The_Snowball:_Warren_Buffett_and_the_Business_of_Life), and dozens of [magazine articles and speeches](http://www.tilsonfunds.com/motley_berkshire_warren_speeches.php) over several decades. In all of that knowledge, and specifically the [1976](https://aboveaverageodds.files.wordpress.com/2009/12/buffett_bh76.pdf) and [1978](http://www.berkshirehathaway.com/letters/1978.html) letters to shareholders , Mr. Buffett provided four rules that govern his strategy for investing, which we will use in our analysis of a company in the notebook.  Buffett acquires partial ownership of a business when it: \n",
    "\n",
    "1. **Is a business that he understands.**  *Levine-Weinberg from TheFool.com put it well in his [July 2014 article](http://www.fool.com/investing/general/2014/07/06/warren-buffetts-4-rules-for-stock-market-success.aspx), \"There are surely tech start-ups you could invest in today that will crush the market in the next 10 years. But if you're not a technology expert, how will you find them?\"  <span style=\"color:red; font-family:Georgia; font-size:initial;\">In this example, I picked Pfizer.  They discover, develop, and manufacture healthcare products.  Pretty easy to understand.* </span>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "2. ** Has favorable longterm prospects.**  *A good translation is in a [June 2015 BusinessInsider.com article](http://www.businessinsider.com/warren-buffett-investing-rules-2015-6) where Kathleen Elkins said one must consider \"whether or not the company will be able to sell their product in 30 years.\"  <span style=\"color:red; font-family:Georgia; font-size:initial;\">Here is a simple example: Apple is a great company, but will people be using iPhones in 2045 (pretty much an unknown)?  Will people still be drinking Coca Cola in 2045 (that's a near certainty)?*</span>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "3.  **Operated by honest and competent people** *This rule is simple enough, but hard to measure.  An article at [InvestorsPodcast.com](http://www.theinvestorspodcast.com/episodes/3-warren-buffett-rules-intrinsic-value.html#sthash.ezTVFQpA.dpuf) gives us one measurable, borrowing from BuffettsBooks.com, when it says \"look for a company that has twice as much equity as debt...Having only a little debt gives the business a lot of flexibility and agility to make the right decisions for shareholders.\"  <span style=\"color:red; font-family:Georgia; font-size:initial;\">We will use the debt-to-equity and current ratios to evaluate leadership impact on debt.*</span>\n",
    "<br>\n",
    "<br>\n",
    "4. **Available at a very attractive price.** *This is the simplest rule, but the one that requires the most detective work and data analysis. This centers on calculating the intrinsic value of a company, or the true worth of a company (not the ticker price).  <span style=\"color:red; font-family:Georgia; font-size:initial;\">Buffett talked about [the \"art\" of calculating intrincic value in an annual report](http://www.valuewalk.com/2014/03/warren-buffett-intrinsic-value-two-problems/).  For now, I use the [BuffetsBooks.com calculator](http://buffettsbooks.com/howtoinvestinstocks/course2/stocks/intrinsic-value-calculator.html#sthash.I02x9s7w.dpbs).*</span>\n",
    "<br>\n",
    "<br>\n",
    "![BerkshireHathawayLetters](http://ecx.images-amazon.com/images/I/51duPVN7EnL._SX391_BO1,204,203,200_.jpg)\n",
    "\n",
    "Simple rules right?  A company that passes these four rules gets into \"Buffet-worthy\" territory.  This is great territory for a company because when Buffett buys, [millions will follow](http://www.businessspectator.com.au/article/2015/6/18/asx/investors-should-brace-buffett-effect). Following is easy so it seems like all investors should be knocking it out of the park.  Not the case! As you will see, it can be hard to find companies that meet all four requirements.  More of your time will be spent analyzing and deciding on companies not worth buying.  Buffett covered this in his 1976 shareholder letter when he said, [*\"It is difficult to find investments meeting such a test, and that is one reason for our concentration of holdings.  We simply can't find one hundred different securities that conform to our investment requirements.\"*](https://aboveaverageodds.files.wordpress.com/2009/12/buffett_bh76.pdf)\n",
    "\n",
    "One last bit of value investor knowledge before we move to the data access and analysis.  Purchasing a [share or stock is becoming a part owner of a business](http://www.investopedia.com/terms/s/stock.asp). It is more than buying the price tied to a ticker symbol.  Holding that concept in your mind stresses the importance of analyzing the company in the same way you would analyze a person who asks you to borrow some money.  You lend based on their ability to pay you back.  In this case, you invest based in the company's ability to reliably return value over an extended period of time.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Set Up (very important)\n",
    "\n",
    "<span style=\"color:red; font-family:Georgia; font-size:initial;\">Full disclosure: I am running OSX El Capitan (10.11.1) on a 2012 Macbook.  Linux or Windows users will have to adjust accordingly. My environment below uses Python 3.5....remember that!!!! </span> \n",
    "\n",
    "The first thing we will do is set up an environment that is exactly like the environment I used to create this notebook.  Lucky for you, I am using [Anaconda](https://www.continuum.io/downloads) which is an easy-to-install, free package manager, environment manager, Python distribution, and collection of over 150 open source packages with free community support. Why are you lucky?  Because it takes a few lines of code to recreate my development environment with all its dependencies. The steps are:\n",
    "1. [Install Anaconda first](http://docs.continuum.io/anaconda/install); make sure it is properly installed by typing \"conda\" in your command prompt or terminal\n",
    "2. Then, [get my yaml file](https://github.com/linwoodc3/LC3-Creations/tree/master/notebooks/securityanalysis) from the project repository. If you don't use Anaconda, use the list at this link to install all the modules I'm using\n",
    "3. Follow the [\"Use Environment from file\"](http://conda.pydata.org/docs/using/envs.html#export-the-environment-file) instructions on Anaconda's website. \n",
    "4. Clone https://github.com/petercerno/good-morning (make sure this is acessible to your sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one more dependency we need to cover; we need to make sure our notebook can import the good-morning repository we just cloned; looking inside the project folder, we see there's no \"setup.py\" file (*I may create one and do the pull request for the github project*).  That means we need to maunally add this file to a path where Python can import it.  I'll put it in the environment path we created. First, I need to know where that is:  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Input:\n",
    "> which conda \n",
    "Output: \n",
    ">/Users/linwood/anaconda/envs/py35/\n",
    "\n",
    "# alternatively, this may work\n",
    "Input:\n",
    "import sys\n",
    "sys.path.append('/...path to.../anaconda/envs/py35/lib/python3.5') # remove \"...path to...\", and replace with path to you envs folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output may be slightly different from mine based on how you installed anaconda.  Now, copy the \"good_morning.py\" and \"good_download.py\" files from the repository we cloned earlier, and paste them in the \"py35\" directory somewhere.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Hit the Data Science Pipeline\n",
    "![Data Access](files/images/data_access.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this analysis, we need 10 years of fundamental financial data.  To understand why, Buffettsbooks.com put together a great series of videos that explains Buffett's four rules and what type of data we need to analyze the company.  Look at [Course 2, videos 17-21](https://www.youtube.com/playlist?list=PLD3EB06EC4A19BFB8).\n",
    "\n",
    "We have three ways to get the data:\n",
    "<br>\n",
    "1.  **Go to the data provider's portal; copy and paste the data into dataframe**\n",
    "2.  **Go to the data provider's portal; export a CSV, load into dataframe**\n",
    "3.  **Use an existing pythonic interface with the data to ingest it directly into my modeling environment** \n",
    "\n",
    "I try all three and give advantages and disadvantages of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data directly from the data provider the old way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The manual data pull is not glamourous at all.  The goal is get ten years worth of financial data from MorningStar.  Why [MorningStar](http://www.morningstar.com/)?  Well, based on the great video series from [BuffetsBooks.com](http://buffettsbooks.com/start-here.html), this is one of the only websites that provide 10 years of historical financials for FREE. To get to the data, enter the company's [ticker symbol](https://en.wikipedia.org/wiki/Ticker_symbol) in the \"Quote\" box on the MorningStar homepage.  We are looking at Pfizer, so enter \"PFE\". Select the \"Key Ratios\" tab.  We have our data!  There are two options now.  We can use the \"Export\" button to download a CSV or we can cut and paste the figures we want.  Both options work for our tool of choice.\n",
    "\n",
    "The goal of this notebook is to use open source tools for analysis, so instead of Excel, I opted to use Python pandas.  [*pandas* is an open source, BSD-licensed library](http://pandas.pydata.org/) providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "So let's import our tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover the data import options going from the most time consuming to the least.  In this case, we'll talk about the old **\"cut and paste\"** method first. \n",
    "\n",
    "To start, we need some data copied.  If you followed directions above, the \"Key Ratios\" data should be in our browser.  To copy me directly, we are going to start with the [current ratio](http://www.investopedia.com/terms/c/currentratio.asp).  In the [middle-bottom of the \"Key Ratios\" tab, click the \"Financial Health\" tab](http://financials.morningstar.com/ratios/r.html?t=PFE&region=USA&culture=en_US).  When the screen refreshes, you should see a section titled \"Liquidity/Financial Health\" at the bottom; copy the \"Current ratio\" line of data.  If you copy it, the pasted output will look like this:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the pasted output from MorningStar.com\n",
    "\n",
    "1.47\t2.20\t2.15\t1.59\t1.66\t2.11\t2.06\t2.15\t2.41\t2.67\t1.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us one current ratio for each year back to 2005.  Next, we create a [python dictionary](https://docs.python.org/2/tutorial/datastructures.html#dictionaries) with our data.  That involves creating key,value pairs.  The year will be the *\"key\"* and the current ratio for that year will be the *\"value\"*. In our data, the first key,value pair is: 2005:1.47.  Let's do that and see the output: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the year as the key and the current ratio for that year as the value in the dictionary\n",
    "\n",
    "current_ratio={2005:1.47, 2006:2.20, 2007:2.15, 2008:1.59, 2009:1.66, 2010:2.11, 2011:2.06, 2012:2.15, 2013:2.41, 2014:2.67 ,2015:1.62}\n",
    "current_ratio; # remove the semicolon to see the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typing out the dictionary syntax takes a few minutes.  A dictionary easily converts to a [pandas dataframe](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe), which is similar to an excel spreadsheet. Our goal is to get all the data into a single dataframe. Let's create our dataframe, and name it df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use the values as the data in the dataframe but use the keys of the current_ratio dictionary as the dataframe's index\n",
    "\n",
    "df = pd.DataFrame([value for key,value in current_ratio.items()],columns=['current_ratio'], index = current_ratio.keys())\n",
    "df; # remove the semicolon to see the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have the current ratio figures.  Let's add more fundamental financial data! \n",
    "\n",
    "This time, we are going to create [python lists](https://docs.python.org/2/tutorial/introduction.html#lists) from the pasted data.  We then convert those lists to arrays using [numpy](http://docs.scipy.org/doc/numpy/user/whatisnumpy.html);  a [numpy array](http://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html) can be appended to a pandas dataframe. At the end of this code block, we should have a dataframe with all of our historical data.  Let's import what we need and write the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_ratio</th>\n",
       "      <th>debt_equity</th>\n",
       "      <th>dividend</th>\n",
       "      <th>EPS</th>\n",
       "      <th>BVperShare</th>\n",
       "      <th>Debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>1.47</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.09</td>\n",
       "      <td>9.05</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2.20</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.66</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.60</td>\n",
       "      <td>6.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1.59</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.20</td>\n",
       "      <td>8.52</td>\n",
       "      <td>7.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1.66</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.23</td>\n",
       "      <td>11.15</td>\n",
       "      <td>20.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.02</td>\n",
       "      <td>10.95</td>\n",
       "      <td>19.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2.06</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.27</td>\n",
       "      <td>11.88</td>\n",
       "      <td>18.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.94</td>\n",
       "      <td>11.16</td>\n",
       "      <td>16.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.19</td>\n",
       "      <td>12.18</td>\n",
       "      <td>17.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2.67</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.42</td>\n",
       "      <td>12.39</td>\n",
       "      <td>18.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.33</td>\n",
       "      <td>10.82</td>\n",
       "      <td>17.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_ratio  debt_equity  dividend   EPS  BVperShare   Debt\n",
       "2005           1.47         0.10      0.76  1.09        9.05   5.40\n",
       "2006           2.20         0.08      0.96  2.66        9.77   4.83\n",
       "2007           2.15         0.11      1.16  1.17        9.60   6.35\n",
       "2008           1.59         0.14      1.28  1.20        8.52   7.16\n",
       "2009           1.66         0.48      0.80  1.23       11.15  20.28\n",
       "2010           2.11         0.44      0.72  1.02       10.95  19.70\n",
       "2011           2.06         0.43      0.80  1.27       11.88  18.58\n",
       "2012           2.15         0.38      0.88  1.94       11.16  16.70\n",
       "2013           2.41         0.40      0.96  3.19       12.18  17.70\n",
       "2014           2.67         0.44      1.04  1.42       12.39  18.63\n",
       "2015           1.62         0.44      1.10  1.33       10.82  17.02"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # we give numpy a shorthand name on import; coders are lazy\n",
    "\n",
    "\n",
    "# We paste the data, enclose it in brackets, and add commas between values to create the list\n",
    "# then use 'np.asarray' (numpy) to convert our list to an array\n",
    "# numpy is a fundamental package for scientific computing in Python.\n",
    "# the df['name'] code appends the result to the dataframe we created above and gives the column's title\n",
    "# Then, we look at our new dataframe (df)\n",
    "\n",
    "df['debt_equity']=np.asarray([0.10,\t0.08,\t0.11,\t0.14,\t0.48,\t0.44,\t0.43,\t0.38,\t0.40,\t0.44,\t0.44])\n",
    "df['dividend']=np.asarray([0.76,\t0.96,\t1.16,\t1.28,\t0.80,\t0.72,\t0.80,\t0.88,\t0.96,\t1.04,\t1.10])\n",
    "df['EPS']=np.asarray([1.09,\t2.66,\t1.17,\t1.20,\t1.23,\t1.02,\t1.27,\t1.94,\t3.19,\t1.42,\t1.33])\n",
    "df['BVperShare']=np.asarray([9.05,\t9.77,\t9.60,\t8.52,\t11.15,\t10.95,\t11.88,\t11.16,\t12.18,\t12.39,\t10.82])\n",
    "df['Debt']= np.asarray([5.40,\t4.83,\t6.35,\t7.16,\t20.28,\t19.70,\t18.58,\t16.70,\t17.70,\t18.63,\t17.02])\n",
    "df; # remove semicolon to see output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the old way of getting data and it's going out of style fast**.  It works, but let's highlight some quick advantages and disadvantages:\n",
    "1. **Advantages**\n",
    "  * We get the exact data we want\n",
    "  * It's up to date information\n",
    "  * We don't worry about fake data or viruses; the data is coming from the provider's portal\n",
    "  * We get a lot of practice on constructing and relating python data structures\n",
    "  \n",
    "2. **Disadvantages**\n",
    "  * Time consuming\n",
    "  * Chance of human error extremely high; adding commas and deleting extra spaces is always a problem\n",
    "  * The data is not loaded dynamically, when the dataframe is created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data directly from the data provider the 'KIND OF' old way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we try the \"kind of old way\" of getting the data we need.  We get a little fancier by eliminating the *cut and paste* workflow and instead, use the option to export a CSV.  pandas can ingest CSV files, so our tool will be happy!  Let's give it a go.  \n",
    "\n",
    "Return to the MorningStar page in your browser with Pfizer's key ratios displayed.  Look for the \"Export\" option, click it and download the csv.  \n",
    "\n",
    "![Export](files/images/MorningStarExport.png)\n",
    "\n",
    "I named my download \"pfe_key_ratios.csv\".  A copy of the data as of 17 November 2015 is in the \"data\" folder of the github repository for this notebook.  Now, let's load it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 3: expected 1 fields, saw 12\\nSkipping line 4: expected 1 fields, saw 12\\nSkipping line 5: expected 1 fields, saw 12\\nSkipping line 6: expected 1 fields, saw 12\\nSkipping line 7: expected 1 fields, saw 12\\nSkipping line 8: expected 1 fields, saw 12\\nSkipping line 9: expected 1 fields, saw 12\\nSkipping line 10: expected 1 fields, saw 12\\nSkipping line 11: expected 1 fields, saw 12\\nSkipping line 12: expected 1 fields, saw 12\\nSkipping line 13: expected 1 fields, saw 12\\nSkipping line 14: expected 1 fields, saw 12\\nSkipping line 15: expected 1 fields, saw 12\\nSkipping line 16: expected 1 fields, saw 12\\nSkipping line 17: expected 1 fields, saw 12\\nSkipping line 18: expected 1 fields, saw 12\\nSkipping line 21: expected 1 fields, saw 12\\nSkipping line 22: expected 1 fields, saw 12\\nSkipping line 23: expected 1 fields, saw 12\\nSkipping line 24: expected 1 fields, saw 12\\nSkipping line 25: expected 1 fields, saw 12\\nSkipping line 26: expected 1 fields, saw 12\\nSkipping line 27: expected 1 fields, saw 12\\nSkipping line 28: expected 1 fields, saw 12\\nSkipping line 29: expected 1 fields, saw 12\\nSkipping line 30: expected 1 fields, saw 12\\nSkipping line 32: expected 1 fields, saw 12\\nSkipping line 33: expected 1 fields, saw 12\\nSkipping line 34: expected 1 fields, saw 12\\nSkipping line 35: expected 1 fields, saw 12\\nSkipping line 36: expected 1 fields, saw 12\\nSkipping line 37: expected 1 fields, saw 12\\nSkipping line 38: expected 1 fields, saw 12\\nSkipping line 39: expected 1 fields, saw 12\\nSkipping line 40: expected 1 fields, saw 12\\nSkipping line 43: expected 1 fields, saw 12\\nSkipping line 45: expected 1 fields, saw 12\\nSkipping line 46: expected 1 fields, saw 12\\nSkipping line 47: expected 1 fields, saw 12\\nSkipping line 48: expected 1 fields, saw 12\\nSkipping line 50: expected 1 fields, saw 12\\nSkipping line 51: expected 1 fields, saw 12\\nSkipping line 52: expected 1 fields, saw 12\\nSkipping line 53: expected 1 fields, saw 12\\nSkipping line 55: expected 1 fields, saw 12\\nSkipping line 56: expected 1 fields, saw 12\\nSkipping line 57: expected 1 fields, saw 12\\nSkipping line 58: expected 1 fields, saw 12\\nSkipping line 60: expected 1 fields, saw 12\\nSkipping line 61: expected 1 fields, saw 12\\nSkipping line 62: expected 1 fields, saw 12\\nSkipping line 63: expected 1 fields, saw 12\\nSkipping line 66: expected 1 fields, saw 12\\nSkipping line 67: expected 1 fields, saw 12\\nSkipping line 68: expected 1 fields, saw 12\\nSkipping line 69: expected 1 fields, saw 12\\nSkipping line 70: expected 1 fields, saw 12\\nSkipping line 71: expected 1 fields, saw 12\\nSkipping line 74: expected 1 fields, saw 12\\nSkipping line 75: expected 1 fields, saw 12\\nSkipping line 76: expected 1 fields, saw 12\\nSkipping line 77: expected 1 fields, saw 12\\nSkipping line 78: expected 1 fields, saw 12\\nSkipping line 79: expected 1 fields, saw 12\\nSkipping line 80: expected 1 fields, saw 12\\nSkipping line 81: expected 1 fields, saw 12\\nSkipping line 82: expected 1 fields, saw 12\\nSkipping line 83: expected 1 fields, saw 12\\nSkipping line 84: expected 1 fields, saw 12\\nSkipping line 85: expected 1 fields, saw 12\\nSkipping line 86: expected 1 fields, saw 12\\nSkipping line 87: expected 1 fields, saw 12\\nSkipping line 88: expected 1 fields, saw 12\\nSkipping line 89: expected 1 fields, saw 12\\nSkipping line 90: expected 1 fields, saw 12\\nSkipping line 91: expected 1 fields, saw 12\\nSkipping line 92: expected 1 fields, saw 12\\nSkipping line 93: expected 1 fields, saw 12\\nSkipping line 94: expected 1 fields, saw 12\\nSkipping line 96: expected 1 fields, saw 12\\nSkipping line 97: expected 1 fields, saw 12\\nSkipping line 98: expected 1 fields, saw 12\\nSkipping line 99: expected 1 fields, saw 12\\nSkipping line 100: expected 1 fields, saw 12\\nSkipping line 103: expected 1 fields, saw 12\\nSkipping line 104: expected 1 fields, saw 12\\nSkipping line 105: expected 1 fields, saw 12\\nSkipping line 106: expected 1 fields, saw 12\\nSkipping line 107: expected 1 fields, saw 12\\nSkipping line 108: expected 1 fields, saw 12\\nSkipping line 109: expected 1 fields, saw 12\\nSkipping line 110: expected 1 fields, saw 12\\nSkipping line 111: expected 1 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "#df2 = pd.read_csv('data/pfe_key_ratios.csv')\n",
    "\n",
    "'''\n",
    "The first line will thrown an error, becuase of some problems with how the file is structured. The\n",
    "exact error is: \"CParserError: Error tokenizing data. C error: Expected 1 fields in line 3, saw 12\"\n",
    "\n",
    "As stated, there's nothing new under the sun. A good practice is to copy the exact error you get, paste \n",
    "it into Google, and see how others solved the problem.  In my case, this url provided the workaround:\n",
    "http://stackoverflow.com/questions/18039057/python-pandas-error-tokenizing-data\n",
    "'''\n",
    "df2 = pd.read_csv('data/pfe_key_ratios.csv',error_bad_lines=False);\n",
    "df2; # remove the semicolon to see the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa!!!!  That red means Python is giving us a warning, and if you look closely, you see a lot of skpped data. Everything actualy. MorningStar's export CSV is not something pandas likes.  Close inspection of the spreadsheet highlights the problem.  \n",
    "\n",
    "![LibreOffice](files/images/LibreOffice.png)\n",
    "\n",
    "The export is nice and structured, but the organization of the data is not something pandas appreciates. Could we write something to read this, probably. But, that would take some time. Now, I would have everything I needed to continue this work in LibreOffice Calc (free and more than capable alternative to Microsoft Excel), but we want to use Python to do this.  \n",
    "\n",
    "**This is the \"kind of\" old way of getting data and is most used today**.  It's a super quick option to get data for analysis in spreadsheets, but let's highlight some advantages and disadvantages:\n",
    "1. **Advantages**\n",
    "  * Again, we get the exact data we want\n",
    "  * Quick!  We got everything in one spreadhsheet very quickly\n",
    "  * We don't worry about fake data or viruses; the data is coming from the provider's portal\n",
    "  * We get a lot of practice on constructing and relating python data structures\n",
    "  \n",
    "2. **Disadvantages**\n",
    "  * The format isn't ready for pandas ingest without some tedious wrangling\n",
    "  * We're back to manual analysis; we'll be cutting and pasting data to different sheets \n",
    "  * The data is only as current as the download you get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data from the data provider the new way\n",
    "\n",
    "Last, we'll look at a pythonic way to get this data.  Just as Warren Buffett has his rules to investing, there's a rule that governs the lives of most programmers, coders, data scientists, etc.  [That rule is, \"Don't reinvent the wheel!!\"](http://blog.codinghorror.com/dont-reinvent-the-wheel-unless-you-plan-on-learning-more-about-wheels/)  \n",
    "\n",
    "Chances are, someone, somewhere out there has faced the same problem I'm facing right now.  There are even greater chances that this someone solved the problem, or is farther along at solving the problem than I am.  So, what's my problem?  ** I want to access 10 years of fundamental financial data from MorningStar.com without leaving the Python environment.**  After a few Google searches, I found Peter Cerno's [**good-morning**](https://github.com/petercerno/good-morning/blob/master/good_morning.py) (referred to as *Good Morning* from now on) repository on [GitHub.com](https://github.com/).  Sure enough, my obscure and seemingly crazy problem was solved; COMPLETELY!  *Good Morning* is a simple Python module for downloading fundamental financial data from financials.morningstar.com.  If you followed all the instructions in the environment set up section above, we're ready to give it a whirl.  <font color='red'>**Remember, you must be using an environment with Python 3 to use *Good Morning***</font>.  Let's see how this module does with Pfizer data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's import the module\n",
    "import good_morning as gm \n",
    "\n",
    "\n",
    "# if you get an error, remember you must have the .py file in a directory listed in the sys.path printout\n",
    "\n",
    "# Use the example at https://github.com/petercerno/good-morning/blob/master/README.md for syntax\n",
    "\n",
    "# We call the module to load the Key ratios\n",
    "kr = gm.KeyRatiosDownloader()\n",
    "\n",
    "# Now we enter the ticker symbol for the company's data we want.  We want Pfizer. We look at the output\n",
    "data = kr.download('PFE')\n",
    "data; # remove the semicolon to see the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! All the data, but we don't know what type of data structure this is. Let's look:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's a list, which means we can access different elements using list indexes.  The basic syntax is list[integer] to access parts of the python list. It's important to remeber python lists are zero indexed; the first element is 0, not 1.  So, let's try an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Key Financials USD</th>\n",
       "      <th>Revenue USD Mil</th>\n",
       "      <th>Gross Margin %</th>\n",
       "      <th>Operating Income USD Mil</th>\n",
       "      <th>Operating Margin %</th>\n",
       "      <th>Net Income USD Mil</th>\n",
       "      <th>Earnings Per Share USD</th>\n",
       "      <th>Dividends USD</th>\n",
       "      <th>Payout Ratio %</th>\n",
       "      <th>Shares Mil</th>\n",
       "      <th>Book Value Per Share USD</th>\n",
       "      <th>Operating Cash Flow USD Mil</th>\n",
       "      <th>Cap Spending USD Mil</th>\n",
       "      <th>Free Cash Flow USD Mil</th>\n",
       "      <th>Free Cash Flow Per Share USD</th>\n",
       "      <th>Working Capital USD Mil</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>51298</td>\n",
       "      <td>83.4</td>\n",
       "      <td>11881</td>\n",
       "      <td>23.2</td>\n",
       "      <td>8085</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.76</td>\n",
       "      <td>67.2</td>\n",
       "      <td>7411</td>\n",
       "      <td>9.05</td>\n",
       "      <td>14733</td>\n",
       "      <td>-2106</td>\n",
       "      <td>12627</td>\n",
       "      <td>1.80</td>\n",
       "      <td>13448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>48371</td>\n",
       "      <td>84.2</td>\n",
       "      <td>12124</td>\n",
       "      <td>25.1</td>\n",
       "      <td>19337</td>\n",
       "      <td>2.66</td>\n",
       "      <td>0.96</td>\n",
       "      <td>52.8</td>\n",
       "      <td>7274</td>\n",
       "      <td>9.77</td>\n",
       "      <td>17594</td>\n",
       "      <td>-2050</td>\n",
       "      <td>15544</td>\n",
       "      <td>2.16</td>\n",
       "      <td>25560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>48418</td>\n",
       "      <td>76.8</td>\n",
       "      <td>7519</td>\n",
       "      <td>15.5</td>\n",
       "      <td>8144</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.16</td>\n",
       "      <td>98.3</td>\n",
       "      <td>6939</td>\n",
       "      <td>9.60</td>\n",
       "      <td>13353</td>\n",
       "      <td>-1880</td>\n",
       "      <td>11473</td>\n",
       "      <td>1.65</td>\n",
       "      <td>25014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>48296</td>\n",
       "      <td>83.2</td>\n",
       "      <td>11726</td>\n",
       "      <td>24.3</td>\n",
       "      <td>8104</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>107.6</td>\n",
       "      <td>6750</td>\n",
       "      <td>8.52</td>\n",
       "      <td>18238</td>\n",
       "      <td>-1701</td>\n",
       "      <td>16537</td>\n",
       "      <td>2.45</td>\n",
       "      <td>16067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>50009</td>\n",
       "      <td>82.2</td>\n",
       "      <td>10827</td>\n",
       "      <td>21.7</td>\n",
       "      <td>8635</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.80</td>\n",
       "      <td>65.0</td>\n",
       "      <td>7045</td>\n",
       "      <td>11.15</td>\n",
       "      <td>16587</td>\n",
       "      <td>-1205</td>\n",
       "      <td>15382</td>\n",
       "      <td>2.18</td>\n",
       "      <td>24445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>67809</td>\n",
       "      <td>76.0</td>\n",
       "      <td>9422</td>\n",
       "      <td>13.9</td>\n",
       "      <td>8257</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.72</td>\n",
       "      <td>70.6</td>\n",
       "      <td>8074</td>\n",
       "      <td>10.95</td>\n",
       "      <td>11454</td>\n",
       "      <td>-1513</td>\n",
       "      <td>9941</td>\n",
       "      <td>1.23</td>\n",
       "      <td>31859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>67425</td>\n",
       "      <td>77.6</td>\n",
       "      <td>15241</td>\n",
       "      <td>22.6</td>\n",
       "      <td>10009</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.80</td>\n",
       "      <td>61.0</td>\n",
       "      <td>7870</td>\n",
       "      <td>11.88</td>\n",
       "      <td>20240</td>\n",
       "      <td>-1660</td>\n",
       "      <td>18580</td>\n",
       "      <td>2.47</td>\n",
       "      <td>29659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>58986</td>\n",
       "      <td>80.8</td>\n",
       "      <td>13221</td>\n",
       "      <td>22.4</td>\n",
       "      <td>14570</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.88</td>\n",
       "      <td>69.8</td>\n",
       "      <td>7508</td>\n",
       "      <td>11.16</td>\n",
       "      <td>17054</td>\n",
       "      <td>-1327</td>\n",
       "      <td>15727</td>\n",
       "      <td>2.09</td>\n",
       "      <td>32796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>51584</td>\n",
       "      <td>81.4</td>\n",
       "      <td>16727</td>\n",
       "      <td>32.4</td>\n",
       "      <td>22003</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.96</td>\n",
       "      <td>62.5</td>\n",
       "      <td>6895</td>\n",
       "      <td>12.18</td>\n",
       "      <td>17765</td>\n",
       "      <td>-1465</td>\n",
       "      <td>16300</td>\n",
       "      <td>2.24</td>\n",
       "      <td>32878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>49605</td>\n",
       "      <td>80.7</td>\n",
       "      <td>12240</td>\n",
       "      <td>24.7</td>\n",
       "      <td>9135</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.04</td>\n",
       "      <td>63.0</td>\n",
       "      <td>6424</td>\n",
       "      <td>12.39</td>\n",
       "      <td>16883</td>\n",
       "      <td>-1583</td>\n",
       "      <td>15300</td>\n",
       "      <td>2.41</td>\n",
       "      <td>36071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>47922</td>\n",
       "      <td>81.3</td>\n",
       "      <td>11126</td>\n",
       "      <td>23.2</td>\n",
       "      <td>8360</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.10</td>\n",
       "      <td>82.7</td>\n",
       "      <td>6288</td>\n",
       "      <td>10.82</td>\n",
       "      <td>15197</td>\n",
       "      <td>-1230</td>\n",
       "      <td>13967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Key Financials USD  Revenue USD Mil  Gross Margin %  Operating Income USD Mil  \\\n",
       "Period                                                                          \n",
       "2005                          51298            83.4                     11881   \n",
       "2006                          48371            84.2                     12124   \n",
       "2007                          48418            76.8                      7519   \n",
       "2008                          48296            83.2                     11726   \n",
       "2009                          50009            82.2                     10827   \n",
       "2010                          67809            76.0                      9422   \n",
       "2011                          67425            77.6                     15241   \n",
       "2012                          58986            80.8                     13221   \n",
       "2013                          51584            81.4                     16727   \n",
       "2014                          49605            80.7                     12240   \n",
       "2015                          47922            81.3                     11126   \n",
       "\n",
       "Key Financials USD  Operating Margin %  Net Income USD Mil  \\\n",
       "Period                                                       \n",
       "2005                              23.2                8085   \n",
       "2006                              25.1               19337   \n",
       "2007                              15.5                8144   \n",
       "2008                              24.3                8104   \n",
       "2009                              21.7                8635   \n",
       "2010                              13.9                8257   \n",
       "2011                              22.6               10009   \n",
       "2012                              22.4               14570   \n",
       "2013                              32.4               22003   \n",
       "2014                              24.7                9135   \n",
       "2015                              23.2                8360   \n",
       "\n",
       "Key Financials USD  Earnings Per Share USD  Dividends USD  Payout Ratio %  \\\n",
       "Period                                                                      \n",
       "2005                                  1.09           0.76            67.2   \n",
       "2006                                  2.66           0.96            52.8   \n",
       "2007                                  1.17           1.16            98.3   \n",
       "2008                                  1.20           1.28           107.6   \n",
       "2009                                  1.23           0.80            65.0   \n",
       "2010                                  1.02           0.72            70.6   \n",
       "2011                                  1.27           0.80            61.0   \n",
       "2012                                  1.94           0.88            69.8   \n",
       "2013                                  3.19           0.96            62.5   \n",
       "2014                                  1.42           1.04            63.0   \n",
       "2015                                  1.33           1.10            82.7   \n",
       "\n",
       "Key Financials USD  Shares Mil  Book Value Per Share USD  \\\n",
       "Period                                                     \n",
       "2005                      7411                      9.05   \n",
       "2006                      7274                      9.77   \n",
       "2007                      6939                      9.60   \n",
       "2008                      6750                      8.52   \n",
       "2009                      7045                     11.15   \n",
       "2010                      8074                     10.95   \n",
       "2011                      7870                     11.88   \n",
       "2012                      7508                     11.16   \n",
       "2013                      6895                     12.18   \n",
       "2014                      6424                     12.39   \n",
       "2015                      6288                     10.82   \n",
       "\n",
       "Key Financials USD  Operating Cash Flow USD Mil  Cap Spending USD Mil  \\\n",
       "Period                                                                  \n",
       "2005                                      14733                 -2106   \n",
       "2006                                      17594                 -2050   \n",
       "2007                                      13353                 -1880   \n",
       "2008                                      18238                 -1701   \n",
       "2009                                      16587                 -1205   \n",
       "2010                                      11454                 -1513   \n",
       "2011                                      20240                 -1660   \n",
       "2012                                      17054                 -1327   \n",
       "2013                                      17765                 -1465   \n",
       "2014                                      16883                 -1583   \n",
       "2015                                      15197                 -1230   \n",
       "\n",
       "Key Financials USD  Free Cash Flow USD Mil  Free Cash Flow Per Share USD  \\\n",
       "Period                                                                     \n",
       "2005                                 12627                          1.80   \n",
       "2006                                 15544                          2.16   \n",
       "2007                                 11473                          1.65   \n",
       "2008                                 16537                          2.45   \n",
       "2009                                 15382                          2.18   \n",
       "2010                                  9941                          1.23   \n",
       "2011                                 18580                          2.47   \n",
       "2012                                 15727                          2.09   \n",
       "2013                                 16300                          2.24   \n",
       "2014                                 15300                          2.41   \n",
       "2015                                 13967                           NaN   \n",
       "\n",
       "Key Financials USD  Working Capital USD Mil  \n",
       "Period                                       \n",
       "2005                                  13448  \n",
       "2006                                  25560  \n",
       "2007                                  25014  \n",
       "2008                                  16067  \n",
       "2009                                  24445  \n",
       "2010                                  31859  \n",
       "2011                                  29659  \n",
       "2012                                  32796  \n",
       "2013                                  32878  \n",
       "2014                                  36071  \n",
       "2015                                    NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].transpose(); # remove the semicolon to see the output\n",
    "# we transposed the list to get it to match our earlier example. Dates now go from top to bottom  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes back as a list of dataframes.  We are primed for analyis.  But first, let's get the data we needed.  We want to recreate the data we had in the manual process earlier.  I'll use some intermediate pandas subsetting and slicing.  The [pandas tutorial](http://pandas.pydata.org/pandas-docs/stable/tutorials.html) covers a lot of the techniques I'm using here and more.  We will name our new dataframe, df3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3=pd.concat([data[0].transpose()[['Earnings Per Share USD','Dividends USD','Book Value Per Share USD']],data[8].transpose()[['Long-Term Debt']],data[9].transpose()[['Current Ratio','Debt/Equity']]],axis=1)\n",
    "df3; # remove the semicolon to see the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the modern way of getting data**.  You pull back only the data you want, and you don't have to go directly to the data provider's web portal.  Let's highlight some advantages and disadvantages:\n",
    "\n",
    "1. **Advantages**\n",
    "  * Again, we get the exact data we want and MORE with less effort.  We don't click through tabs, just enter the ticker symbol\n",
    "  * Minimal code needed;  we had all the data we needed an more in 4 lines of code\n",
    "  * Data will load dynamically as each time the code is run, the data is updated\n",
    "  * It's already in python pandas data format\n",
    "  \n",
    "2. **Disadvantages**\n",
    "  * If the data provider changes their website or data structure, this fails\n",
    "  * Set up to get the module as a callable tool takes some prior knowledge; can be frustrating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data Analysis](files/images/data_analysis.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = 'red'>Everything below here under construction</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the grunt work, we're finally to the data analysis.  This part is relatively simple.  Here, we are using Buffett's rules and the available data to decide where or not Pfizer is a \"value investor\" pick for longterm ownership.  This type of analysis is good for individual investors but also for institutional investors who have a longer outlook.  \n",
    "\n",
    "Of the four rules, two are somewhat subjective.  Its why no two value investor's will have the same portfolio.  We all view companies and profiles differently.  But, to refresh the first two rules for Pfizer:\n",
    "\n",
    "1. **Is Pfizer a business that I understand.**  <span style=\"color:red; font-family:Georgia; font-size:initial;\">In this example, I picked Pfizer.  They discover, develop, and manufacture healthcare products.  Pretty easy to understand.*</span>  ** Pfizer passes rule 1** \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "2. ** Pfizer has favorable longterm prospects.**  *  <span style=\"color:red; font-family:Georgia; font-size:initial;\"> In 2045, people will still need healthcare products.  In fact, we may need them more as medical advances and technology increase the life expectancy. </span> **Pfizer passes rule 2**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "3.  **Pfizer is operated by honest and competent people** <span style=\"color:red; font-family:Georgia; font-size:initial;\">We want a debt-to-equity ratio below .50 and a current ratio above 1.50.</span>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "4. **Available at a very attractive price.** <span style=\"color:red; font-family:Georgia; font-size:initial;\">I will use the [BuffetsBooks.com calculator](http://buffettsbooks.com/howtoinvestinstocks/course2/stocks/intrinsic-value-calculator.html#sthash.I02x9s7w.dpbs).*</span>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "# Using Debt as a measure of leadership: Debt<.50 and Current Ratio>1.50\n",
    "\n",
    "[In course 2, lessons 17-21](https://www.youtube.com/playlist?list=PLD3EB06EC4A19BFB8), Buffettsbooks.com does a great job of explaining why we look for companies with debt-to-equity ratios below .50 over  and current ratios greater than 1.50 over a 10 year period.  Our simple task for rule 3 is to see if Pfizer made the cut:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Ratio</th>\n",
       "      <th>Debt/Equity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Period</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>1.47</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2.20</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2.15</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1.59</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1.66</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2.11</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2.06</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2.15</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2.41</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2.67</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1.62</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Current Ratio  Debt/Equity\n",
       "Period                            \n",
       "2005             1.47         0.10\n",
       "2006             2.20         0.08\n",
       "2007             2.15         0.11\n",
       "2008             1.59         0.14\n",
       "2009             1.66         0.48\n",
       "2010             2.11         0.44\n",
       "2011             2.06         0.43\n",
       "2012             2.15         0.38\n",
       "2013             2.41         0.40\n",
       "2014             2.67         0.44\n",
       "2015             1.62         0.44"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a smaller dataframe with only debt-to-equity and current ratio\n",
    "df3[['Current Ratio','Debt/Equity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We the proper data broken out, let's do some simple [boolean indexing (true/false)](http://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing) and an average with our thresholds from Buffett.  Let's look at debt-to-equity ratio first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Period\n",
      "2005    True\n",
      "2006    True\n",
      "2007    True\n",
      "2008    True\n",
      "2009    True\n",
      "2010    True\n",
      "2011    True\n",
      "2012    True\n",
      "2013    True\n",
      "2014    True\n",
      "2015    True\n",
      "Freq: A-DEC, Name: Debt/Equity, dtype: bool\n",
      "\n",
      "\n",
      "The average debt-to-equity ratio for Pfizer over a 10-year period is 0.31.\n"
     ]
    }
   ],
   "source": [
    "print() # whitespace\n",
    "\n",
    "# Boolean index of the dataframe; if the value is less than .50, returns \"True\"\n",
    "print (df3['Debt/Equity']<.50)\n",
    "\n",
    "print() # whitespace\n",
    "print()\n",
    "\n",
    "\n",
    "# Average of the column; we want a value less than .50\n",
    "print (\"The average debt-to-equity ratio for Pfizer over a 10-year period is %r.\" % round(df3['Debt/Equity'].mean(),2) )\n",
    "vigilant1= round(df3['Debt/Equity'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same concept as the personal debt-to-equity ratio used in personal finance.  Basically, this is a calculation of the total assets you own and the total liabilities (debts) you owe.  High debt is one danger to a company, and good managers manage the amount of debt their companies take on.  \n",
    "\n",
    "We can illustrate this \"danger\" by equating it to personal finance.  If you added up everything you owned (stocks, bank accounts, etc.) that would be your assets.  Let's say that was 100,000.  Now, if you added up everything you OWED (mortgage, car, bills, etc.), that would equal your total liabilities.  Let's say that is 90,000. If you died, your family would be left with $ 10,000 after everything was paid off (not including taxes).  In this case, you equity is $10,000 and your debt-to-equity ratio is 0.90.\n",
    "\n",
    "Buffett historically buys companies with a ratio lower than .50.  A debt-to-equity ratio of .50 means that a company has 50 cents of debt for every dollar of equity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period\n",
       "2005    False\n",
       "2006     True\n",
       "2007     True\n",
       "2008     True\n",
       "2009     True\n",
       "2010     True\n",
       "2011     True\n",
       "2012     True\n",
       "2013     True\n",
       "2014     True\n",
       "2015     True\n",
       "Freq: A-DEC, Name: Current Ratio, dtype: bool"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['Current Ratio']>1.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df3['BVdiff']= df3['BVperShare']-df3['BVperShare'].shift()\n",
    "df3['Unaccounted_Earnings']=df3.apply(lambda row: row['EPS']-(row['dividend'] + row['BVdiff']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import good_morning as gm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we make a prediction of future earnings on a linear model, we can make some assumptions of the future based on the past.  Here, I calculate the the ratio of earnings to book value.  The goal is to see how earnings historically related to book value every year to calculate the next years earnings.  This is why stability is so important; if the financials over a 10 year period form a positively correlated linear model, predictions become easier.  The goal is to find those companies with positively correlated earnings, debt-to-equity ratio, dividend, book-value-per-share, and current ratio. So we get the percentage for each year and then calculate basic summary statistics.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.apply(lambda row: row['EPS']/row['BVperShare'], axis=1).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['EPS','BVperShare','dividend','BVdiff']];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company = df[['EPS']].sum()\n",
    "pocket=df[['dividend']].sum()+df.BVperShare.iloc[-1]-df.BVperShare.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "company.iloc[0]-pocket.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.polynomial.polynomial as poly\n",
    "\n",
    "# There's nothing new under the sun; I modified some code for numpy data fitting.  \n",
    "# The link is http://docs.scipy.org/doc/numpy/reference/generated/numpy.polyfit.html\n",
    "\n",
    "\n",
    "# security data for fitting\n",
    "x = df.index\n",
    "y = df['BVperShare']\n",
    "\n",
    "x_new = np.linspace(x[0], x[-1], num=len(x)*10)\n",
    "coefs = poly.polyfit(x, y, 1)\n",
    "ffit = poly.Polynomial(coefs) \n",
    "plt.scatter(x, y, s=30, alpha=0.15, marker='D')\n",
    "plt.plot(x_new, ffit(x_new))\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Earnings')\n",
    "plt.xlim([2005,2026])\n",
    "plt.ylim([7,16])\n",
    "plt.title('Book Value per Share for Pfizer, Inc over 10 Years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['index']=df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Pulling the data out for the simple linear model\n",
    "X = np.asarray(df[['index']])\n",
    "y = np.asarray(df['BVperShare'])\n",
    "\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr.predict(2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the predicted book value per share to get an estimated earnings per share.  I use the predicted book value for the next year (above) and the average earnings-to-book value ratio for ten years.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr.predict(2016)*df.apply(lambda row: row['EPS']/row['BVperShare'], axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have enough data to make the ultimate calculation; the intricsic value.  To do this, we take all the values from the historical financials and plug them into [Buffett Books Intrinsic Value Calculator](http://buffettsbooks.com/howtoinvestinstocks/course2/stocks/intrinsic-value-calculator.html#sthash.I02x9s7w.dpbs).  For every investor, intrinsic values will differ given the use of the current US treasury 10 year yield.  That changes daily; so calculating intrinsic value today or next week will change.  Either way, you set a bar for each stock that you look at, so know when something is 'on sale'.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
