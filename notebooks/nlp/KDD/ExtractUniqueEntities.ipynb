{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook works on extracting unique named entities and organizations from KDD papers and passing them lists.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import subprocess\n",
    "import unicodedata\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk import Tree\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from operator import itemgetter\n",
    "import polyglot\n",
    "import string\n",
    "from emailextractor import file_to_str, get_emails # paste code to .py file from following link and save within your environment path to call it: https://gist.github.com/dideler/5219706\n",
    "\n",
    "'''\n",
    "Severl issues extended the time to complete this work\n",
    "that were not related to the coding itself.  I had two\n",
    "Anaconda distros installed on my computer.  This led\n",
    "to problems with importing modules because the paths\n",
    "for installation and retrieval were mixed.  I had to\n",
    "uninstall both anacondas, reinstall, and then recreate\n",
    "my virtual environment.  Imports and installs worked cleanly\n",
    "\n",
    "To create ipython shells in a virtual environment, use:\n",
    "http://stackoverflow.com/questions/30492623/using-both-python-2-x-and-python-3-x-in-ipython-notebook\n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path        = os.path.abspath(os.getcwd())\n",
    "TESTDIR     = os.path.normpath(os.path.join(os.path.expanduser(\"~\"),\"projects\",\"LC3-Creations\", \"examples\",\"KDDsample\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "I experienced unicode problems early on.  Everytime I had an error, I scoured the internet for solutions. Here's the credit.\n",
    "\n",
    "\n",
    "\n",
    "- For Typeerror codes using subprocess to convert pdf2txt output to straight unicode --> http://stackoverflow.com/questions/33283603/python-popen-communicate-str-encodeencoding-utf-8-errors-ignore-cr\n",
    "- For problems with ASCII characters --> http://stackoverflow.com/questions/175240/how-do-i-convert-a-files-format-from-unicode-to-ascii-using-python\n",
    "- For unicode characters left in unicode converted to a string  --> http://stackoverflow.com/questions/8689795/how-can-i-remove-non-ascii-characters-but-leave-periods-and-spaces-using-python\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "a = unicode(subprocess.check_output(['pdf2txt.py',str(os.path.normpath(os.path.join(TESTDIR,\"p1.pdf\")))]),errors='ignore')\n",
    "document = filter(lambda x: x in string.printable,unicodedata.normalize('NFKD', a).encode('ascii','ignore').decode('unicode_escape').encode('ascii','ignore'))\n",
    "lower = document.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online Controlled Experiments: \n",
      "\n",
      "Lessons from Running A/B/n Tests for 12 Years \n",
      "\n",
      " \n",
      "\n",
      "Ron Kohavi \n",
      "\n",
      "Distinguished Engineer & General Manager,  \n",
      "\n",
      "Analysis & Experimentation \n",
      "\n",
      "Microsoft \n",
      "\n",
      "Bellevue, WA, USA \n",
      "\n",
      "RonKohavi@outlook.com  \n",
      "\n",
      "in \n",
      "\n",
      "He \n",
      "\n",
      "2005 \n",
      "\n",
      " \n",
      "BIO \n",
      "Ronny  Kohavi is  a  Microsoft \n",
      "Distinguished  Engineer  and \n",
      "for \n",
      "the  General  Manager \n",
      "and \n",
      "Microsofts  Analysis \n",
      "at \n",
      "Experimentation \n",
      "team \n",
      "Microsoft. \n",
      "joined \n",
      "Microsoft \n",
      "and \n",
      "founded  the  Experimentation \n",
      "Platform  team  in  2006.  He \n",
      "was previously the director of \n",
      "data  mining  and  personalization  at  Amazon.com,  and  the  Vice \n",
      "President  of  Business  Intelligence  at  Blue  Martini  Software, \n",
      "which  went  public  in  2000,  and  later  acquired  by  Red  Prairie. \n",
      "Prior to joining Blue Martini, Kohavi managed MineSet project, \n",
      "Silicon  Graphics  award-winning  product  for  data  mining  and \n",
      "visualization. He joined Silicon Graphics after getting a Ph.D. in \n",
      "Machine  Learning  from  Stanford  University,  where  he  led  the \n",
      "MLC++  project,  the  Machine  Learning  library  in  C++  used  in \n",
      "MineSet and at Blue Martini Software. Kohavi received his BA \n",
      "from  the  Technion,  Israel.  He  was  the  General  Chair  for  KDD \n",
      "2004, co-chair of KDD 99s industrial track with Jim Gray, and \n",
      "co-chair of the KDD Cup 2000 with Carla Brodley. He was an \n",
      "invited speaker at the National Academy of Engineering in 2000, \n",
      "a keynote speaker at PAKDD 2001, an invited speaker at KDD \n",
      "2001s  industrial  track,  a  keynote  speaker  at  EC  2010  and  at \n",
      "Recsys 2012. His papers have over 26,000 citations and three of \n",
      "his  papers  are  in  the  top  1,000  most-cited  papers  in  Computer \n",
      "Science. \n",
      "\n",
      " \n",
      "\n",
      "Talk slides are available at: http://bit.ly/KDD2015Kohavi  \n",
      "\n",
      " \n",
      "Abstract \n",
      "The  Internet  provides  developers  of  connected  software, \n",
      "including web sites, applications, and devices, an unprecedented \n",
      "opportunity to accelerate innovation by evaluating ideas quickly \n",
      "and  accurately  using  trustworthy  controlled  experiments  (e.g., \n",
      "A/B  tests  and  their  generalizations).  From  front-end  user-\n",
      "interface  changes  to  backend  recommendation  systems  and \n",
      "relevance  algorithms,  from  search  engines  (e.g.,  Google, \n",
      "Microsofts  Bing,  Yahoo)  to  retailers  (e.g.,  Amazon,  eBay, \n",
      "Netflix,  Etsy)  to  social  networking  services  (e.g.,  Facebook, \n",
      "LinkedIn,  Twitter)  to  Travel  services  (e.g.,  Expedia,  Airbnb, \n",
      "Booking.com)  to  many  startups,  online  controlled  experiments \n",
      "are now utilized to make data-driven decisions at a wide range of \n",
      "companies.  While  the  theory  of  a  controlled  experiment  is \n",
      "simple, and dates back to Sir Ronald A. Fishers experiments at \n",
      "the Rothamsted Agricultural Experimental Station in England in \n",
      "the  1920s,  the  deployment  and  mining  of  online  controlled \n",
      "experiments at scale (e.g., hundreds of experiments run every day \n",
      "at Bing) and deployment of online controlled experiments across \n",
      "dozens of web sites and applications has taught us many lessons.  \n",
      "We  provide  an  introduction,  share  real  examples,  key  lessons, \n",
      "and cultural challenges. \n",
      "   \n",
      "Categories and Subject Descriptors \n",
      "G.3 Probability and Statistics/Experimental Design: controlled \n",
      "experiments; randomized experiments; A/B testing. \n",
      "General Terms \n",
      "Measurement; Design; Experimentation \n",
      " \n",
      "Keywords \n",
      "Controlled experiments; A/B testing; online experiments \n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Permission to make digital or hard copies of part or all of this work for personal or \n",
      "classroom  use  is  granted  without  fee  provided  that  copies  are  not  made  or \n",
      "distributed for profit or commercial advantage, and that copies bear this notice and \n",
      "the full citation on the first page. Copyrights for third-party components of this work \n",
      "must be honored. For all other uses, contact the owner/author(s). Copyright is held \n",
      "by the author/owner(s). \n",
      "KDD15, August 1013, 2015, Sydney, NSW, Australia. \n",
      "ACM 978-1-4503-3664-2/15/08.. \n",
      "http://dx.doi.org/10.1145/2783258.2785464 \n",
      "\n",
      "1\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"returns named entity chunks in a given text\"\n",
    "tagged = nltk.pos_tag(nltk.word_tokenize(re.sub('[\\s]',\" \", document)))\n",
    "entities = nltk.chunk.ne_chunk(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online,PERSON\n",
      "Ron Kohavi Distinguished Engineer,PERSON\n",
      "General Manager,ORGANIZATION\n",
      "Analysis,PERSON\n",
      "Experimentation Microsoft Bellevue,ORGANIZATION\n",
      "WA,ORGANIZATION\n",
      "USA,ORGANIZATION\n",
      "BIO Ronny Kohavi,ORGANIZATION\n",
      "Microsoft Distinguished Engineer,ORGANIZATION\n",
      "General Manager,ORGANIZATION\n",
      "Microsofts Analysis,PERSON\n",
      "Experimentation,ORGANIZATION\n",
      "Microsoft,PERSON\n",
      "Microsoft,PERSON\n",
      "Experimentation Platform,ORGANIZATION\n",
      "Amazon.com,ORGANIZATION\n",
      "Business Intelligence,ORGANIZATION\n",
      "Red Prairie,PERSON\n",
      "Blue Martini,PERSON\n",
      "Kohavi,PERSON\n",
      "MineSet,ORGANIZATION\n",
      "Silicon Graphics,PERSON\n",
      "Silicon Graphics,PERSON\n",
      "Stanford University,ORGANIZATION\n",
      "Machine,ORGANIZATION\n",
      "MineSet,ORGANIZATION\n",
      "Kohavi,PERSON\n",
      "Technion,ORGANIZATION\n",
      "General,ORGANIZATION\n",
      "KDD,ORGANIZATION\n",
      "KDD,ORGANIZATION\n",
      "Jim Gray,PERSON\n",
      "KDD,ORGANIZATION\n",
      "Carla Brodley,PERSON\n",
      "National Academy,ORGANIZATION\n",
      "PAKDD,ORGANIZATION\n",
      "KDD,ORGANIZATION\n",
      "EC,ORGANIZATION\n",
      "Recsys,ORGANIZATION\n",
      "Computer Science,ORGANIZATION\n",
      "Microsofts Bing,PERSON\n",
      "eBay,ORGANIZATION\n",
      "Netflix,PERSON\n",
      "LinkedIn,ORGANIZATION\n",
      "Twitter,PERSON\n",
      "Sir Ronald,PERSON\n",
      "Rothamsted,ORGANIZATION\n",
      "Bing,ORGANIZATION\n",
      "Subject Descriptors,PERSON\n",
      "Terms Measurement,PERSON\n",
      "Experimentation Keywords Controlled,ORGANIZATION\n",
      "Copyright,PERSON\n",
      "NSW,ORGANIZATION\n",
      "ACM,ORGANIZATION\n"
     ]
    }
   ],
   "source": [
    "# putting it in similar formats for visuals\n",
    "for l in entities:\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'PERSON':\n",
    "            print \" \".join(map(itemgetter(0), l))+\",\"+l.label()\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'ORGANIZATION':\n",
    "            print \" \".join(map(itemgetter(0), l))+\",\"+l.label()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I established two lists to hold the values that I extract from the text.  This itemgetter function will check for unique values.  First, I iterate over the extracted entities and see if the objects is a nltk.tree.Tree with a \"Person\" label.  If it is, and the length is equal to 1 (first or last name only), I append that value to the list. If it's larger, I iterate of the entity tree and pull out the first value only using itemgetter.  Then, I join the values from the list and append it to the destination list.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a list out of NLTK's standard NE chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Online', 'Ron Kohavi Distinguished Engineer', 'Analysis', 'Microsofts Analysis', 'Microsoft', 'Red Prairie', 'Blue Martini', 'Kohavi', 'Silicon Graphics', 'Jim Gray', 'Carla Brodley', 'Microsofts Bing', 'Netflix', 'Twitter', 'Sir Ronald', 'Subject Descriptors', 'Terms Measurement', 'Copyright']\n",
      "\n",
      "\n",
      "['General Manager', 'Experimentation Microsoft Bellevue', 'WA', 'USA', 'BIO Ronny Kohavi', 'Microsoft Distinguished Engineer', 'Experimentation', 'Experimentation Platform', 'Amazon.com', 'Business Intelligence', 'MineSet', 'Stanford University', 'Machine', 'Technion', 'General', 'KDD', 'National Academy', 'PAKDD', 'EC', 'Recsys', 'Computer Science', 'eBay', 'LinkedIn', 'Rothamsted', 'Bing', 'Experimentation Keywords Controlled', 'NSW', 'ACM']\n",
      "\n",
      "\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "persons = []\n",
    "organizations = []\n",
    "locations =[]\n",
    "\n",
    "for l in entities:\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'PERSON':\n",
    "            if len(l)== 1:\n",
    "                if l[0][0] in persons:\n",
    "                    pass\n",
    "                else:\n",
    "                    persons.append(l[0][0])\n",
    "            else:\n",
    "                if \" \".join(map(itemgetter(0), l)) in persons:\n",
    "                    pass\n",
    "                else:\n",
    "                    persons.append(\" \".join(map(itemgetter(0), l)))\n",
    "                    \n",
    "for o in entities:\n",
    "    if isinstance(o,nltk.tree.Tree):\n",
    "        if o.label() == 'ORGANIZATION':\n",
    "            if len(o)== 1:\n",
    "                if o[0][0] in organizations:\n",
    "                    pass\n",
    "                else:\n",
    "                    organizations.append(o[0][0])\n",
    "            else:\n",
    "                if \" \".join(map(itemgetter(0), o)) in organizations:\n",
    "                    pass\n",
    "                else:\n",
    "                    organizations.append(\" \".join(map(itemgetter(0), o)))\n",
    "                    \n",
    "for o in entities:\n",
    "    if isinstance(o,nltk.tree.Tree):\n",
    "        if o.label() == 'LOCATION':\n",
    "            if len(o)== 1:\n",
    "                if o[0][0] in locations:\n",
    "                    pass\n",
    "                else:\n",
    "                    locations.append(o[0][0])\n",
    "            else:\n",
    "                if \" \".join(map(itemgetter(0), o)) in locations:\n",
    "                    pass\n",
    "                else:\n",
    "                    locations.append(\" \".join(map(itemgetter(0), o)))\n",
    "                    \n",
    "                \n",
    "print persons\n",
    "print\n",
    "print\n",
    "print organizations\n",
    "print\n",
    "print\n",
    "print locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Manager\n",
      "Experimentation Microsoft Bellevue\n",
      "BIO Ronny Kohavi\n",
      "Microsoft Distinguished Engineer\n",
      "General Manager\n",
      "Experimentation Platform\n",
      "Business Intelligence\n",
      "Stanford University\n",
      "National Academy\n",
      "Computer Science\n",
      "Experimentation Keywords Controlled\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "for o in entities:\n",
    "    if isinstance(o,nltk.tree.Tree):\n",
    "        if o.label() == 'ORGANIZATION' or o.label() == 'GPE':\n",
    "            if len(o)>1:\n",
    "                print \" \".join(map(itemgetter(0), o))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to iterate over the extracted list of entities to get a better break between person's and their university name.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = [nltk.word_tokenize(l) for l in persons]\n",
    "fin = [nltk.chunk.ne_chunk(nltk.pos_tag(l)) for l in tokens]\n",
    "fin;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating lists of named entities from Stanford's NER model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function looks though an extracted stanford ner list, and finds continuous entitiy labels.  This should create first name, last name records of entities.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = StanfordNERTagger('/Users/linwood/stanford-corenlp-full-2015-04-20/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "       '/Users/linwood/stanford-corenlp-full-2015-04-20/stanford-corenlp-3.5.2.jar',\n",
    "       encoding='utf-8')\n",
    "tokenized_text = word_tokenize(re.sub('[\\s]',\" \", document))\n",
    "stanentities = st.tag(tokenized_text)\n",
    "\n",
    "\n",
    "def get_continuous_chunks(tagged_sent):\n",
    "    continuous_chunk = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for token, tag in tagged_sent:\n",
    "        if tag != \"O\":\n",
    "            current_chunk.append((token, tag))\n",
    "        else:\n",
    "            if current_chunk: # if the current chunk is not empty\n",
    "                continuous_chunk.append(current_chunk)\n",
    "                current_chunk = []\n",
    "    # Flush the final current_chunk into the continuous_chunk, if any.\n",
    "    if current_chunk:\n",
    "        continuous_chunk.append(current_chunk)\n",
    "    return continuous_chunk\n",
    "\n",
    "ne_tagged_sent = [('Rami', 'PERSON'), ('Eid', 'PERSON'), ('is', 'O'), ('studying', 'O'), ('at', 'O'), ('Stony', 'ORGANIZATION'), ('Brook', 'ORGANIZATION'), ('University', 'ORGANIZATION'), ('in', 'O'), ('NY', 'LOCATION')]\n",
    "\n",
    "named_entities = get_continuous_chunks(stanentities)\n",
    "named_entities_str = [\" \".join([token for token, tag in ne]) for ne in named_entities]\n",
    "named_entities_str_tag = [(\" \".join([token for token, tag in ne]), ne[0][1]) for ne in named_entities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Years Ron Kohavi Distinguished Engineer & General Manager , Analysis & Experimentation Microsoft Bellevue',\n",
       "  u'ORGANIZATION'),\n",
       " (u'USA', u'ORGANIZATION'),\n",
       " (u'Ronny Kohavi', u'PERSON'),\n",
       " (u'Microsoft', u'ORGANIZATION'),\n",
       " (u'General Manager', u'ORGANIZATION'),\n",
       " (u'Experimentation', u'ORGANIZATION'),\n",
       " (u'Microsoft', u'ORGANIZATION'),\n",
       " (u'Microsoft', u'ORGANIZATION'),\n",
       " (u'2006', u'DATE'),\n",
       " (u'Amazon.com', u'ORGANIZATION'),\n",
       " (u'Blue Martini Software', u'ORGANIZATION'),\n",
       " (u'2000', u'DATE'),\n",
       " (u'Red Prairie', u'ORGANIZATION'),\n",
       " (u'Blue Martini', u'ORGANIZATION'),\n",
       " (u'Kohavi', u'PERSON'),\n",
       " (u'Silicon Graphics', u'ORGANIZATION'),\n",
       " (u'Machine Learning', u'ORGANIZATION'),\n",
       " (u'Stanford University', u'ORGANIZATION'),\n",
       " (u'Machine Learning', u'ORGANIZATION'),\n",
       " (u'Blue Martini Software', u'ORGANIZATION'),\n",
       " (u'BA', u'ORGANIZATION'),\n",
       " (u'Technion', u'LOCATION'),\n",
       " (u'Israel', u'LOCATION'),\n",
       " (u'KDD 2004', u'ORGANIZATION'),\n",
       " (u'KDD', u'ORGANIZATION'),\n",
       " (u'Jim Gray', u'PERSON'),\n",
       " (u'KDD', u'ORGANIZATION'),\n",
       " (u'2000', u'DATE'),\n",
       " (u'Carla Brodley', u'PERSON'),\n",
       " (u'National Academy of Engineering', u'ORGANIZATION'),\n",
       " (u'2000', u'DATE'),\n",
       " (u'2001', u'DATE'),\n",
       " (u'KDD', u'ORGANIZATION'),\n",
       " (u'EC', u'ORGANIZATION'),\n",
       " (u'2012', u'DATE'),\n",
       " (u'Computer Science', u'ORGANIZATION'),\n",
       " (u'Google', u'ORGANIZATION'),\n",
       " (u'Microsofts Bing', u'PERSON'),\n",
       " (u'Yahoo', u'ORGANIZATION'),\n",
       " (u'Amazon', u'LOCATION'),\n",
       " (u'Netflix', u'ORGANIZATION'),\n",
       " (u'Etsy', u'ORGANIZATION'),\n",
       " (u'Facebook', u'LOCATION'),\n",
       " (u'Expedia', u'ORGANIZATION'),\n",
       " (u'Airbnb', u'LOCATION'),\n",
       " (u'Ronald A. Fishers', u'PERSON'),\n",
       " (u'Rothamsted Agricultural Experimental Station', u'ORGANIZATION'),\n",
       " (u'England', u'LOCATION'),\n",
       " (u'1920s', u'DATE'),\n",
       " (u'August 1013', u'DATE'),\n",
       " (u'2015', u'DATE'),\n",
       " (u'Sydney', u'LOCATION'),\n",
       " (u'NSW', u'ORGANIZATION'),\n",
       " (u'Australia', u'LOCATION')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities = get_continuous_chunks(stanentities)\n",
    "named_entities_str = [\" \".join([token for token, tag in ne]) for ne in named_entities]\n",
    "named_entities_str_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new =[word_tokenize(l) for l in persons]\n",
    "stan = [st.tag(l) for l in new]\n",
    "stan;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Ronny Kohavi',\n",
       " u'Kohavi',\n",
       " u'Jim Gray',\n",
       " u'Carla Brodley',\n",
       " u'Microsofts Bing',\n",
       " u'Ronald A. Fishers']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare=[]\n",
    "for l,m in named_entities_str_tag:\n",
    "    l=re.sub('(\\])',\" \",l).strip()\n",
    "    if m == 'PERSON':\n",
    "        if l in compare:\n",
    "            pass\n",
    "        else:\n",
    "            compare.append(l)\n",
    "    else:\n",
    "        pass\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list1 = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list2 = [i for i in xrange(7,17,1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7, 8, 9}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list1) & set(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parts_of_speech(corpus):\n",
    "    \"returns named entity chunks in a given text\"\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(corpus))\n",
    "    entities = nltk.chunk.ne_chunk(tagged)\n",
    "    # Another entity extractor\n",
    "    st = StanfordNERTagger('/Users/linwood/stanford-corenlp-full-2015-04-20/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "           '/Users/linwood/stanford-corenlp-full-2015-04-20/stanford-corenlp-3.5.2.jar',\n",
    "           encoding='utf-8')\n",
    "    tokenized_text = word_tokenize(corpus)\n",
    "    stanentities = st.tag(tokenized_text)\n",
    "    return entities\n",
    "def find_entities(chunks):\n",
    "    \"given list of tagged parts of speech, returns unique named entities\"\n",
    "\n",
    "    def traverse(tree):\n",
    "        \"recursively traverses an nltk.tree.Tree to find named entities\"\n",
    "        entity_names = []\n",
    "    \n",
    "        if hasattr(tree, 'node') and tree.node:\n",
    "            if tree.node == 'NE':\n",
    "                entity_names.append(' '.join([child[0] for child in tree]))\n",
    "            else:\n",
    "                for child in tree:\n",
    "                    entity_names.extend(traverse(child))\n",
    "    \n",
    "        return entity_names\n",
    "    \n",
    "    named_entities = []\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        entities = sorted(list(set([word for tree in chunk\n",
    "                            for word in traverse(tree)])))\n",
    "        for e in entities:\n",
    "            if e not in named_entities:\n",
    "                named_entities.append(e)\n",
    "    return named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(u'Years', u'ORGANIZATION'),\n",
       "  (u'Ron', u'ORGANIZATION'),\n",
       "  (u'Kohavi', u'ORGANIZATION'),\n",
       "  (u'Distinguished', u'ORGANIZATION'),\n",
       "  (u'Engineer', u'ORGANIZATION'),\n",
       "  (u'&', u'ORGANIZATION'),\n",
       "  (u'General', u'ORGANIZATION'),\n",
       "  (u'Manager', u'ORGANIZATION'),\n",
       "  (u',', u'ORGANIZATION'),\n",
       "  (u'Analysis', u'ORGANIZATION'),\n",
       "  (u'&', u'ORGANIZATION'),\n",
       "  (u'Experimentation', u'ORGANIZATION'),\n",
       "  (u'Microsoft', u'ORGANIZATION'),\n",
       "  (u'Bellevue', u'ORGANIZATION')],\n",
       " [(u'USA', u'ORGANIZATION')],\n",
       " [(u'Ronny', u'PERSON'), (u'Kohavi', u'PERSON')],\n",
       " [(u'Microsoft', u'ORGANIZATION')],\n",
       " [(u'General', u'ORGANIZATION'), (u'Manager', u'ORGANIZATION')],\n",
       " [(u'Experimentation', u'ORGANIZATION')],\n",
       " [(u'Microsoft', u'ORGANIZATION')],\n",
       " [(u'Microsoft', u'ORGANIZATION')],\n",
       " [(u'2006', u'DATE')],\n",
       " [(u'Amazon.com', u'ORGANIZATION')],\n",
       " [(u'Blue', u'ORGANIZATION'),\n",
       "  (u'Martini', u'ORGANIZATION'),\n",
       "  (u'Software', u'ORGANIZATION')],\n",
       " [(u'2000', u'DATE')],\n",
       " [(u'Red', u'ORGANIZATION'), (u'Prairie', u'ORGANIZATION')],\n",
       " [(u'Blue', u'ORGANIZATION'), (u'Martini', u'ORGANIZATION')],\n",
       " [(u'Kohavi', u'PERSON')],\n",
       " [(u'Silicon', u'ORGANIZATION'), (u'Graphics', u'ORGANIZATION')],\n",
       " [(u'Machine', u'ORGANIZATION'), (u'Learning', u'ORGANIZATION')],\n",
       " [(u'Stanford', u'ORGANIZATION'), (u'University', u'ORGANIZATION')],\n",
       " [(u'Machine', u'ORGANIZATION'), (u'Learning', u'ORGANIZATION')],\n",
       " [(u'Blue', u'ORGANIZATION'),\n",
       "  (u'Martini', u'ORGANIZATION'),\n",
       "  (u'Software', u'ORGANIZATION')],\n",
       " [(u'BA', u'ORGANIZATION')],\n",
       " [(u'Technion', u'LOCATION')],\n",
       " [(u'Israel', u'LOCATION')],\n",
       " [(u'KDD', u'ORGANIZATION'), (u'2004', u'DATE')],\n",
       " [(u'KDD', u'ORGANIZATION')],\n",
       " [(u'Jim', u'PERSON'), (u'Gray', u'PERSON')],\n",
       " [(u'KDD', u'ORGANIZATION')],\n",
       " [(u'2000', u'DATE')],\n",
       " [(u'Carla', u'PERSON'), (u'Brodley', u'PERSON')],\n",
       " [(u'National', u'ORGANIZATION'),\n",
       "  (u'Academy', u'ORGANIZATION'),\n",
       "  (u'of', u'ORGANIZATION'),\n",
       "  (u'Engineering', u'ORGANIZATION')],\n",
       " [(u'2000', u'DATE')],\n",
       " [(u'2001', u'DATE')],\n",
       " [(u'KDD', u'ORGANIZATION')],\n",
       " [(u'EC', u'ORGANIZATION')],\n",
       " [(u'2012', u'DATE')],\n",
       " [(u'Computer', u'ORGANIZATION'), (u'Science', u'ORGANIZATION')],\n",
       " [(u'Google', u'ORGANIZATION')],\n",
       " [(u'Microsofts', u'PERSON'), (u'Bing', u'PERSON')],\n",
       " [(u'Yahoo', u'ORGANIZATION')],\n",
       " [(u'Amazon', u'LOCATION')],\n",
       " [(u'Netflix', u'ORGANIZATION')],\n",
       " [(u'Etsy', u'ORGANIZATION')],\n",
       " [(u'Facebook', u'LOCATION')],\n",
       " [(u'Expedia', u'ORGANIZATION')],\n",
       " [(u'Airbnb', u'LOCATION')],\n",
       " [(u'Ronald', u'PERSON'), (u'A.', u'PERSON'), (u'Fishers', u'PERSON')],\n",
       " [(u'Rothamsted', u'ORGANIZATION'),\n",
       "  (u'Agricultural', u'ORGANIZATION'),\n",
       "  (u'Experimental', u'ORGANIZATION'),\n",
       "  (u'Station', u'ORGANIZATION')],\n",
       " [(u'England', u'LOCATION')],\n",
       " [(u'1920s', u'DATE')],\n",
       " [(u'August', u'DATE'), (u'1013', u'DATE')],\n",
       " [(u'2015', u'DATE')],\n",
       " [(u'Sydney', u'LOCATION')],\n",
       " [(u'NSW', u'ORGANIZATION')],\n",
       " [(u'Australia', u'LOCATION')]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting entities and creating lists using Polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from polyglot.text import Text\n",
    "e=Text(re.sub('[\\s]',\" \",document[:10000])).entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code iterates over the polyglot extracted entities and creates a list of person, locations, and organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import unicodedata\n",
    "\n",
    "def extraction(corpus):\n",
    "    \n",
    "    # extract entities from a single string; remove whitespace characters\n",
    "    try:\n",
    "        e = Text(re.sub('[\\s]',\" \",corpus)).entities\n",
    "    except:\n",
    "        pass #e = Text(re.sub(\"(r'(x0)',\" \",\"(re.sub('[\\s]',\" \",corpus)))).entities\n",
    "    \n",
    "    current_person =[]\n",
    "    persons =[]\n",
    "    current_org=[]\n",
    "    organizations=[]\n",
    "    current_loc=[]\n",
    "    locations=[]\n",
    "\n",
    "    for l in e:\n",
    "        if l.tag == 'I-PER':\n",
    "            for m in l:\n",
    "                current_person.append(unicodedata.normalize('NFKD', m).encode('ascii','ignore'))\n",
    "            else:\n",
    "                    if current_person: # if the current chunk is not empty\n",
    "                        persons.append(\" \".join(current_person))\n",
    "                        current_person = []\n",
    "        elif l.tag == 'I-ORG':\n",
    "            for m in l:\n",
    "                current_org.append(unicodedata.normalize('NFKD', m).encode('ascii','ignore'))\n",
    "            else:\n",
    "                    if current_org: # if the current chunk is not empty\n",
    "                        organizations.append(\" \".join(current_org))\n",
    "                        current_org = []\n",
    "        elif l.tag == 'I-LOC':\n",
    "            for m in l:\n",
    "                current_loc.append(unicodedata.normalize('NFKD', m).encode('ascii','ignore'))\n",
    "            else:\n",
    "                    if current_loc: # if the current chunk is not empty\n",
    "                        locations.append(\" \".join(current_loc))\n",
    "                        current_loc = []\n",
    "    results = {}\n",
    "    results['persons']=persons\n",
    "    results['organizations']=organizations\n",
    "    results['locations']=locations\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ron Kohavi',\n",
       " 'Ronny Kohavi',\n",
       " 'Blue Martini',\n",
       " 'Kohavi',\n",
       " 'Kohavi',\n",
       " 'Jim Gray',\n",
       " 'Carla Brodley',\n",
       " 'Microsofts Bing',\n",
       " 'Sir Ronald A',\n",
       " 'KDD15']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction(document)['persons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "document;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-fb550ba4ca58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mregexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"REFERENCES(.*)$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "regexp = re.compile(\"REFERENCES(.*)$\")\n",
    "references = Text(regexp.search(re.sub('[\\s]',\" \",document)).group(1)).entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-23526814b9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mregexp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"REFERENCES(.*)$\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "regexp1 = re.compile(\"REFERENCES(.*)$\")\n",
    "references = Text(regexp.search(re.sub('[\\s]',\" \",document)).group(1)).entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c4c9a6b386d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'persons'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "len(extraction(regexp.search(re.sub('[\\s]',\" \",document)).group(1))['persons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truth Sets to test extraction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6 authors\n",
      "\n",
      "There are 3 author organizations\n",
      "\n",
      "There are 7 author locations\n",
      "\n",
      "There are 152 authors in the references\n"
     ]
    }
   ],
   "source": [
    "#p19.pdf\n",
    "\n",
    "p19pdf_authors=['Tim Althoff*','Xin Luna Dong','Kevin Murphy','Safa Alai','Van Dang','Wei Zhang']\n",
    "p19pdf_author_organizations=['Computer Science Department','Stanford University','Google']\n",
    "p19pdf_author_locations=['Stanford, CA','Stanford','CA','Google','1600 Amphitheatre Parkway, Mountain View, CA 94043','1600 Amphitheatre Parkway','Mountain View']\n",
    "\n",
    "p19pdf_references_authors =['A. Ahmed', 'C. H. Teo', 'S. Vishwanathan','A. Smola','J. Allan', 'R. Gupta', 'V. Khandelwal',\n",
    "                           'D. Graus', 'M.-H. Peetz', 'D. Odijk', 'O. de Rooij', 'M. de Rijke','T. Huet', 'J. Biega', \n",
    "                            'F. M. Suchanek','H. Ji', 'T. Cassidy', 'Q. Li','S. Tamang', 'A. Kannan', 'S. Baker', 'K. Ramnath', \n",
    "                            'J. Fiss', 'D. Lin', 'L. Vanderwende',  'R. Ansary', 'A. Kapoor', 'Q. Ke', 'M. Uyttendaele',\n",
    "                           'S. M. Katz','A. Krause','D. Golovin','J. Leskovec', 'A. Krause', 'C. Guestrin', 'C. Faloutsos', \n",
    "                            'J. VanBriesen','N. Glance','J. Li','C. Cardie','J. Li','C. Cardie','C.-Y. Lin','H. Lin','J. A. Bilmes'\n",
    "                           'X. Ling','D. S. Weld', 'A. Mazeika', 'T. Tylenda','G. Weikum','M. Minoux', 'G. L. Nemhauser', 'L. A. Wolsey',\n",
    "                            'M. L. Fisher','R. Qian','D. Shahaf', 'C. Guestrin','E. Horvitz','T. Althoff', 'X. L. Dong', 'K. Murphy', 'S. Alai',\n",
    "                            'V. Dang','W. Zhang','R. A. Baeza-Yates', 'B. Ribeiro-Neto', 'D. Shahaf', 'J. Yang', 'C. Suen', 'J. Jacobs', 'H. Wang', 'J. Leskovec',\n",
    "                           'W. Shen', 'J. Wang', 'J. Han','D. Bamman', 'N. Smith','K. Bollacker', 'C. Evans', 'P. Paritosh', 'T. Sturge', 'J. Taylor',\n",
    "                           'R. Sipos', 'A. Swaminathan', 'P. Shivaswamy', 'T. Joachims','K. Sprck Jones','G. Calinescu', 'C. Chekuri', 'M. Pl','J. Vondrk',\n",
    "                           'F. M. Suchanek', 'G. Kasneci','G. Weikum', 'J. Carbonell' ,'J. Goldstein','B. Carterette', 'P. N. Bennett', 'D. M. Chickering',\n",
    "                            'S. T. Dumais','A. Dasgupta', 'R. Kumar','S. Ravi','Q. X. Do', 'W. Lu', 'D. Roth','X. Dong', 'E. Gabrilovich', 'G. Heitz', 'W. Horn', \n",
    "                            'N. Lao', 'K. Murphy',  'T. Strohmann', 'S. Sun','W. Zhang', 'M. Dubinko', 'R. Kumar', 'J. Magnani', 'J. Novak', 'P. Raghavan','A. Tomkins',\n",
    "                           'U. Feige','F. M. Suchanek','N. Preda','R. Swan','J. Allan', 'T. Tran', 'A. Ceroni', 'M. Georgescu', 'K. D. Naini', 'M. Fisichella',\n",
    "                           'T. A. Tuan', 'S. Elbassuoni', 'N. Preda','G. Weikum','Y. Wang', 'M. Zhu', 'L. Qu', 'M. Spaniol', 'G. Weikum',\n",
    "                           'G. Weikum', 'N. Ntarmos', 'M. Spaniol', 'P. Triantallou', 'A. A. Benczr',  'S. Kirkpatrick', 'P. Rigaux','M. Williamson',\n",
    "                           'X. W. Zhao', 'Y. Guo', 'R. Yan', 'Y. He','X. Li']\n",
    "p19pdf_allauthors=['Tim Althoff*','Xin Luna Dong','Kevin Murphy','Safa Alai','Van Dang','Wei Zhang','A. Ahmed', 'C. H. Teo', 'S. Vishwanathan','A. Smola','J. Allan', 'R. Gupta', 'V. Khandelwal',\n",
    "                           'D. Graus', 'M.-H. Peetz', 'D. Odijk', 'O. de Rooij', 'M. de Rijke','T. Huet', 'J. Biega', \n",
    "                            'F. M. Suchanek','H. Ji', 'T. Cassidy', 'Q. Li','S. Tamang', 'A. Kannan', 'S. Baker', 'K. Ramnath', \n",
    "                            'J. Fiss', 'D. Lin', 'L. Vanderwende',  'R. Ansary', 'A. Kapoor', 'Q. Ke', 'M. Uyttendaele',\n",
    "                           'S. M. Katz','A. Krause','D. Golovin','J. Leskovec', 'A. Krause', 'C. Guestrin', 'C. Faloutsos', \n",
    "                            'J. VanBriesen','N. Glance','J. Li','C. Cardie','J. Li','C. Cardie','C.-Y. Lin','H. Lin','J. A. Bilmes'\n",
    "                           'X. Ling','D. S. Weld', 'A. Mazeika', 'T. Tylenda','G. Weikum','M. Minoux', 'G. L. Nemhauser', 'L. A. Wolsey',\n",
    "                            'M. L. Fisher','R. Qian','D. Shahaf', 'C. Guestrin','E. Horvitz','T. Althoff', 'X. L. Dong', 'K. Murphy', 'S. Alai',\n",
    "                            'V. Dang','W. Zhang','R. A. Baeza-Yates', 'B. Ribeiro-Neto', 'D. Shahaf', 'J. Yang', 'C. Suen', 'J. Jacobs', 'H. Wang', 'J. Leskovec',\n",
    "                           'W. Shen', 'J. Wang', 'J. Han','D. Bamman', 'N. Smith','K. Bollacker', 'C. Evans', 'P. Paritosh', 'T. Sturge', 'J. Taylor',\n",
    "                           'R. Sipos', 'A. Swaminathan', 'P. Shivaswamy', 'T. Joachims','K. Sprck Jones','G. Calinescu', 'C. Chekuri', 'M. Pl','J. Vondrk',\n",
    "                           'F. M. Suchanek', 'G. Kasneci','G. Weikum', 'J. Carbonell' ,'J. Goldstein','B. Carterette', 'P. N. Bennett', 'D. M. Chickering',\n",
    "                            'S. T. Dumais','A. Dasgupta', 'R. Kumar','S. Ravi','Q. X. Do', 'W. Lu', 'D. Roth','X. Dong', 'E. Gabrilovich', 'G. Heitz', 'W. Horn', \n",
    "                            'N. Lao', 'K. Murphy',  'T. Strohmann', 'S. Sun','W. Zhang', 'M. Dubinko', 'R. Kumar', 'J. Magnani', 'J. Novak', 'P. Raghavan','A. Tomkins',\n",
    "                           'U. Feige','F. M. Suchanek','N. Preda','R. Swan','J. Allan', 'T. Tran', 'A. Ceroni', 'M. Georgescu', 'K. D. Naini', 'M. Fisichella',\n",
    "                           'T. A. Tuan', 'S. Elbassuoni', 'N. Preda','G. Weikum','Y. Wang', 'M. Zhu', 'L. Qu', 'M. Spaniol', 'G. Weikum',\n",
    "                           'G. Weikum', 'N. Ntarmos', 'M. Spaniol', 'P. Triantallou', 'A. A. Benczr',  'S. Kirkpatrick', 'P. Rigaux','M. Williamson',\n",
    "                           'X. W. Zhao', 'Y. Guo', 'R. Yan', 'Y. He','X. Li']\n",
    "\n",
    "print \"There are %r authors\" % len(p19pdf_authors)\n",
    "print  # white space\n",
    "print \"There are %r author organizations\" %len(p19pdf_author_organizations)\n",
    "print \n",
    "print \"There are %r author locations\" % len(p19pdf_author_locations)\n",
    "print  \n",
    "print \"There are %r authors in the references\" %len(p19pdf_references_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 authors\n",
      "\n",
      "There are 6 author organizations\n",
      "\n",
      "There are 8 author locations\n",
      "\n",
      "There are 106 authors in the references\n"
     ]
    }
   ],
   "source": [
    "#p29.pdf\n",
    "\n",
    "p29pdf_authors=['Laurent Amsaleg','Stéphane Girard','Oussama Chelly','Teddy Furon','Michael E. Houle','Ken-ichi Kawarabayashi',\n",
    "               'Michael Nett']\n",
    "p29pdf_author_organizations=['Equipe LINKMEDIA','Campus Universitaire de Beaulieu','CNRS/IRISA Rennes','National Institute of Informatics',\n",
    "                             'Equipe MISTIS INRIA','Google']\n",
    "p29pdf_author_locations=['Campus Universitaire de Beaulieu','35042 Rennes Cedex, France','France','-1-2 Hitotsubashi, Chiyoda-ku Tokyo 101-8430, Japan',\n",
    "                        'Japan','6-10-1 Roppongi, Minato-ku Tokyo 106-6126','Inovallée, 655, Montbonnot 38334 Saint-Ismier Cedex','Tokyo']\n",
    "\n",
    "p29pdf_references_authors =['A. A. Balkema','L. de Haan','N. Bingham', 'C. Goldie','J. Teugels','N. Boujemaa', 'J. Fauqueur', 'M. Ferecatu', 'F. Fleuret',\n",
    "                            'V. Gouet', 'B. LeSaux','H. Sahbi','C. Bouveyron', 'G. Celeux', 'S. Girard','J. Bruske', 'G. Sommer',\n",
    "                           'F. Camastra','A. Vinciarelli','S. Coles','J. Costa' ,'A. Hero','T. de Vries', 'S. Chawla','M. E. Houle',\n",
    "                           'R. A. Fisher','L. H. C. Tippett','M. I. Fraga Alves', 'L. de Haan','T. Lin','M. I. Fraga Alves', 'M. I. Gomes','L. de Haan',\n",
    "                           'B. V. Gnedenko',' A. Gupta', 'R. Krauthgamer','J. R. Lee','A. Gupta', 'R. Krauthgamer','J. R. Lee','M. Hein','J.-Y. Audibert',\n",
    "                           'B. M. Hill','M. E. Houle','M. E. Houle','M. E. Houle','M. E. Houle', 'H. Kashima', 'M. Nett','M. E. Houle', 'X. Ma', 'M. Nett',\n",
    "                            'V. Oria','M. E. Houle', 'X. Ma', 'V. Oria','J. Sun','M. E. Houle','M. Nett','H. Jegou', 'R. Tavenard', 'M. Douze','L. Amsaleg',\n",
    "                           'I. Jollie','D. R. Karger','M. Ruhl','J. Karhunen','J. Joutsensalo','Y. LeCun', 'L. Bottou', 'Y. Bengio', 'P. Haner',\n",
    "                           'J. Pickands, III','C. R. Rao','S. T. Roweis','L. K. Saul','A. Rozza', 'G. Lombardi', 'C. Ceruti', 'E. Casiraghi', 'P. Campadelli',\n",
    "                           'B. Scholkopf', 'A. J. Smola','K.-R. Muller','U. Shaft','R. Ramakrishnan',' F. Takens','J. Tenenbaum', 'V. D. Silva','J. Langford',\n",
    "                           'J. B. Tenenbaum', 'V. De Silva','J. C. Langford','J. B. Tenenbaum', 'V. De Silva','J. C. Langford','J. Venna','S. Kaski',\n",
    "                           'P. Verveer','R. Duin','J. von Brunken', 'M. E. Houle', 'A. Zimek','J. von Brunken', 'M. E. Houle','A. Zimek']\n",
    "\n",
    "p29pdf_allauthors=['Laurent Amsaleg','Stéphane Girard','Oussama Chelly','Teddy Furon','Michael E. Houle','Ken-ichi Kawarabayashi',\n",
    "               'Michael Nett','A. A. Balkema','L. de Haan','N. Bingham', 'C. Goldie','J. Teugels','N. Boujemaa', 'J. Fauqueur', 'M. Ferecatu', 'F. Fleuret',\n",
    "                            'V. Gouet', 'B. LeSaux','H. Sahbi','C. Bouveyron', 'G. Celeux', 'S. Girard','J. Bruske', 'G. Sommer',\n",
    "                           'F. Camastra','A. Vinciarelli','S. Coles','J. Costa' ,'A. Hero','T. de Vries', 'S. Chawla','M. E. Houle',\n",
    "                           'R. A. Fisher','L. H. C. Tippett','M. I. Fraga Alves', 'L. de Haan','T. Lin','M. I. Fraga Alves', 'M. I. Gomes','L. de Haan',\n",
    "                           'B. V. Gnedenko',' A. Gupta', 'R. Krauthgamer','J. R. Lee','A. Gupta', 'R. Krauthgamer','J. R. Lee','M. Hein','J.-Y. Audibert',\n",
    "                           'B. M. Hill','M. E. Houle','M. E. Houle','M. E. Houle','M. E. Houle', 'H. Kashima', 'M. Nett','M. E. Houle', 'X. Ma', 'M. Nett',\n",
    "                            'V. Oria','M. E. Houle', 'X. Ma', 'V. Oria','J. Sun','M. E. Houle','M. Nett','H. Jegou', 'R. Tavenard', 'M. Douze','L. Amsaleg',\n",
    "                           'I. Jollie','D. R. Karger','M. Ruhl','J. Karhunen','J. Joutsensalo','Y. LeCun', 'L. Bottou', 'Y. Bengio', 'P. Haner',\n",
    "                           'J. Pickands, III','C. R. Rao','S. T. Roweis','L. K. Saul','A. Rozza', 'G. Lombardi', 'C. Ceruti', 'E. Casiraghi', 'P. Campadelli',\n",
    "                           'B. Scholkopf', 'A. J. Smola','K.-R. Muller','U. Shaft','R. Ramakrishnan',' F. Takens','J. Tenenbaum', 'V. D. Silva','J. Langford',\n",
    "                           'J. B. Tenenbaum', 'V. De Silva','J. C. Langford','J. B. Tenenbaum', 'V. De Silva','J. C. Langford','J. Venna','S. Kaski',\n",
    "                           'P. Verveer','R. Duin','J. von Brunken', 'M. E. Houle', 'A. Zimek','J. von Brunken', 'M. E. Houle','A. Zimek']\n",
    "\n",
    "\n",
    "print \"There are %r authors\" % len(p29pdf_authors)\n",
    "print  # white space\n",
    "print \"There are %r author organizations\" %len(p29pdf_author_organizations)\n",
    "print \n",
    "print \"There are %r author locations\" % len(p29pdf_author_locations)\n",
    "print  \n",
    "print \"There are %r authors in the references\" %len(p29pdf_references_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(compare) & set(p29pdf_allauthors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p29pdf_allauthors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('[\\s]',\" \",document)[9300:10500]\n",
    "#regexp.search(re.sub('[\\s]',\" \",document)).group(1)[4900:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'locations': ['Microsoft Bellevue',\n",
       "  'WA',\n",
       "  'USA',\n",
       "  'Red Prairie',\n",
       "  'Israel',\n",
       "  'England',\n",
       "  'Sydney',\n",
       "  'NSW',\n",
       "  'Australia'],\n",
       " 'organizations': ['Microsoft',\n",
       "  'Microsoft',\n",
       "  'Microsoft',\n",
       "  'Business Intelligence',\n",
       "  'Blue Martini Software',\n",
       "  'Blue',\n",
       "  'Silicon Graphics',\n",
       "  'Graphics',\n",
       "  'Stanford University',\n",
       "  'Blue Martini Software',\n",
       "  'Technion',\n",
       "  'National Academy of Engineering',\n",
       "  'Computer Science',\n",
       "  'Google',\n",
       "  'Yahoo',\n",
       "  'eBay',\n",
       "  'Netflix',\n",
       "  'Facebook',\n",
       "  'ACM'],\n",
       " 'persons': ['Ron Kohavi',\n",
       "  'Ronny Kohavi',\n",
       "  'Blue Martini',\n",
       "  'Kohavi',\n",
       "  'Kohavi',\n",
       "  'Jim Gray',\n",
       "  'Carla Brodley',\n",
       "  'Microsofts Bing',\n",
       "  'Sir Ronald A',\n",
       "  'KDD15']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ron Kohavi',\n",
       " 'Ronny Kohavi',\n",
       " 'Blue Martini',\n",
       " 'Kohavi',\n",
       " 'Kohavi',\n",
       " 'Jim Gray',\n",
       " 'Carla Brodley',\n",
       " 'Microsofts Bing',\n",
       " 'Sir Ronald A',\n",
       " 'KDD15']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class entities(object):\n",
    "  def __init__(self):\n",
    "    self.persons = extraction(document)['persons']\n",
    "    self.organizations = extraction(document)['organizations']\n",
    "\n",
    "my_shape = entities()\n",
    "my_shape.persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to extract emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ohavi@outlook.com',)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(get_emails(document))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get only the Title and Author Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-22d7a6917072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(.*)(?=ABSTRACT)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mabstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "p=re.compile('(.*)(?=ABSTRACT)')\n",
    "abstract = p.search(re.sub('[\\s]',\" \",document)).group(1)\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get Title Only (or most of it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Online Controlled Experiments: '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=re.compile('(.+)(\\\\n\\\\n)')\n",
    "q=re.compile('(?<=\\\\n\\\\n)(.+?)(?=\\\\n\\\\n)')\n",
    "#p.search(document).group(1)+\" \"+q.search(document).group(1)\n",
    "p.search(document).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get Abstract only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p= re.compile('(?<=ABSTRACT)(.+)(?=Categories and Subject Descriptors)')\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p= re.compile('(?<=ABSTRACT)(.+)(?=Categories and Subject Descriptors)')\n",
    "try:\n",
    "    p.search(re.sub('[\\s]',\" \",document)).group(1)\n",
    "except AttributeError:\n",
    "    p=re.compile('(?<=abstract)(.+)(?=categories and subject descriptors)')\n",
    "    abstract=p.search(re.sub('[\\s]',\" \",lower)).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  the  internet  provides  developers  of  connected  software,  including web sites, applications, and devices, an unprecedented  opportunity to accelerate innovation by evaluating ideas quickly  and  accurately  using  trustworthy  controlled  experiments  (e.g.,  a/b  tests  and  their  generalizations).  from  front-end  user- interface  changes  to  backend  recommendation  systems  and  relevance  algorithms,  from  search  engines  (e.g.,  google,  microsofts  bing,  yahoo)  to  retailers  (e.g.,  amazon,  ebay,  netflix,  etsy)  to  social  networking  services  (e.g.,  facebook,  linkedin,  twitter)  to  travel  services  (e.g.,  expedia,  airbnb,  booking.com)  to  many  startups,  online  controlled  experiments  are now utilized to make data-driven decisions at a wide range of  companies.  while  the  theory  of  a  controlled  experiment  is  simple, and dates back to sir ronald a. fishers experiments at  the rothamsted agricultural experimental station in england in  the  1920s,  the  deployment  and  mining  of  online  controlled  experiments at scale (e.g., hundreds of experiments run every day  at bing) and deployment of online controlled experiments across  dozens of web sites and applications has taught us many lessons.   we  provide  an  introduction,  share  real  examples,  key  lessons,  and cultural challenges.      '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get keywords only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-aaa2345ec775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?<=keywords)(.+)(?=introduction)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mkeywords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "p= re.compile('(?<=Keywords)(.+)(?=INTRODUCTION)')\n",
    "try:\n",
    "    p.search(re.sub('[\\s]',\" \",document)).group(1)\n",
    "except AttributeError:\n",
    "    p=re.compile('(?<=keywords)(.+)(?=introduction)')\n",
    "    keywords=p.search(re.sub('[\\s]',\" \",lower)).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p= re.compile('(?<=ABSTRACT)(.+)(?=Categories and Subject Descriptors)')\n",
    "try:\n",
    "    p.search(re.sub('[\\s]',\" \",document)).group(1)\n",
    "except AttributeError:\n",
    "    p=re.compile('(?<=abstract)(.+)(?=categories and subject descriptors)')\n",
    "    abstract=p.search(re.sub('[\\s]',\" \",lower)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get Categories and Subject Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= re.compile('(?<=Categories and Subject Descriptors)(.+)(?=Keywords)')\n",
    "re.findall('\\[(.*?)\\]',p.search(re.sub('[\\s]',\" \",document)).group(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get Body only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-469515cdab4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?<=INTRODUCTION)(.+)(?=ACKNOWLEDGMENTS)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "p= re.compile('(?<=INTRODUCTION)(.+)(?=ACKNOWLEDGMENTS)')\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get CONCLUSION only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-5a638f2e829e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?<=CONCLUSION)(.+)(?=ACKNOWLEDGMENTS)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "p= re.compile('(?<=CONCLUSION)(.+)(?=ACKNOWLEDGMENTS)')\n",
    "p.search(re.sub('[\\s]',\" \",document).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to get References only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-d85c820ab59e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?<=REFERENCES)(.+)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "p= re.compile('(?<=REFERENCES)(.+)')\n",
    "references = p.search(re.sub('[\\s]',\" \",document)).group(1)\n",
    "p.search(re.sub('[\\s]',\" \",document)).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'online controlled experiments: \\n\\nlessons from running a/b/n tests for 12 years \\n\\n \\n\\nron kohavi \\n\\ndistinguished engineer & general manager,  \\n\\nanalysis & experimentation \\n\\nmicrosoft \\n\\nbellevue, wa, usa \\n\\nronkohavi@outlook.com  \\n\\nin \\n\\nhe \\n\\n2005 \\n\\n \\nbio \\nronny  kohavi is  a  microsoft \\ndistinguished  engineer  and \\nfor \\nthe  general  manager \\nand \\nmicrosofts  analysis \\nat \\nexperimentation \\nteam \\nmicrosoft. \\njoined \\nmicrosoft \\nand \\nfounded  the  experimentation \\nplatform  team  in  2006.  he \\nwas previously the director of \\ndata  mining  and  personalization  at  amazon.com,  and  the  vice \\npresident  of  business  intelligence  at  blue  martini  software, \\nwhich  went  public  in  2000,  and  later  acquired  by  red  prairie. \\nprior to joining blue martini, kohavi managed mineset project, \\nsilicon  graphics  award-winning  product  for  data  mining  and \\nvisualization. he joined silicon graphics after getting a ph.d. in \\nmachine  learning  from  stanford  university,  where  he  led  the \\nmlc++  project,  the  machine  learning  library  in  c++  used  in \\nmineset and at blue martini software. kohavi received his ba \\nfrom  the  technion,  israel.  he  was  the  general  chair  for  kdd \\n2004, co-chair of kdd 99s industrial track with jim gray, and \\nco-chair of the kdd cup 2000 with carla brodley. he was an \\ninvited speaker at the national academy of engineering in 2000, \\na keynote speaker at pakdd 2001, an invited speaker at kdd \\n2001s  industrial  track,  a  keynote  speaker  at  ec  2010  and  at \\nrecsys 2012. his papers have over 26,000 citations and three of \\nhis  papers  are  in  the  top  1,000  most-cited  papers  in  computer \\nscience. \\n\\n \\n\\ntalk slides are available at: http://bit.ly/kdd2015kohavi  \\n\\n \\nabstract \\nthe  internet  provides  developers  of  connected  software, \\nincluding web sites, applications, and devices, an unprecedented \\nopportunity to accelerate innovation by evaluating ideas quickly \\nand  accurately  using  trustworthy  controlled  experiments  (e.g., \\na/b  tests  and  their  generalizations).  from  front-end  user-\\ninterface  changes  to  backend  recommendation  systems  and \\nrelevance  algorithms,  from  search  engines  (e.g.,  google, \\nmicrosofts  bing,  yahoo)  to  retailers  (e.g.,  amazon,  ebay, \\nnetflix,  etsy)  to  social  networking  services  (e.g.,  facebook, \\nlinkedin,  twitter)  to  travel  services  (e.g.,  expedia,  airbnb, \\nbooking.com)  to  many  startups,  online  controlled  experiments \\nare now utilized to make data-driven decisions at a wide range of \\ncompanies.  while  the  theory  of  a  controlled  experiment  is \\nsimple, and dates back to sir ronald a. fishers experiments at \\nthe rothamsted agricultural experimental station in england in \\nthe  1920s,  the  deployment  and  mining  of  online  controlled \\nexperiments at scale (e.g., hundreds of experiments run every day \\nat bing) and deployment of online controlled experiments across \\ndozens of web sites and applications has taught us many lessons.  \\nwe  provide  an  introduction,  share  real  examples,  key  lessons, \\nand cultural challenges. \\n   \\ncategories and subject descriptors \\ng.3 probability and statistics/experimental design: controlled \\nexperiments; randomized experiments; a/b testing. \\ngeneral terms \\nmeasurement; design; experimentation \\n \\nkeywords \\ncontrolled experiments; a/b testing; online experiments \\n \\n\\n \\n\\npermission to make digital or hard copies of part or all of this work for personal or \\nclassroom  use  is  granted  without  fee  provided  that  copies  are  not  made  or \\ndistributed for profit or commercial advantage, and that copies bear this notice and \\nthe full citation on the first page. copyrights for third-party components of this work \\nmust be honored. for all other uses, contact the owner/author(s). copyright is held \\nby the author/owner(s). \\nkdd15, august 1013, 2015, sydney, nsw, australia. \\nacm 978-1-4503-3664-2/15/08.. \\nhttp://dx.doi.org/10.1145/2783258.2785464 \\n\\n1\\x0c'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p= re.compile('(?<=REFERENCES)(.+)')\n",
    "p.document.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to count the number of references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-37235227d2c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\[(.*?)\\]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "create a match of all references by counting the number of integers enclosed by brackets (i.e. '[2]').  \n",
    "\n",
    "This is how references are labeled in the research papers\n",
    "'''\n",
    "\n",
    "len(re.findall('\\[(.*?)\\]',regexp.search(re.sub('[\\s]',\" \",document)).group(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import googleapiclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NLTK standard chunk comparison to hand labeled entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abstract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-783c1b370796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"returns named entity chunks in a given text\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtesttagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstract\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtestentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesttagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmachinelist_persons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'abstract' is not defined"
     ]
    }
   ],
   "source": [
    "\"returns named entity chunks in a given text\"\n",
    "testtagged = nltk.pos_tag(nltk.word_tokenize(abstract))\n",
    "testentities = nltk.chunk.ne_chunk(testtagged)\n",
    "\n",
    "machinelist_persons=[]\n",
    "machinelist_orgs=[]\n",
    "\n",
    "for l in testentities:\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'PERSON':\n",
    "            if \" \".join(map(itemgetter(0), l)) not in machinelist_persons:\n",
    "                machinelist_persons.append(\" \".join(map(itemgetter(0), l)))\n",
    "\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'ORGANIZATION':\n",
    "            if \" \".join(map(itemgetter(0), l)) not in machinelist_orgs:\n",
    "                machinelist_orgs.append(\" \".join(map(itemgetter(0), l)))\n",
    "print len(machinelist_persons),len(p19pdf_authors)                \n",
    "set(machinelist_persons) & set(p19pdf_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'machinelist_persons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-e171aac41282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mwww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdnuggets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfaq\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m '''\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minboth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachinelist_persons\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp19pdf_authors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mext_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachinelist_persons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrue_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp19pdf_authors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'machinelist_persons' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using explanations from this page to estimate precision and recall\n",
    "http://www.kdnuggets.com/faq/precision-recall.html\n",
    "'''\n",
    "inboth = float(len(set(machinelist_persons) & set(p19pdf_authors)))\n",
    "ext_len=float(len(machinelist_persons))\n",
    "true_len=float(len(p19pdf_authors))\n",
    "\n",
    "d = {'Predicted Negative': [0,0], 'Predicted Positive': [ext_len-true_len,inboth]}\n",
    "metrics = pd.DataFrame(d, index=['Negative Cases','Positive Cases'])\n",
    "print \"The \\\"Accuracy\\\" is %r.\\nThe \\\"Recall\\\" is %r.\\nThe \\\"Precision\\\" is %r.\" % ((round((inboth/ext_len)*100)),(round(inboth/true_len)*100),(inboth/(inboth+ext_len-true_len))*100)\n",
    "#,,\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'references' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0161f0a99672>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"returns named entity chunks in a given text\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtesttagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtestentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesttagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmachinelist_persons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'references' is not defined"
     ]
    }
   ],
   "source": [
    "\"returns named entity chunks in a given text\"\n",
    "testtagged = nltk.pos_tag(nltk.word_tokenize(references))\n",
    "testentities = nltk.chunk.ne_chunk(testtagged)\n",
    "\n",
    "machinelist_persons=[]\n",
    "machinelist_orgs=[]\n",
    "\n",
    "for l in testentities:\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'PERSON':\n",
    "            if \" \".join(map(itemgetter(0), l)) not in machinelist_persons:\n",
    "                machinelist_persons.append(\" \".join(map(itemgetter(0), l)))\n",
    "\n",
    "    if isinstance(l,nltk.tree.Tree):\n",
    "        if l.label() == 'ORGANIZATION':\n",
    "            if \" \".join(map(itemgetter(0), l)) not in machinelist_orgs:\n",
    "                machinelist_orgs.append(\" \".join(map(itemgetter(0), l)))\n",
    "print len(machinelist_persons),len(p19pdf_references_authors)                \n",
    "set(machinelist_persons) & set(p19pdf_references_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'machinelist_persons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-47459f09cc21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mmachinelist_persons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mp19pdf_references_authors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp19pdf_references_authors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'machinelist_persons' is not defined"
     ]
    }
   ],
   "source": [
    "print machinelist_persons\n",
    "print p19pdf_references_authors\n",
    "p19pdf_references_authors.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'machinelist_persons' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-c36cfc2d47cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mwww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdnuggets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfaq\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m '''\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minboth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachinelist_persons\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp19pdf_references_authors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mext_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachinelist_persons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrue_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp19pdf_references_authors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'machinelist_persons' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Using explanations from this page to estimate precision and recall\n",
    "http://www.kdnuggets.com/faq/precision-recall.html\n",
    "'''\n",
    "inboth = float(len(set(machinelist_persons) & set(p19pdf_references_authors)))\n",
    "ext_len=float(len(machinelist_persons))\n",
    "true_len=float(len(p19pdf_references_authors))\n",
    "\n",
    "d = {'Predicted Negative': [0,0], 'Predicted Positive': [abs(ext_len-true_len),inboth]}\n",
    "metrics = pd.DataFrame(d, index=['Negative Cases','Positive Cases'])\n",
    "print \"The \\\"Accuracy\\\" is %r.\\nThe \\\"Recall\\\" is %r.\\nThe \\\"Precision\\\" is %r.\" % ((round((inboth/ext_len)*100)),(round(inboth/true_len)*100),(inboth/(inboth+ext_len-true_len))*100)\n",
    "#,,\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
