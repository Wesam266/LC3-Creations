{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import urllib2\n",
    "import unicodedata\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "wordnet_tags = ['n', 'v', 'a', 's', 'r']\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The main code, built from testing, is in the cell immediately below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from http://brandonrose.org/clustering\n",
    "\n",
    "\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmer = WordNetLemmatizer()\n",
    "wordnet_tags = ['n', 'v', 'a', 's', 'r']\n",
    "\n",
    "def tokenize_and_stem_n_lem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    ''' \n",
    "    Old code gave seperate lists for lem and stem; I lemmed, then just stemmed the result\n",
    "    #stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    #lems = [lemmer.lemmatize(l) for l in filtered_tokens]\n",
    "    '''\n",
    "    stems = [stemmer.stem(lemmer.lemmatize(l)) for l in filtered_tokens]\n",
    "    \n",
    "    #return stems,lems\n",
    "    return stems\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-6703759500bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0msection\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mr'\\n\\n([^]]*)\\n\\n(Abstract|ABSTRACT)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "path        = os.path.abspath(os.getcwd())\n",
    "TESTDIR     = os.path.normpath(os.path.join(os.path.expanduser(\"~\"),\"projects\",\"LC3-Creations\", \"examples\",\"KDDsample\"))\n",
    "\n",
    "corpus = {}\n",
    "\n",
    "start_time = time.time()\n",
    "for dirName, subdirList, fileList in walk(TESTDIR):\n",
    "        for fileName in fileList:\n",
    "            if fileName.startswith('p') and fileName.endswith('.pdf'):\n",
    "                a = unicode(subprocess.check_output(['pdf2txt.py',str(os.path.normpath(os.path.join(TESTDIR,fileName)))]),errors='ignore')\n",
    "                document = unicodedata.normalize('NFKD', a).encode('ascii','ignore')\n",
    "                # Getting title\n",
    "                title = re.findall(\"^[^\\\\n\\\\n]+\",document)[0]\n",
    "                \n",
    "                # Getting the abstract\n",
    "                try:\n",
    "                    abstract = re.findall (r'\\n\\n(Abstract|ABSTRACT)([^]]*)\\n\\n',document[:2000])[0]\n",
    "                except IndexError:\n",
    "                    abstract = re.findall (r'(Abstract|ABSTRACT)([^]]*)',document[:2000])[0][1]\n",
    "                except IndexError:\n",
    "                    abstract = \"We are unable to parse the abstract of %s, with title %s; Check file for abstract\" % (fileName,title)\n",
    "\n",
    "                else :\n",
    "                    abstract = \"We are unable to parse the abstract of %s, with title %s; Check file for abstract\" % (fileName,title)\n",
    "\n",
    "                if isinstance(abstract, tuple):\n",
    "                    abstract = re.sub('[\\s]',\" \",abstract[1])\n",
    "                elif isinstance(abstract,list):\n",
    "                    abstract = re.sub('[\\s]',\" \",abstract[1])\n",
    "                elif isinstance(abstract,str):\n",
    "                    abstract = re.sub('[\\s]',\" \", abstract)\n",
    "                \n",
    "                else:\n",
    "                    abstract = \"We are unable to parse the abstract of %s, with title %s; Check file for abstract\" % (fileName,title)\n",
    "\n",
    "        \n",
    "                \n",
    "                    \n",
    "                # Extracts section with names and email addresses only\n",
    "                section  = re.findall (r'\\n\\n([^]]*)\\n\\n(Abstract|ABSTRACT)',document[:2000])\n",
    "\n",
    "                type(section[0][0])\n",
    "\n",
    "                if isinstance(section, list):\n",
    "                    section = re.sub('[\\s]',\" \",section[0][0])\n",
    "                else:\n",
    "                    section = re.sub('[\\s]',\" \",section)\n",
    "                    \n",
    "\n",
    "                # Code to extract entities from top section of pdf and store a relationship tree\n",
    "                tagged = nltk.pos_tag(nltk.word_tokenize(section))\n",
    "                entities = nltk.chunk.ne_chunk(tagged)\n",
    "                \n",
    "                # Another entity extractor\n",
    "                st = StanfordNERTagger('/Users/linwood/stanford-corenlp-full-2015-04-20/classifiers/english.conll.4class.distsim.crf.ser.gz',\n",
    "\t\t\t\t\t   '/Users/linwood/stanford-corenlp-full-2015-04-20/stanford-corenlp-3.5.2.jar',\n",
    "\t\t\t\t\t   encoding='utf-8')\n",
    "                tokenized_text = word_tokenize(section)\n",
    "                stanentities = st.tag(tokenized_text)\n",
    "                \n",
    "                # Calls function to lemmatize and stem the document; stores the result\n",
    "                tokenize_and_stem_n_lem(abstract);\n",
    "\n",
    "                '''\n",
    "                This gives seperate lists for lem and stem; replacement code stores combin\n",
    "                # Creates the json document format to store the files\n",
    "                corpus[str(fileName)]={}\n",
    "                corpus[str(fileName)]={'Title':title,'Abstract':abstract,'Entities':entities, \n",
    "                                       \"Stanford ER\":stanentities, \"Stems\": tokenize_and_stem_n_lem(abstract)[0], \n",
    "                                      \"Lems\": tokenize_and_stem_n_lem(abstract)[1]}'''\n",
    "                \n",
    "                # Creates the json document format to store the files\n",
    "                corpus[str(fileName)]={}\n",
    "                corpus[str(fileName)]={'Title':title,'Abstract':abstract,'Entities':entities, \n",
    "                                       \"Stanford ER\":stanentities, \"Stems\": tokenize_and_stem_n_lem(abstract)}\n",
    "                print \".\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Inferring Gas Consumption and Pollution Emissions of   Vehicles throughout a City    Jingbo Shang1,2,*, Yu Zheng2,+, Wenzhu Tong3,2,*, Eric Chang2, Yong Yu1   1Dept. of Computer Science & Engineering, Shanghai Jiao Tong University   2Microsoft Research, No.5 Danling Street, Haidian District, Beijing 100080, China   3Computer School of Wuhan University, Wuhan, Hubei, China   {v-jishan, yuzheng, v-wetong, echang}@microsoft.com, yyu@apex.sjtu.edu.cn    a direct result, is strategically important to modeling urban traffic, gas  consumption, and pollution emission, in order to help save energy and  protect the environment [19]. For instance, if we were to know the gas  consumption  for  traveling  any  road  segment  at  any  time,  we  can  suggest cost-efficient driving routes and identify road segments where  gas  is  being  wasted  significantly.  Such  knowledge  can  impact  authorities  decision  making  on  improving  a  citys  transportation  infrastructure.  In  the  meantime,  real-time  estimation  of  emissions  from  vehicles  can  enable  pollution  alerts.  In  the  long  run,  this  information  can  help  diagnose  the  root  cause  of  air  pollution.  For  example, whether reducing traffic of vehicles will significantly lower  air  pollution  is  still  a  controversial  subject  in  developing  countries.  There is no clear method to determine the percentage of PM2.5 in a  given air space that is generated by vehicles.   As shown in Figure 1, we instantly estimate the total gas consumption  and the corresponding pollution emission of vehicles traveling on any  road  segment  in  a  city  at  a  particular  time  slot,  using  the  GPS  trajectories  of  a  sample  of  vehicles  (e.g.  taxicabs).  Specifically,  we  first infer the average travel speed on each road segment, using sparse  GPS data from a few vehicles. We then estimate the traffic volume  (i.e., the number of vehicles/minute) traversing a road segment based  on  the  average  travel  speed  and  other  factors,  such  as  weather  and  type of roads. Finally, the travel speed and traffic volume of a road  segment are used to calculate the total gas consumption and vehicle  emissions on the road, allowing us to determine the pulse of traffic,  energy consumption, and emission levels throughout a city.      Figure 1. Goals of our Work   Our work faces three main challenges. 1) Data sparseness: We can  only have a sample of traffic data, as many vehicles do not have a  GPS sensor installed. Moreover, in a given time slot, only a small  portion of road segments are traversed by GPS-equipped vehicles.  For  example,  according  to  the  statistic  on  Beijings  taxi  data,  on  average,  only  13%  of  road  segments  are  traversed  by  taxis  in  an  hour. 2) From travel speeds to traffic volumes: The traffic volume  on a road segment depends on multiple factors, such as the current  travel speeds and density of vehicles, the length, shape, and capacity  of the road, as well as weather conditions. Unfortunately, it is not  easy to obtain enough training data to learn the mapping between  traffic  volumes  and  these  factors.  In  addition,  the  occurrence  of  sampled vehicles on roads may be skewed from that of the entire set  of vehicles. For example, observing more taxis on a road segment  does not mean  more occurrences of other vehicles. Consequently,  we can neither use the sampled traffic as a training set to learn the  + Yu Zheng is the correspondence author of this paper.     ABSTRACT  This  paper  instantly  infers  the  gas  consumption  and  pollution  emission of vehicles traveling on a citys road network in a current  time  slot,  using  GPS  trajectories  from  a  sample  of  vehicles  (e.g.,  taxicabs). The knowledge can be used to suggest cost-efficient driving  routes  as  well  as  identifying  road  segments  where  gas  has  been  wasted  significantly.  The  instant  estimation  of  the  emissions  from  vehicles can enable pollution alerts and help diagnose the root cause  of air pollution in the long run. In our method, we first compute the  travel speed of each road segment using the GPS trajectories received  recently. As many road segments are not traversed by trajectories (i.e.,  data  sparsity),  we  propose  a Travel  Speed Estimation  (TSE)  model  based  on  a  context-aware  matrix  factorization  approach.  TSE  leverages features learned from other data sources, e.g., map data and  historical trajectories, to deal with the data sparsity problem. We then  propose a Traffic Volume Inference (TVI) model to infer the number  of  vehicles  passing  each  road  segment  per  minute.  TVI  is  an  unsupervised  Bayesian  Network  that  incorporates  multiple  factors,  such as travel speed, weather conditions and geographical features of  a road. Given the travel speed and traffic volume of a road segment,  gas consumption and emissions can be calculated based on existing  environmental theories. We evaluate our method based on extensive  experiments using GPS trajectories generated by over 32,000 taxis in  Beijing  over  a  period  of  two  months.  The  results  demonstrate  the  advantages of our method over baselines, validating the contribution  of its components and finding interesting discoveries for the benefit of  society.    Categories and Subject Descriptors  H.2.8  [Database  Management]:  Database  Applications  -  data  mining, Spatial databases and GIS;  Keywords  Urban computing; traffic pollution; gas consumption; trajectories.  1.  INTRODUCTION  While consuming a huge amount of gas, vehicles traveling in cities  also generate  greenhouse gases (GHG), like CO2, and air pollution,  e.g.,  PM2.5.  Figuring  out  the  answers  to  challenging  questions  of  emissions, such as how much gas is consumed by vehicles in a given  city or on a particular road, or what volume of PM2.5 is generated as  *The paper was done when the first and third authors were an intern in  Microsoft  Research  under  the  supervision  of  the  second  author  who    contributed the main idea and algorithms of this paper.  Permission  to  make  digital  or  hard  copies  of  all  or  part  of  this  work  for  personal or classroom use is granted without fee provided that copies are not  made or distributed for profit or commercial advantage and that copies bear  this notice and the full citation on the first page. Copyrights for components  of this work owned by others than ACM must be honored. Abstracting with  credit is permitted. To copy otherwise, or republish, to post on servers or to  redistribute to lists, requires prior specific permission and/or a fee. Request  permissions from permissions@acm.org.  KDD14, August 2427, 2014, New York, New York, USA.  Copyright  2014 ACM 978-1-4503-2956-9/14/08$15.00  http://dx.doi.org/10.1145/2623330.2623653   1027 aforementioned  mapping,  nor  simply  multiply  a  factor  to  the  volume of sampled vehicles. 3) Real-time and citywide: To enable a  valuable  service,  e.g.,  enabling  air  pollution  alerts,  it  is  better  to  have  real-time  information  about  traffic,  gas  consumption  and  emissions, with a city scale. This calls for a knowledge discovery  ability that is both efficient (i.e., providing information on the entire  city  a  few  minutes  after  receiving  the  data)  and  effective  (e.g.,  consider  the  traffic  conditions  not  only  on  a  road  segment  individually but also on a road network systematically).    Given  the  aforementioned  challenges,  existing  methods  for  estimating the traffic conditions on a single road do not work well.  For instance, traffic detection solutions [5, 7, 13] using loop sensors  on roads and surveillance cameras are difficult to scale up to cover  an entire city. Some approaches, e.g., fundamental diagram [1, 3],  need a lot of training data, or are not applicable to a complex road  network  [2].  Conventional  models  using  floating  car  data  to  estimate traffic conditions do not tackle the data sparsity problem  well,  which  cannot  be  simply  solved  by  interpolation  [18]  or  just  using historical patterns [2] either (refer to the related work section  for details). Our research makes three main contributions:    We  infer  the  travel  speed  of  a  road  segment  throughout  a  city,  using  a  model  (titled  TSE)  based  on  a  context-aware  matrix  factorization.  TSE  incorporates  historical  traffic  patterns, the correlation between different times of day, and  physical  features  of  a  road  (such  as  the  length),  in  a  framework  of  collaborative  filtering,  to  tackle  the  data  sparsity problem.      We  propose  an  unsupervised  graphical  model  for  traffic  volume inference (titled TVI) on a road segment in a given  time  slot.  TVI  considers  multiple  factors,  such  as  physical  features  of  a  road,  travel  speed,  variance  in  speed,  and  weather conditions, in a Bayesian Network.      We evaluate the effectiveness and efficiency of our method  with extensive experiments, using GPS trajectories generated  by  32,670  taxis  over  a  period  of  two  months.  Our  method  outperforms baselines significantly. We have share a sample  of the experimental data at [20].    The rest of the paper is organized as follows. Section 2 overviews  our method. We detail the methodology in Section 3 and evaluate  our  approach  in  Section  4.  After  reviewing  related  work  in  Section 5, we conclude this paper in Section 6.  2.  OVERVIEW   Definition  1:  Trajectory.  A  spatial  trajectory (cid:1846)(cid:1870) is  a  sequence  of  time-ordered  spatial  points, (cid:1846)(cid:1870):(cid:1868)(cid:2869)(cid:1372)(cid:1868)(cid:2870)(cid:1372)(cid:1710)(cid:1372)(cid:1868)(cid:3041) ,  where  each  point has a geospatial coordinate set (cid:1864) and a timestamp (cid:1872), (cid:1868)(cid:3404)(cid:4666)(cid:1864),(cid:1872)(cid:4667).  Definition 3: Road Network. A road network (cid:1844)(cid:1840) is comprised of a  set  of  road  segments (cid:4668)(cid:1870)(cid:4669) connected  among  each  other  in  a  graph  format. Each road segment (cid:1870) is a directed edge having two terminal  (cid:1870).(cid:1864)(cid:1857)(cid:1866), a level (cid:1870).(cid:1864)(cid:1857)(cid:1874) (e.g., a highway or a street), a direction (cid:1870).(cid:1856)(cid:1861)(cid:1870)  (e.g., one-way or bi-directional)  and the number of lanes (cid:1870).(cid:1866).    Definition 2: POI. A point of interest POI is a venue (like a school  and shopping mall) in the physical world, having a name, address,  coordinates, category, and other attributes.    points, a list of intermediate points describing the segment, a length   Section 3. We first map the GPS trajectories received in the current  time slot onto a road network using a map-matching algorithm [6],  and then calculate the travel speed on the road segments covered by  trajectories. We also extract road features from map data, like Points  of  Interests  (POI)  and  road  networks,  and  traffic  patterns  from  historical trajectories. The road features and traffic patterns are used  as context to improve the accuracy of travel speed estimation, which  computes the average travel speeds of road segments that are absent  of  trajectory  data  through  a  context-aware  matrix-factorization  approach.  The  road  features  and  inferred  travel  speed  as  well  as  other  features  (like  weather  conditions)  are  then  employed  as  observations in a graphical model to infer traffic volumes on a road  segment. Finally, employing existing equations from environmental  science,  we  calculate  the  gas  consumption  and  emission  on  each  road segment.   Gas Consum.   GHG Emission  Weather w  Volume N  Energy and Emission Calculation  Traffic Volume Inference  Speed V  Speed Variance Dv  Travel Speed Estimation  Road Features   fr  POI Features fp  Road Traffic  Patterns Mr  Historical Region  Traffic Patterns MG  Instant Traffic on   Roads Mr  Instant Regional   Traffic MG  Context Extraction  RoadNetworks  Trajectory Mapping  PointsofInterests  GPSTrajectories  Figure 2. Framework of our method      3.  METHODOLOGY  3.1  Trajectory Mapping  The trajectory mapping component receives GPS trajectories from  vehicles and projects each trajectory onto a road network using a  map-matching algorithm [6]. This component also calculates the  average travel speed for road segments currently covered by the  trajectory  data  received.  As  shown  in  Figure  3,  three  vehicles   travel  four  road  segments (cid:1870)(cid:2869) , (cid:1870)(cid:2870) , (cid:1870)(cid:2871)  and (cid:1870)(cid:2872) ,  generating  three  trajectories (cid:1846)(cid:1870)(cid:2869), (cid:1846)(cid:1870)(cid:2870),  and (cid:1846)(cid:1870)(cid:2871) .  After  map-matching,  each  point                 (cid:1874)(cid:2869)(cid:3404)(cid:1830)(cid:1861)(cid:1871)(cid:1872)(cid:4666)(cid:1868)(cid:2869).(cid:1864),(cid:1868)(cid:2870).(cid:1864)(cid:4667) |(cid:1868)(cid:2870).(cid:1872)(cid:3398)(cid:1868)(cid:2869).(cid:1872)| where (cid:1830)(cid:1861)(cid:1871)(cid:1872) is  a  function  calculating  the  road  network  distance                                  (cid:1874)(cid:1191)(cid:3404) (cid:1874)(cid:3036)(cid:3041)(cid:3036) (cid:1866) ;                              (2)                                  (cid:1856)(cid:3049)(cid:3404) (cid:4666)(cid:3049)(cid:3284)(cid:2879)(cid:3049)(cid:3364)(cid:4667)(cid:3118)(cid:3041) (cid:3041)(cid:3036)  from  a  trajectory is  mapped  onto  a  road  segment.  Then,  we  can  calculate the travel speed for each point based on Equation 1,    ,          (1)   between two points. Likewise, we can calculate the travel speed  for  other  points  and  then  compute  the  average  and  variance  of  travel speed of a road segment as Equation 2 and 3.    ,                          (3)   Figure 2 presents the framework of our method, which is comprised  of  five  major  components:  trajectory  mapping,  context  extraction,  travel  speed  estimation,  traffic  volume  inference,  and  energy  &  emission  calculations,  which  will  be  elaborated  respectively  in   Figure 3. Calculating the average travel speed of a road segment      1028 For instance, the average travel speed of (cid:1870)(cid:2869) is (cid:4666)(cid:1874)(cid:2869)(cid:3397)(cid:1874)(cid:2870)(cid:3397)(cid:1874)(cid:2872)(cid:4667)3 . To   ensure the quality of the calculated average speed, we require a road  segment to be traveled by vehicles for certain times (e.g., 3 times in  the experiments). Otherwise, the road segment is considered absent  of data and will later be inferred by our method. The average speed  and variance formulate a road segments traffic conditions, which  will  be  used  in  both  travel  speed  estimation  and  traffic  volume  inference components.   3.2  Context Extraction  This component generates two categories of knowledge. One is a set  of physical features extracted from POI and road network databases,  describing the geographic contexts of a road segment. The other is  the traffic patterns learned from historical trajectories, revealing the  correlation between different time slots.  Physical features of a road: As shown in Figure 3 A), the physical   features of a road segment (cid:1870) further consist of three parts:    r6  r5  r1  d1  r2  r3  r4  g1  g5  g9  g13  g2  g6  g10  g14  g3  g7  g11  g15  g4  g8  g12  g16  f1 f2  fk  fr  fp  fg  r1 r2 Z= r3  A)  Mr=  t1 t2 ti tj tm  r1  (22, 6.1) (12, 4.5)  Null  ri  rn (v1,i, dv1,i) (v2,i, dv2,i) (vi,i, dvi,i) (vi,j, dvi,j) (vn,i, dvn,i)  B) g1 g2 g16 14 50 22 27 16 8  26 72 49  23 6 9 42 2 11  7  t1 t2 ti tj tm  Mg=     61  91  rn  (48, 8.6) (17, 1.6)  Figure 3. Context Extraction   terminals  (e.g.,  within  a  disc  of  200  meters),  we  calculate  the  distribution  of  POIs  across  10  categories:  Schools,  Companies  &  Offices, Banks & ATMs, Malls & Shopping, Restaurants, Gas stations  & Vehicle services, Parking, Hotels, Residences, Transportation, and  Entertainment  & Living Services. The 10 POI categories are mined  from POI and road network datasets, co-occurring with road segments   1) Road network features (cid:1858)(cid:3045): (cid:1870).(cid:1864)(cid:1857)(cid:1866), (cid:1870).(cid:1864)(cid:1857)(cid:1874), (cid:1870).(cid:1856)(cid:1861)(cid:1870), (cid:1870).(cid:1866), the number of  connections, and a tortuosity (cid:2028), which is the ratio between (cid:1870).(cid:1864)(cid:1857)(cid:1866) and  the  Euclidian  distance  between  the  two  terminals  of (cid:1870)  .  In  this  example, (cid:1870)(cid:2869) has  two  connections  on  one  terminal  and  three  on  the  other; (cid:1870)(cid:2869).(cid:2028)(cid:3404)(cid:1870)(cid:2869).(cid:1864)(cid:1857)(cid:1866) (cid:1856)(cid:2869) .    2) POI features (cid:1858)(cid:3043): For a road segment (cid:1870), from the POIs around (cid:1870)s  most frequently. For instance, the (cid:1858)(cid:3043) of (cid:1870)(cid:2869) is (0, 0, 1, 1, 0, 1, 0, 0, 2, 0).  3) Global position feature (cid:1858)(cid:3034): This feature basically indicates which  city  into  4(cid:3400)4  grids,  the (cid:1858)(cid:3034) of  a  road  segment  located  in (cid:1859)(cid:2874) can  be  geographically close to each other, their (cid:1858)(cid:3034) will be similar.   We place (cid:1858)(cid:3045), (cid:1858)(cid:3043), and (cid:1858)(cid:3034) of each road segment into a matrix (cid:1852), where  feature. (cid:1858)(cid:3045) and (cid:1858)(cid:3043) represent the local features of a road segment, while  (cid:1858)(cid:3034) captures a road segments global geo-position. The general idea is  that road segments with similar (cid:1858)(cid:3045) and (cid:1858)(cid:3043)could share a similar traffic  condition.  If  their (cid:1858)(cid:3034) is  also  similar  (i.e.,  close  to  each  other),  they   represented  by  the  IDs  of  its  eight  neighbors,  i.e.,  (1,1,1,0,1,0,1,0,  1,1,1,0,0,0,0,0), as illustrated in Figure 3 B). If two road segments are   each row denotes a road segment and a column represents a kind of   part of the city a road segment falls in. For instance, if we partition a   The feature is further normalized into a distribution.    would have a more similar traffic condition.    level but denser representation of traffic patterns. To model the traffic   traversing a specific grid cell in a particular time slot, calculated based   changing  over  time  of  day.  Specifically,  as  shown  in  the  bottom  of   Traffic  Patterns:  While  the  physical  features  of  a  road  segment  are   particular time slot, calculated based on the historical data over a long  period (e.g., 2 months). The similarity between two rows reveals the   grained traffic patterns in a city, where a row stands for a time slot and a  column denotes a grid cell. For example, as shown in Figure 3 B), we  partition  Beijing  into  16  disjoint  grids,  each  of  which  contains  some   static, we also extract from historical trajectories two matrices (cid:1839)(cid:3045) and  (cid:1839)(cid:3034) that  respectively  represent  fine  and  coarse-grained  traffic  patterns  Figure 3, a row of (cid:1839)(cid:3045) denotes a time slot (e.g., 2pm-2:10pm), and a  column  stands  for  a  road  segment.  Each  entry  in (cid:1839)(cid:3045)  contains  the  average traffic condition ((cid:1874)(cid:1191), (cid:1856)(cid:1874)) on a particular road segment and in a  correlation between two time slots. Likewise, matrix (cid:1839)(cid:3008) reflects coarse- road  segments.  Each  entry  of (cid:1839)(cid:3008) is  the  average  number  of  vehicles  on the data over a long period of time. In contrast to (cid:1839)(cid:3045), (cid:1839)(cid:3034) is a higher- patterns  more  accurately,  we  can  maintain (cid:1839)(cid:3045)  and (cid:1839)(cid:3034)  which  This component estimates the traffic condition ((cid:1874)(cid:1191), (cid:1856)(cid:1874)) on each road  As illustrated in Figure 4, we formulate three matrices (cid:1850), (cid:1851), and (cid:1852),  where (cid:1850)(cid:3404)(cid:1839)(cid:1314)(cid:3045)||(cid:1839)(cid:3045) , (cid:1851)(cid:3404)(cid:1839)(cid:1314)(cid:3008)||(cid:1839)(cid:3008) ,  and (cid:1852)  contains  the  physical  features of roads. Specifically, (cid:1839)(cid:1314)(cid:3045) and (cid:1839)(cid:1314)(cid:3008) are matrices built based  on  the  recent  trajectory  data  received  from (cid:1872)(cid:3036) to (cid:1872)(cid:3037) (e.g.,  1pm-3pm),  where (cid:1872)(cid:3037) is  the  current  time  slot. (cid:1839)(cid:3045) and (cid:1839)(cid:3008) are  the  traffic  pattern  time slots from (cid:1872)(cid:3036) to (cid:1872)(cid:3037). In the implementation, we build (cid:1839)(cid:3045) and (cid:1839)(cid:3008)  of an entire day in advance and retrieve the entries from (cid:1872)(cid:3036) to (cid:1872)(cid:3037) when  constructing (cid:1850) and (cid:1851) (refer  to  the  broken  line  box  in  the  bottom  of  missing values in row (cid:1872)(cid:3037) of (cid:1839)(cid:1314)(cid:3045) with the help of  (cid:1839)(cid:3045),  (cid:1851) and (cid:1852).   correspond to workdays and holidays, respectively.  3.3  Travel Speed Estimation (TSE)   Figure  3).  Given  the  above  settings,  the  goal  of  estimating  current  traffic conditions on a road network can be converted into filling the   segment,  using  recently  received  trajectory  data  and  contexts  (extracted in Section 3.2) in a framework of collaborative filtering.    matrices built over a long period of time, corresponding to the same   g1 g2 g16  g1 g2 g16  MG  MG  titi+1 tj  r1 r2  rn  r1 r2  rn  Mr  Mr  titi+1 tj  f1 f2  fk  fr  fp  fg  r1 r2 rn     Y  Z  X  Figure 4. Context-aware Matrix Factorization-based CF   few  non-zero  entries  due  to  the  data  sparsity  problem.  So,  the   into  the  product  of  two  low-rank  matrices  based  on  the  non-zero   enough. To tackle the data sparsity problem, we incorporate another   Basically, we can achieve this goal through solely factorizing (cid:1839)(cid:1314)(cid:3045)  entries  of (cid:1839)(cid:1314)(cid:3045).  However,  as  we  mentioned  before, (cid:1839)(cid:1314)(cid:3045)   has  very  approximation  of (cid:1839)(cid:1314)(cid:3045)  by  solely  factorizing  itself  is  not  accurate  two  context  matrices (cid:1851)  and (cid:1852) ,  where (cid:1851)  models  the  temporal  correlations  between  different  time  slots  and (cid:1852)  models  the  Intuitively, (cid:1839)(cid:1314)(cid:3045) and (cid:1839)(cid:1314)(cid:3008) represent current traffic conditions in a city,  and   (cid:1839)(cid:3045)  and (cid:1839)(cid:3008)  denote  historical  traffic  patterns.  Putting (cid:1839)(cid:1314)(cid:3045)  together with (cid:1839)(cid:3045) (and (cid:1839)(cid:1314)(cid:3008) together with (cid:1839)(cid:3008)(cid:4667) reveals the deviation  Additionally, (cid:1839)(cid:3045) and (cid:1839)(cid:3008) built over a long period of time are much  of (cid:1850) and (cid:1851) can help tackle the data sparsity problem.   More specifically, we can decompose (cid:1850),  (cid:1851) and (cid:1852) as follows:      (cid:1851)(cid:3406)(cid:1846)(cid:3400)(cid:4666)(cid:1833);(cid:1833)(cid:4667)(cid:3021);  (cid:1850)(cid:3406)(cid:1846)(cid:3400)(cid:4666)(cid:1844);(cid:1844)(cid:4667)(cid:3021);  (cid:1852)(cid:3406)(cid:1844)(cid:3400)(cid:1832)(cid:3021),     (4)   of current traffic conditions from the corresponding traffic patterns.   denser than the recently received data. As a result, the formulation   geographical  similarity  between  two  different  road  segments.   1029 the   improve   the  accuracy  of   closed-form solutions to minimize the objective function. Therefore,  we  iteratively  minimize  the  objective  function  according  to  the  gradient descent algorithm shown in Figure 5. Specifically, we have   objective function (5) control the loss in matrix factorization, and the  last term controls the regularization over the factorized matrices so as  to prevent over fitting.  In general, the objective function is not jointly   where (cid:1846),(cid:1833),(cid:1844), and (cid:1832) are low-rank matrices representing the latent  factors; (cid:1850) and (cid:1851) share  latent  factor (cid:1846); (cid:1850) and (cid:1852) share  latent  factor  (cid:1844). As (cid:1851) and (cid:1852) can be built from other data sources, e.g., historical  trajectories  and  map  data,  they  are  much  denser  than (cid:1850) .  Consequently, (cid:1851)  and (cid:1852)  can  approximation, if we factorize  (cid:1850),  (cid:1851) and (cid:1852) collaboratively. After  the  factorization,  we  can  recover (cid:1850) through  the  production  of (cid:1846)  and (cid:4666)(cid:1844);(cid:1844)(cid:4667)(cid:3021). The objective function is defined as Equation 5.  (cid:1838)(cid:4666)(cid:1846),(cid:1844),(cid:1833),(cid:1832)(cid:4667)(cid:3404)(cid:2869)(cid:2870)||(cid:1851)(cid:3398)(cid:1846)(cid:4666)(cid:1833);(cid:1833)(cid:4667)(cid:3021)||(cid:2870)(cid:3397)(cid:3090)(cid:3117)(cid:2870)||(cid:1850)(cid:3398)(cid:1846)(cid:4666)(cid:1844);(cid:1844)(cid:4667)(cid:3021)||(cid:2870)(cid:3397) (cid:3090)(cid:3118)(cid:2870)||(cid:1852)(cid:3398)(cid:1844)(cid:1832)(cid:3021)||(cid:2870)(cid:3397)(cid:3090)(cid:3119)(cid:2870)(cid:4666)||(cid:1846)||(cid:2870)(cid:3397)||(cid:1844)||(cid:2870)(cid:3397)||(cid:1833)||(cid:2870)(cid:3397)||(cid:1832)||(cid:2870)(cid:4667),           (5)  where (cid:1510)(cid:1510) denotes  the  Frobenius  norm.  The  first  three  terms  in  the  convex  to  all  the  variables (cid:1844), (cid:1846), (cid:1833),  and (cid:1832).  That  is,  we  cannot  get  the gradients (denoted as(cid:1487)) for each variable:    (cid:1487)(cid:3021)(cid:1838)(cid:3404)(cid:4670)(cid:1846)(cid:4666)(cid:1833);(cid:1833)(cid:4667)(cid:3021)(cid:3398)(cid:1851)(cid:4671)(cid:4666)(cid:1833);(cid:1833)(cid:4667)(cid:3021)(cid:3397)(cid:2019)(cid:2869)(cid:4666)(cid:1846)(cid:4666)(cid:1844);(cid:1844)(cid:4667)(cid:3021)(cid:3398)(cid:1850)(cid:4667)(cid:4666)(cid:1844);(cid:1844)(cid:4667)(cid:3021)(cid:3397)(cid:2019)(cid:2871)(cid:1846),            (cid:1487)(cid:3019)(cid:1838)(cid:3404)(cid:2019)(cid:2869)(cid:4670)(cid:1846)(cid:4666)(cid:1844);(cid:1844)(cid:4667)(cid:3021)(cid:3398)(cid:1850)(cid:4671)(cid:3021)(cid:1846)(cid:3397)(cid:2019)(cid:2870)(cid:4666)(cid:1844)(cid:1832)(cid:3021)(cid:3398)(cid:1852)(cid:4667)(cid:1832)(cid:3021)(cid:3397)(cid:2019)(cid:2871)(cid:1844),            (cid:1487)(cid:3008)(cid:1838)(cid:3404)(cid:3435)(cid:1846)(cid:4666)(cid:1833);(cid:1833)(cid:4667)(cid:1846)(cid:3398)(cid:1851)(cid:3439)(cid:3021)(cid:1846)(cid:3397)(cid:2019)(cid:2871)(cid:1833),                                          (6)         (cid:1487)(cid:3007)(cid:1838)(cid:3404)(cid:2019)(cid:2870)(cid:4666)(cid:1844)(cid:1832)(cid:3021)(cid:3398)(cid:1852)(cid:4667)(cid:3021)(cid:1846)(cid:3397)(cid:2019)(cid:2871)(cid:1832).  Input: Incomplete matrix (cid:1850), context matrices (cid:1851) and (cid:1852)   Output: Complete matrix (cid:1850).  1.  (cid:1872)(cid:3404)1;  2.  While ((cid:1872)(cid:3407)(cid:1840) and (cid:1838)(cid:3047)(cid:3398)(cid:1838)(cid:3047)(cid:2878)(cid:2869)(cid:3408)(cid:2035))         // N is #(max iterations)  3.       Get the gradients (cid:1487)(cid:3021)(cid:3295), (cid:1487)(cid:3019)(cid:3295), (cid:1487)(cid:3008)(cid:3295), and (cid:1487)(cid:3007)(cid:3295) by Eq.(6);  4.       (cid:2011)(cid:3404)1;            (cid:1838)(cid:4666)(cid:1846)(cid:3047)(cid:3398)(cid:2011)(cid:1487)(cid:3021)(cid:3295),(cid:1844)(cid:3047)(cid:3398)(cid:2011)(cid:1487)(cid:3019)(cid:3295),(cid:1833)(cid:3047)(cid:3398)(cid:2011)(cid:1487)(cid:3008)(cid:3295),(cid:1832)(cid:3047)(cid:3398)(cid:2011)(cid:1487)(cid:3007)(cid:3295)(cid:4667)(cid:3410)(cid:1838)(cid:4666)(cid:1846)(cid:3047),(cid:1844)(cid:3047),(cid:1833)(cid:3047),(cid:1832)(cid:3047)(cid:4667)   6.                     (cid:2011)(cid:3404)(cid:2011) 2 ;        // search for the maximal step size  7.       (cid:1846)(cid:3047)(cid:2878)(cid:2869)(cid:3404)(cid:1846)(cid:3047)(cid:3398)(cid:2011)(cid:1487)(cid:3021)(cid:3295), (cid:1844)(cid:3047)(cid:2878)(cid:2869)(cid:3404)(cid:1844)(cid:3047)(cid:3398)(cid:2011)(cid:1487)(cid:3019)(cid:3295) and   8.       (cid:1833)(cid:3047)(cid:2878)(cid:2869)(cid:3404)(cid:1833)(cid:3047)(cid:3398)(cid:2011)(cid:1487)(cid:3008)(cid:3295),  (cid:1832)(cid:3047)(cid:2878)(cid:2869)(cid:3404)(cid:1832)(cid:3047)(cid:3398)(cid:2011)(cid:1487)(cid:3007)(cid:3295);  8.       (cid:1872)(cid:3404)(cid:1872)(cid:3397)1;  9.   Return (cid:1850);   Algorithm TSE   5.       While    it  is   Figure 5. Model for travel speed estimation  3.4  Traffic Volume Inference (TVI)  3.4.1  Model Description  Intrinsically, there exists a certain relationship, e.g., fundamental  diagram, among traffic speed, volume and density. Yet to quantify  this  relationship  accurately  requires  a  large  amount  of  traffic  volume  data.  As  many  road  segments  are  not  equipped  with  in- road devices, collecting such training data with a city-scale is very  costly.  Thus,  impractical  to  use  supervised  learning  algorithms to learn the relationship. In addition, the occurrence of  the sampled vehicles (e.g., taxis) on a road segment may be quite  different from the entire set of vehicles, though their travel speed  could be similar. In other words, observing more taxis on a road  segment  does  not  deduce  more  occurrences  of  other  vehicles.  Given  this,  we  cannot  infer  the  total  volume  of  traffic  directly  based  on  the  sampled  traffic  data.  To  address  this  issue,  we  propose  an  unsupervised  graphical  model,  TVI,  based  on  a  partially observed Bayesian Network.   Figure 6 presents the graphical structure of TVI model, where a  gray  node  denotes  a  hidden  variable  and  white  nodes  are  observations. Note that we can train only one TVI model using the   minute  per  lane)  of  a  road  segment  is  influenced  by  four  major   data  of  all  road  segments.  The  model  is  then  applied  to  infer  the  traffic volume for each road segment respectively. Specifically, the   traffic volume on each road lane (cid:1840)(cid:3028) (i.e., the number of vehicles per  factors, consisting of the  weather conditions (cid:1875), time of day (cid:1872), the  type  of  road (cid:2016),  and  the  volume  of  observed  sample  vehicles (cid:1840)(cid:3047).  Furthermore,  a  roads (cid:2016)  is  co-determined  by  its  road  network  features (cid:1858)(cid:3045)  (such  as (cid:1870).(cid:1864)(cid:1857)(cid:1866) ),  global  position  feature (cid:1858)(cid:3034) ,  and  surrounding POIs (cid:2009) which is influenced by (cid:1858)(cid:3043) and the total number  of  POIs (cid:1840)(cid:3043) . (cid:1874)(cid:1191)  and (cid:1856)(cid:1874)  are  the  average  travel  speed  and  speed  varriance, respectively, inferred by TSE model. (cid:1874)(cid:1191) is determined by  (cid:2016), (cid:1840)(cid:3028), and (cid:1875). (cid:1856)(cid:1874) is co-determined by (cid:1840)(cid:3047), (cid:1840)(cid:3028), and (cid:1874)(cid:1191).       ;    3.4.2  Learning    Algorithm 2: Parameter Learning of TVI   Figure 6. The graphical structure of TVI model   be  drawn  simply  by  counting  the  occurrence  of  each  condition.  Hence, we use the Expectation-Maximization (EM) algorithm to  learn  the  parameters  in  an  unsupervised  manner,  i.e.,  without   Due to the hidden nodes, the conditional probability of (cid:1840)(cid:3028) cannot  knowing the value of traffic volume (cid:1840)(cid:3028), as shown in Figure 7.   Input: Bayesian Network structure; observed evidences (cid:1831)  Output: Conditional probability (cid:1842)(cid:4666)(cid:1841)|(cid:1842)(cid:1853)(cid:4666)(cid:1841)(cid:4667)(cid:4667) of each node (cid:1841)  1. Randomly initialize (cid:1842)(cid:4666)(cid:1841)|(cid:1842)(cid:1853)(cid:4666)(cid:1841)(cid:4667)(cid:4667) for each node (cid:1841)  2. While (cid:1842)(cid:4666)(cid:1841)|(cid:1842)(cid:1853)(cid:4666)(cid:1841)(cid:4667)(cid:4667) does not converge  3.        Foreach evidence (cid:1857)(cid:3404)(cid:4666)(cid:1858)(cid:3045),(cid:1858)(cid:3034),(cid:1858)(cid:3043),(cid:1840)(cid:3043),(cid:1872),(cid:1875),(cid:1840)(cid:3047),(cid:1874)(cid:3365),(cid:1856)(cid:3049)(cid:4667) (cid:1488) (cid:1831)  4.              Foreach value of (cid:1860)(cid:3404)(cid:4666)(cid:2009),(cid:2016),(cid:1840)(cid:3028)(cid:4667) (cid:1488)(cid:1834)  5.                    (cid:1842)(cid:4666)(cid:1860),(cid:1857)(cid:4667)(cid:1370)(cid:1842)(cid:3435)(cid:2009)(cid:3627)(cid:1858)(cid:3043),(cid:1840)(cid:3043)(cid:3439)(cid:1842)(cid:3435)(cid:2016)(cid:3627)(cid:2009),(cid:1858)(cid:3034),(cid:1858)(cid:3045)(cid:3439)(cid:3400)                         (cid:1842)(cid:4666)(cid:1840)(cid:3028)|(cid:2016),(cid:1872),(cid:1875),(cid:1840)(cid:3047)(cid:4667)(cid:1842)(cid:4666)(cid:1874)(cid:3365)|(cid:1840)(cid:3028),(cid:2016),(cid:1875)(cid:4667)(cid:1842)(cid:4666)(cid:1856)(cid:3049)|(cid:1840)(cid:3028),(cid:1840)(cid:3047),(cid:1874)(cid:3365)(cid:4667)  6.               Foreach value of (cid:1860)(cid:3404)(cid:4666)(cid:2009),(cid:2016),(cid:1840)(cid:3028)(cid:4667) (cid:1488)(cid:1834)  7.                    (cid:1842)(cid:4666)(cid:1860)|(cid:1857)(cid:4667)(cid:1370)(cid:1842)(cid:4666)(cid:1860),(cid:1857)(cid:4667)/ (cid:1842)(cid:4666)(cid:1860),(cid:1857)(cid:4667) 8.        Foreach node (cid:1841)  (cid:3035)(cid:1488)(cid:3009) 9.               (cid:2025)(cid:1370) the occurrences of (cid:4666)(cid:1841),(cid:1842)(cid:1853)(cid:4666)(cid:1841)(cid:4667)(cid:4667);  10.             (cid:1842)(cid:4666)(cid:1841)|(cid:1842)(cid:1853)(cid:4666)(cid:1841)(cid:4667)(cid:4667)(cid:1370) (cid:2025)/the occurrence of (cid:1842)(cid:1853)(cid:4666)(cid:1841)(cid:4667);  11. Return (cid:1842)(cid:4666)(cid:1841)|(cid:1842)(cid:1853)(cid:4666)(cid:1841)(cid:4667)(cid:4667) conditional  probabilities,  e.g. (cid:1842)(cid:3435)(cid:2009)(cid:3627)(cid:1858)(cid:3043),(cid:1840)(cid:3043)(cid:3439)  and (cid:1842)(cid:4666)(cid:1874)(cid:1191) |(cid:1840)(cid:3028),(cid:2016),(cid:1875)(cid:4667) ,  the values of the hidden nodes (cid:4666)(cid:2009),(cid:2016),(cid:1840)(cid:3028)(cid:4667) for each instance of the   with  random  values.  In  the  E-step  (Line  4-7),  we  call  exact  inference method, i.e., use the simple Bayesian rule, to compute   At the beginning part, this algorithm sets the parameters, i.e., the   Figure 7. Parameter learning algorithm of TVI   observed data. This is actually an inference process. In the M-step  (Line 8-10), by scanning the inferred results from the E-step, the  algorithm  recalculates  the  conditional  probabilities,  which  will  replace  the  old  parameters.  Keep  iterating  until  the  parameters  converge, we learn a solution for the unknown parameters.   3.4.3  Discretization  All  the  variables  in  our  model  are  discretized.  This  reduces  the  inference  difficulty,  while  ensuring  the  inferred  results  are  statistically useful for gas consumption and emission calculation.   Some  nodes  are  discretized  based  on  commonsense  knowledge.   For  example,  speed (cid:1874)(cid:1191)  has  7  categories,  i.e.,  [0,10),  [10,20),   [20,40), [40,60), [60,80), [80,120), [120, ~) km/h, corresponding  to  different  traffic  conditions  like  free  flow  and  congestion.  However,  it  is  difficult  to  find  a  proper  discretization  for  traffic   1030 volumes  (on  each  lane) (cid:1840)(cid:3028) ,  as  we  do  not  really  have  prior  knowledge on how big (cid:1840)(cid:3028) could be on different road segments.    To  address  this  problem,  we  record  358  video  clips  on  50  road  segments  at  different  times  of  day,  and  then  manually  counted  the  number of vehicles passing these road segments in a given time slot  (i.e. the true traffic volume) (see Table 3 for details) by replaying the  video clips. A simple method is to discretize the traffic volume data  uniformly  according  to  the  range  identified  from  the  collected  observations. However, the observations are too limited to reveal the  true  upper  bound  of  the  possible  volume  on  road  segments.  In  addition,  road  segments  of  different  levels  may  have  very  different  upper  bound  of  traffic  volumes.  So,  we  employ  the  observed  true  volumes  to  fit  a  curve  that  reveals  the  distribution  of  the  traffic  volumes  on  different  levels  of  road  segments.  Then,  the  fitted   distribution is used as a guidance for the discretization of (cid:1840)(cid:3028).   As shown in Figure 8, the black data points indicate the observed true  volumes, which have been projected onto buckets with a width of 2,  i.e., [0, 2), [2, 4), and so on. Significant difference can be observed  among  the  three  road  levels  because  of  the  different  road  features,  such as speed limits and number of lanes. For example, the volume of  level 0-1 roads centers in the range of [10, 40), while most volume  data of level 3 roads is smaller than 10. To model the traffic volumes  on different roads more accurately, we fit a dedicated distributions for  each level of road segment (level 0 and 1 share the same distribution  as  both  of  them  denote  highways  in  Beijing).  We  adopt  normal  distribution   (cid:2870)(cid:3097)(cid:3118) (cid:4667)                 (7)  Figure 7, e.g., (cid:2020)=21.6 and (cid:2026)=6.38 are good fits for level 0-1 roads   (cid:1858)(cid:4666)(cid:1876); (cid:2020),(cid:2026)(cid:4667)(cid:3404) (cid:2869)(cid:3097)(cid:2870)(cid:3095)exp (cid:4666)(cid:3398)(cid:4666)(cid:3051)(cid:2879)(cid:3091)(cid:4667)(cid:3118)  to  fit  the  observed  volume  data.  The  parameters  are  shown  in   (p-value > 0.05 in a chi-square test).    10  s n o  i t  a v r e s b o     #   = 21.61 =  6.38  m  0 0  10  5  0   True Traffic Volumes  Normal Distribution  m1 m2 m3 m4  20  30 A) Level 0-1 (highways)  #veh/min/lane  m5 40  s n o  i t  a v r e s b o     #  40  30  20  10  0  0   =  5.44 =  3.13  True Traffic Volumes  Normal Distribution  10  20  #veh/min/lane  30  40  15  10  s n o  i t  a v r e s b o   #  5  0  0  10  B) Level 2 (main roads)  =  2.95 =  2.38   True Traffic Volumes  Normal Distribution  20  30 C) Level 3 (small streets)  #veh/min/lane  40     Figure 8. Fitting volume distribution for different road levels   The observations on these road segments can fit the distribution of  traffic  volume  w.r.t.  a  level  of  roads  for  two  reasons.  First,  the  selected  road  segments  of  a  level  have  a  diversity  of  features  (such as length) and traffic volumes. Second, we evenly select the  observations  from  each  road  segment  and  in  different  time  slots  (82, 163, and 54 observations for level 0-1, 2, and 3 respectively).   Given  the  fitted  distribution  of  a  road  level,  we  find  a  group  of   splitting  points (cid:1865)(cid:2868),(cid:1865)(cid:2869),(cid:1710),(cid:1865)(cid:2873) that  divide  the  traffic  volume  into  five categories  ((cid:1855)(cid:2869), (cid:1855)(cid:2870),, (cid:1855)(cid:2873)), such that (cid:1516) d(cid:1876)(cid:3404)0.2,  (cid:3040)(cid:3284)(cid:3040)(cid:3284)(cid:3127)(cid:3117) where (cid:1865)(cid:3036)(cid:2879)(cid:2869) and (cid:1865)(cid:3036) are the left and right boundary of category (cid:1855)(cid:3036)s  range  respectively; (cid:1865)(cid:2868)(cid:3404)0, (cid:1865)(cid:2873)(cid:3404)(cid:3397).  The  five  categories  may   (cid:1858)(cid:4666)(cid:1876); (cid:2020),(cid:2026)(cid:4667)  stand for tiny, small, median, big, and very large traffic volumes.   The output of the inference is a probability distribution over the 5  discretized volume categories.    3.4.4  Inference  For a more accurate inference, we train three different models for  road segments of level 0-1, level 2, and level 3 respectively, based   on  the  data  of the  corresponding  level.  Given a  road  segment (cid:1870),  we  select  a  model  according  to (cid:1870).(cid:1864)(cid:1857)(cid:1874) and  then  infer  its  traffic  volume (cid:1870).(cid:1840)(cid:3028) according to the E-step in Line 4-7 of Algorithm 2.  We  choose (cid:1853)(cid:1870)(cid:1859)(cid:1865)(cid:1853)(cid:1876)(cid:3030)(cid:1488)(cid:4668)(cid:3030)(cid:3117),(cid:1710),(cid:3030)(cid:3121)(cid:4669)(cid:1842)(cid:4666)(cid:1840)(cid:3028)(cid:1488)(cid:1855)(cid:4667) as  the  inferred  category  and  convert  the  category (cid:1855) to  a  real  traffic  volume  according  to  the corresponding volume distribution (cid:1858)(cid:4666)(cid:1876); (cid:2020),(cid:2026)(cid:4667) and the inferred  probability (cid:1842)(cid:4666)(cid:1840)(cid:3028)(cid:1488)(cid:1855)(cid:4667).  Specifically,  we  find  the  value (cid:1840)(cid:3028) (in (cid:1855)s  range) such that (cid:1842)(cid:4666)(cid:1840)(cid:3028)(cid:1488)(cid:1855)(cid:4667)(cid:3404)(cid:1516) (cid:1858)(cid:4666)(cid:1876); (cid:2020),(cid:2026)(cid:4667) d(cid:1876)/ 0.2, where (cid:1865) is  the left boundary of (cid:1855)s range, and 0.2 is the total probability of  category (cid:1855).  The  total  traffic  volume  on  a  road  segment (cid:1870) equals  (cid:1870).(cid:1840)(cid:3028)(cid:3400)(cid:1870).(cid:1866).   (cid:3015)(cid:3276)(cid:3040)  3.5  Energy and Emission Calculation  The  information  of  traffic  speed  and  volume  can  be  further  exploited for estimating real-time gas consumption and emissions  on road surfaces. Different models are available in environmental  science,  which  quantify  the  relationship  between  emissions  and  speed,  as  well  as  other  factors,  based  on  large  amounts  of  data.  The most frequently used models include MOBILE and COPERT,  which have been developed by scientists in the USA and Europe  respectively [11]. We use COPERT model [8] because vehicles in  Beijing currently adopt European-3 standards [14].  In  the  COPERT  model,  traffic  emissions  consist  of  three  parts,  namely  hot  emissions,  cold  start  emissions,  and  evaporative  emissions. Hot emissions occur when the engine is at its normal  mode,  which  is  the  general  condition  for  a  running  vehicle  and  thus is our major concern. Cold start emissions denote emissions  from transient engine operation, and evaporative emissions come  from refueling and temperature changes. The latter two parts are  omitted in our estimation due to lack of data; they are also of less  significance in overall emissions [2].   Hot emission factor (EF), the amount of pollutant a single vehicle  emits  per  kilometer  (g/km),  is  calculated  as  a  function  of  travel   speed (cid:1874) (cid:4666)km/h(cid:4667). The generic function is          (cid:1831)(cid:1832)(cid:3404)(cid:4666)(cid:1853)(cid:3397)(cid:1855)(cid:1874)(cid:3397)(cid:1857)(cid:1874)(cid:2870)(cid:4667)/(cid:4666)1(cid:3397)(cid:1854)(cid:1874)(cid:3397)(cid:1856)(cid:1874)(cid:2870)(cid:4667).              (8)   The parameters are given in Table 1 to calculate different kinds of  emissions  and  gas  consumption,  which  applies  for  Euro  3  passenger cars (gas consumption calculation additionally requires  a  vehicle  capacity  of  1.4-2.0L).  Although  diversity  of  vehicles  will  slightly  influence  the  computation,  the  results  are  still  statistically useful as we select the most representative cars in the  calculation.  As  for  other  pollutants  like  CO2  and  PM2.5,  their  emission  factors  are  proportional  to  fuel  consumption  (FC).  For  instance,  the  conversion  factor  of  CO2  is  3.18  for  gasoline,  i.e.,  is   (cid:1831)(cid:1832)(cid:1829)(cid:1841)2(cid:3404)3.18(cid:3400)(cid:1831)(cid:1832)(cid:1832)(cid:1829) ;  for PM(cid:2870).(cid:2873)  the  conversion  factor  3(cid:3400)10(cid:2879)(cid:2873).  The overall emission on a certain road (cid:1870) is:                               (cid:1831)(cid:3404)(cid:1831)(cid:1832)(cid:3400)(cid:1870).(cid:1840)(cid:3028)(cid:3400)(cid:1870).(cid:1866)(cid:3400)(cid:1870).(cid:1864)(cid:1857)(cid:1866),                      (9)  1.25(cid:3400)10(cid:2879)(cid:2873) 1.88(cid:3400) 6.53(cid:3400)10(cid:2879)(cid:2874) 3.97(cid:3400)10(cid:2879)(cid:2873) 9.65(cid:3400)10(cid:2879)(cid:2871) 4.21(cid:3400)  Table 1. Pollution emission parameters of COPERT model [8]   3.65(cid:3400)10(cid:2879)(cid:2870) 1.22(cid:3400) 9.6(cid:3400)10(cid:2879)(cid:2870)  5.57(cid:3400)10(cid:2879)(cid:2870) 9.29(cid:3400)10(cid:2879)(cid:2870)  Consumption   c  11.4   1.1(cid:3400) 1.49(cid:3400)  Hydrocarbon   b 35.4  a 71.7  -0.248  0.253   Fuel   Nox   217   CO  e 0  -  -  d  -  -  -  1031 4.  EXPERIMENTS  As the model introduced in Section 3.5 has already been tested in  environmental research, we focus on evaluating TSE and TVI.  4.1  Settings  4.1.1  Datasets  Road  networks:  We  use  the  road  network  of  Beijing,  which  is  comprised of 148,110 nodes and 196,307 edges. The road network   covers  a  40(cid:3400) 50km  spatial  range,  with  a  total  length  (of  road   segments)  of  21,895km.  Road  segments  with  level  0  and  1  are  highways. The bigger the level number is, the smaller the road is.     POIs: The datasets consist of 273,165 POIs of Beijing, which are  classified into 195 tier two categories. We only choose the top 10  categories that are located nearby road segments most frequently.     GPS  Trajectories:  We  use  GPS  trajectories  generated  by  33,000  Beijing taxis over a period of 47 days. The number of GPS points  reaches 673,469,757, and the total length of the trajectories is over  26,218,407km. The average sampling rate is 96 seconds per point.  After projecting the trajectories onto the road network, we come up  with the statistics shown in Table 2. % covered/time slot denotes  the proportion of road  segments traveled by at least one taxi in  a  given  time  slot  (we  set  10  minutes  a  time  slot  in  the  following  experiments). The last row of Table 2 presents the average number  of  traverses  by  taxis  in  a  time  slot.  Figure  9  A)  presents  the  proportion  of  road  segments  traveled  by  taxis  at  different  times.  Even during the peak hours, the proportion is only about 20% on  workdays and 17.5% on holidays, respectively. In reality, the travel  speed  derived  from  only  one  taxis  trajectory  (i.e.,  sup=1)  is  not  reliable. If counting the number of road segments traveled by three  taxis (i.e., sup=3) in a time slot, the proportion decreases to 8% on  workdays  and  5%  on  holidays,  respectively.  Figure  9  B)  further  shows  the  proportion  changing  over  the  number  of  traverses.  For  example,  over  90  percent  of  road  segments  are  traversed  by  less  than 5 taxis in a time slot. The data presented in Table 2 and Figure  9 reveals the sparsity problem we are facing.  Table 2. Statistics on Beijing road network with mapped trajectories    Num. of segments  Total length   % covered /time slot  # of travels/time slot   Level 3  142,865  14,747km  2.07%  0.11   Level 0,1  5,061  1,448km  9.97%  1.08   others  18,578  2,164km  2.94%  0.20   Level 2  29,803  3,537km  7.02%  0.42   0.20  0.15  0.10  0.05  0.00  s t  n e m g e S   d a o R    f o   n o i t r o p o r P  0  4  1.0  0.9  0.8  0.7  0.6  0.5  n o i t r o p o r  P   Holiday (Sup=1)  Workday (Sup=1)   Holiday (Sup=3)  Workday (Sup=3)  12  16  8 Time of day  40 Support Figure 9. Sparseness of mapped trajectories.   20     20  24  0  60  80     4.1.2  Baselines and Ground Truth  KNN: This baseline uses the average speed and traffic volume of  the nearest 3 neighbors to represent a road segments values.  Kriging is a spatial prediction method with the best linear unbiased   estimator [17]. Given a few detected neighbor points (cid:1876)(cid:3036)(cid:4666)1(cid:3409)(cid:1861)(cid:3409)(cid:1866)(cid:4667),  unknown  point (cid:1876)(cid:2868)  as  follows: (cid:1852)(cid:1499)(cid:4666)(cid:1876)(cid:2868)(cid:4667)(cid:3404) (cid:2019)(cid:3036) (cid:3041)(cid:3036)(cid:2880)(cid:2869) (cid:1852)(cid:4666)(cid:1876)(cid:3036)(cid:4667) ,  where  (cid:1852)(cid:4666)(cid:1876)(cid:3036)(cid:4667) is a value of location (cid:1876)(cid:3036), (cid:2019)(cid:3036) is a weight, and (cid:1866) is the number   Kriging uses a weighted linear combination estimator to predict an   of  samples.  Using  a  Kriging  model  with  a  linear  kernel,  we   interpolate the travel speed of a road segment (absent of taxis) based  on its 5 nearest neighbors with data.   Ground Truth: When evaluating TSE, we randomly remove 30%   of the non-zero entries from (cid:1839)(cid:1314)(cid:3045)s last row (i.e., the current time                                   (10)   slot)  and  predict  their  values  using  different  methods.  The  30  percent  non-zero  entries  are  then  used  as  a  ground  truth  to  measure  the  accuracy  of  the  predicted  values  by  RMSE  (root  mean square error), which is defined as    The  ground  truth  of  TVI  is  collected  as  introduced  in  Section  3.4.3. We calculate the mean absolute error (MAE) of volume on  each lane (i.e., number of vehicles per minute per lane) as   where (cid:1877)(cid:3114)(cid:3549)is a prediction and (cid:1877)(cid:3036) is the ground truth.    (cid:1844)(cid:1839)(cid:1845)(cid:1831)(cid:3404)(cid:3495)(cid:4666)(cid:3052)(cid:3284)(cid:2879)(cid:3052)(cid:3362)(cid:3549)(cid:4667)(cid:3118) (cid:3289)(cid:3284) (cid:3041) (cid:1839)(cid:1827)(cid:1831)(cid:3404)(cid:3627)(cid:1870).(cid:1840)(cid:3028)(cid:3398)(cid:1870).(cid:1840)(cid:3028)(cid:3554)(cid:3627)                             (11)  (cid:1839)(cid:1844)(cid:1831)(cid:3404) where (cid:1870).(cid:1840)(cid:3028) is the ground truth of traffic volume on road (cid:1870)s each  lane and (cid:1870).(cid:1840)(cid:3028)(cid:3554)  is the prediction; (cid:1870).(cid:1866) is the number of lanes in (cid:1870).     |(cid:3045).(cid:3015)(cid:3276)(cid:2879)(cid:3045).(cid:3015)(cid:3276)(cid:3554)|(cid:3400)(cid:3045).(cid:3041) (cid:3293)(cid:1488)(cid:3267)(cid:3263) (cid:3045).(cid:3015)(cid:3276) (cid:3400)(cid:3045).(cid:3041) (cid:3293)(cid:1488)(cid:3267)(cid:3263)  and the mean relative error (MRE) as                            (12)   3  0  4   3  1  7   3  4  9   3  0  8   2  0  28  43   2  8  92  142   2  14  74  136   total    49  309  358   7:00 ~ 10:00  0,1  0  7   10:00~16:00  0,1  6  29   16:00~20:00  0,1  6  28   experiments,  we  also  found  that  using  6  time  slots  (1hour)  to   Table 3. Ground truth collected for evaluation  after 20:00  2  0,1  6  4  6  17  37   Time  Lev.  Holi  Work  Total   4.1.3  Configuration of Models  We set 10 minutes as a time slot in our experiment. We partition a   tried a dynamic extension of our TVI model, and experiment shows  that  TVI  runs  much  faster  without  significant  accuracy  loss.  Therefore we keep using the static TVI model in our experiments.   4.2  Evaluation on TSE  In Table 4, we compare the overall performance of TSE with the   city into 4(cid:3400)4 grids and calculate the global position feature (cid:1858)(cid:3034) and  historical traffic pattern (cid:1839)(cid:3034) (we try different numbers for a partition,  finding  that  4(cid:3400) 4  is  slightly  better  than  others).  During  the  formulate (cid:1839)(cid:1314)(cid:3045) and (cid:1839)(cid:1314)(cid:3034) results  in  a  relatively  higher  accuracy.  We  baseline  method  that  only  factorizes  current  traffic  data (cid:1839)(cid:1314)(cid:3045) ,  denoted as MF((cid:1839)(cid:1314)(cid:3045)), or that combines geographic features (cid:1852) with  (cid:1839)(cid:1314)(cid:3045) ,  denoted  as  MF((cid:1839)(cid:1314)(cid:3045)(cid:3397)(cid:1852)),  or  that  combines  the  temporal  correlation  between  different  time  slots  of (cid:1839)(cid:1314)(cid:3008) with (cid:1852) and (cid:1839)(cid:1314)(cid:3045),  denoted as MF((cid:1839)(cid:1314)(cid:3045)(cid:3397)(cid:1839)(cid:1314)(cid:3034)(cid:3397)(cid:1852)). As a result, TSE outperforms all  the baselines in terms of RMSE of (cid:1874)(cid:1191) and (cid:1856)(cid:1874). The historical traffic  significant decrease of RMSE (about 0.5) over MF((cid:1839)(cid:1314)(cid:3045)(cid:3397)(cid:1839)(cid:1314)(cid:3034)(cid:3397) (cid:1852)). In addition, TSE has very good efficiency, much more so than   patterns  that  TSE  incorporates  are  very  helpful,  bringing  a   Kriging. By only using one server (with 4-core, 3.4GHz CPU and  8GB RAM), TSE can infer the travel speed of every single road  segment in Beijing within 22 seconds.    Table 4. Overall performance of different methods   RMSE of (cid:2204)(cid:3365)   RMSE of (cid:2186)(cid:2204)   2.172  1.939  1.908  1.369  2.340  3.360   1.833  1.385  1.314  1.035  1.300  1.590   Methods   MF((cid:1839)(cid:1314)(cid:3045))  MF((cid:1839)(cid:1314)(cid:3045)(cid:3397)(cid:1852))  MF((cid:1839)(cid:1314)(cid:3045)(cid:3397)(cid:1839)(cid:1314)(cid:3034)(cid:3397)(cid:1852))   TSE   Kriging  KNN   Time (sec)   2.2  18.2  20.2  22.2  1,000  0.14   1032 Figure 10 A) further explores the performance of TSE changing  over time of day.  As there are only a few taxis traveling on road  surfaces after 10pm and before 8am (see Figure 9 for a proof), the  corresponding estimation error is bigger than other time slots. As  time  goes  by,  we  observe  more  taxis  in  the  road  network  (i.e.,  more  road  segments  are  covered  by  trajectories).  Consequently,  the  RMSE  decreases  and  reaches  its  best  performance  at  4pm.  While the number of taxis is approaching to its peak at 4pm, the  traffic  conditions  start  stepping  into  congestions.  If  focusing  on  estimating  the  gas  consumption  and  pollution  in  daytime,  our  model is more accurate than the results presented in Table 4.     1.7  1.6  1.5  1.4  1.3  1.2  1.1  1.0  0.9  E S M R   Workday-v  Holiday-v   Workday-dv  Holiday-dv  4  6  8  10  14  12 16 Time of Day  18  20  22  24  6  5  4  3  2  1  0  E S M R      RMSE-v  RMSE-dv  0  20  60  40 Speed (km/h)  80  100              A) Changing over time of day               B)   Changing over speed   Figure 10.  Exploration of TSEs effectiveness   Figure  10  B)  shows  the  RMSE  of  TSE  changing  over  the  (real)  travel speed of a road segment to be estimated. Intuitively, a high  speed indicates a good traffic condition, in which people have more  flexibility  in  traveling  with  different  speeds.  As  a  result,  the   variance of speeds ((cid:1856)(cid:1874)) on a road segment can be big and become  ((cid:3410) 90km/h)  usually  has  the  lowest  driving  speed  constraint,  or   relatively  difficult  to  estimate.  In  addition,  the  number  of  road  segments that allow a high travel speed is small, making it difficult  for  TSE  model  to  fill  in  missing  values.  However,  a  highway   people  have  the  concern  in  mind  when  traveling  on  it.  This  will  reduce the flexibility of driving at different speeds, possibly leading  to the drop of RMSE after 90km/h in Figure 10 B).    Table 5. Effectiveness of TSE on different levels of road segments   RMSE  Speed  Variance   level 0-1  2.575  1.526   level 2  1.189  1.128   level 3  0.977  0.628   level >=4   1.612  1.234   We further explore the performance of TSE on different levels of  road segments in Table 5. It is worth noting that TSE has a good  performance on level 2 and 3 road segments, which covers 88.5%  of  Beijings  road  network.  These  road  segments  do  not  usually  have a loop sensor. So, it is important to have a method like TSE  that can infer the travel speed on such road segments.   4.3  Evaluation on TVI  Table  6  presents  the  overall  performance  of  TVI.  Using the  test  data presented in Table 3, we compare TVI with six baselines: we   first  study  not  using  the  variance  of  speed (cid:1856)(cid:1874) (TVI  w/o (cid:1856)(cid:1874))  and  weather  conditions (cid:1875)  (TVI  w/o (cid:1875) )  in  our  model,  and  then  Clearly, TVI has better performance beyond TVI w/o (cid:1856)(cid:1874) and TVI  w/o (cid:1875). As traffic conditions depend on the weather condition, e.g.,  improve  inference  accuracy.  Besides,  having (cid:1856)(cid:1874) together  with (cid:1874)(cid:1191),  volume in Beijings road network in 0.84 seconds, (i.e., 7(cid:2020)(cid:1871) each).    we  can  better  reveal  the  traffic  conditions  on  road  segments,  thereby  inferring  traffic  volumes  more  accurately.  According  to  the  efficiency  study,  TVI  is  very  efficient,  inferring  the  traffic   compare TVI with several existing methods, e.g., linear regression  (LR) and fundamental diagram (FD).   on  rainy  days  the  traffic  speed  is  much  slower  and  thus  traffic  volume  is  smaller,  information  on  weather  conditions  does  help   MAE  3.01  3.19  3.15  3.06  2.66  3.9  6.7   MRE  29%  31%  29%  27%  16%  42%  137%   7.27   7.18  7.10  0.15 0.13  0.13  0.13   Table 6. Overall performance of TVI   Inference time (us/road)   Methods  TVI   TVI w/o (cid:1856)(cid:1874)  TVI w/o (cid:1875)   LR  FD  FD-SC  FD-DC  We also compare TVI with two supervised methods, consisting of  linear regression (LR) and Fundamental Diagram (FD), which learn  a curve simulating the relation between the traffic volume and travel  speed  on  a  particular  road  segment  based  on  a  large  volume  of  training data.  For LR, we use half of the data as a training set and  another half for a test. W.r.t. FD, we select three road segments with  enough labels, using half for training and half for testing. Our TVI  model outperforms the supervised LR and has a slightly bigger error  than FD. Note that TVI is an unsupervised model that can scale up  to the entire road network. Designing an unsupervised method with  an  accuracy  even  better  than  a  supervised  approach  is  indeed  a  contribution.  In addition, the performance of TVI is tested based on  the whole dataset presented in Table 1, while FD is only tested on  three roads and LR is on half roads. Tested on the same three road  segments, TVI has a volume error of 2.73 which is even closer to  that  of  FD.  It  should  be  noted  that  FD  needs  training  for  each  individual road segment, some of which may have no volume data  at all. To address this issue, we first cluster road segments into a few   groups in terms of their geographical features in matrix (cid:1852). We train   a FD model based on the data from some road segments in a cluster,  and then apply the model to other road segments in the same cluster  (FD-SC). The performance decreases very quickly. If applying the  model trained from one cluster to another cluster, the volume error  is even bigger. These results denote that FD is  not scalable to an  entire road network.   Table 7 further explores the performance of TVI on different road  levels and in different type of days. It turns out that TVI has a better  performance on level 2 road segments which are absent of a loop  sensor  but  with  a  large  volume  of  traffic,  and  thus  are  our  major  concerns. Additionally, TVI has a better performance on weekdays  than weekends, as some taxi drivers do not work on weekends, and  traffic conditions on weekends are relatively irregular and complex  compared to weekdays.    Table 7. Exploration of the performance of TVI    MAE  MRE   level 0-1   5.55  22%   level 2  Weekday  Weekend  2.23  41%   3.28  30%   2.97  29%   Table 8 further presents the time that different components spend  on processing the data of a time slot (i.e., 10 minutes), if we only  use a single core of a single server. Note that we can map-match  the trajectories of different drivers separately and infer the traffic  volume  on  different  road  segments  independently.  Using  five  cores  of  the  server  to  perform  the  map-matching  and  TVI  in  parallel,  we  can  infer  the  travel  speed,  traffic  volume,  energy  consumption,  and  pollution  emission  throughout  Beijings  road  network in 1 minute.    Table 8. Efficiency of different components of our method   Online components   Map-matching  TSE  TVI (inference)  Total   Offline components    Time  4.94min  Geo-feature extraction  22.2s  0.84s  5.32min  Total   Historical pattern extraction  TVI learning   Time  149s  240s  89s  478s   1033 4.4  Visualization   Figure 11 visualizes the traffic volume, energy consumption, and  pollution  emission  around  Beijing  Olympic  Park  on  a  weekday  (2013/9/17 Tuesday),  weekend  (2013/9/21  Saturday),  and  public  holiday (2013/10/2), respectively.    2013/09/17 Tuesday   2013/09/21 Saturday  2013/10/02  National Holiday  M P 9          8  M P 9          8  M A 1 1          0 1  e m u l o V  n o i t p m u s n o C   s a G  n o i t p m u s n o C   s a G  M P 9     x O N       8  veh/min  25  15  0  kg/km  240  150  0  kg/km  240  150  0  g/km  120  90    Figure 11. Traffic volume, energy consumption and emissions around   0  Beijing Olympic Park in different time slots   As  depicted in the first  row, in  time  slot 8-9pm,  the region  has  a  bigger traffic volume during the weekday than during the weekend  and holiday. This is aligned with our commonsense knowledge that  people  usually  visit  this  region  in  the  daytime  (rather  than  in  the  evening) of weekends or a holiday. The large volume of traffic on a  weekday is caused by people who drive home after work passing by  this region. Given the same reason, in the second row of Figure 11,  we  observe  more  red  road  segments,  which  denotes  more  energy  consumption, on the weekday than on the weekend and the national  holiday.  The  latter  two  days  generally  have  a  similar  energy  consumption  pattern  except  several  road  segments  where  the  national holiday is slightly higher than the weekend. The former has  relatively  more  sightseeing  buses  arriving  at  the  park  or  more  tourists taking taxis to this region in the evening (than the latter). On  the  contrary,  in  the  time  slot  from  10  to  11am,  we  observe  more  energy consumption on the weekend and holiday, as many people  drive to the park at these times for fun. On a workday, after morning  rush hours (e.g., 8-10am), people barely drive to this place during   working  time.  The  emissions  of PM(cid:2870).(cid:2873)  and CO(cid:2870)  have  the  same  (3(cid:3400)10(cid:2879)(cid:2873) and 3.18 respectively). The last row of Figure 11 presents  the  emission  of (cid:1840)(cid:1841)(cid:3051) in  the  region,  where  the  workday  has  more  Figure 12 demonstrates the gas consumption and emission of (cid:1840)(cid:1841)(cid:3051)   pattern  as  the  energy  consumption,  just  having  different  factors   emission than the weekend and national holiday in 8-9pm.      around  Zhongguancun  area,  which  is  a  place  mixed  with  many  companies and entertainments, in the aforementioned three days,   respectively.  In the  time  slot  from  3pm  to  4pm,  the  time  before  evening  rush  hours,  this  area  has  less  gas  consumption  on  the  workday than during the weekend and holiday, because people are  still working indoors. When time goes to weekends and holidays,  many people travel to this region for the purpose of entertainment,  e.g.,  go  shopping  and  watch  a  movie,  leading  to  more  energy  consumption and emission of CO, as illustrated in the two rows of  Figure  12.  There  is  a  movie  theater,  a  supermarket,  and  two  shopping centers located in the region marked by the broken curve.    2013/09/17 Tuesday   2013/09/21 Saturday  2013/10/02  National Holiday  kg/km  240  150  0  kg/km  30  12  n o i t p m u s n o C   s a G     M P 4  3        M P 4  3     O C  0    Figure 12. Gas consumption and pollution emission around   consumption, and (cid:1840)(cid:1841)(cid:3051) emission on three types of days: weekdays,   Figures  13,  14  and  15  show  the  citywide  traffic  volume,  gas   Zhonguancun area   weekends,  and  public  holidays.  The  number  plotted  in  the  three  figures  are  averaged  by  day,  respectively.  Figure  13  presents  the  average  traffic  volume  on  a  road  segment  in  one  minute,  which  depends on the travel speed on the road segment and the density of  the  traffic.  Before  7am,  a  workday  has  a  larger  volume  of  traffic  than  a  weekend  or  a  holiday.  At  this  moment,  the  travel  speed  is  very fast during the three types of days, while more people travel (to  work)  on  a  weekday  than  a  holiday.  When  time  goes  to  8-10am  (i.e.,  Beijings  morning  rush  hours  on  workdays),  however,  the  travel  speed  decreases  significantly  on  a  weekday,  reducing  the  traffic  volume  that  can  pass  a  road  segment.  The  weekend  and  holiday  have  a  similar  decreasing  trend,  but  do  not  drop  tremendously, because the travel speed is not that slow from 8am to  10am. After morning rush hours, the travel speed increases, leading  to  an  increase  of  the  traffic  volume.  Then,  we  see  the  decreasing  pattern  repeats  in  evening  rush  hours,  5-7pm,  during  a  weekday.   After  evening  rush  hours,  the  traffic  volume  increases  again  with  the increase of the travel speed on a weekday, until at later night  when the traffic  density decreases tremendously (we do not show  the traffic volume after 11pm in these figures as they are very small  and  quite  similar  to  each  other).  The  public  holiday  has  a  bigger  traffic  flow  than  the  other  two  days,  as  a  portion  of  people  leave  Beijing for vacation, which reduces the traffic density slightly but  enhances the travel speeds on roads significantly.   Figure  14  shows  the  total  energy  consumption  of  the  entire  road  network per hour changing over time of day. For instance, from 12pm  to 1pm, about 3,850,000 liters of gasoline are consumed by vehicles  in  Beijing.  Supposing  there  are  2  million  vehicles  traveling  on  the  road  network  in  this  time  slot,  each  vehicle  consumes  1.9  liter  gasoline  per  hour,  which  is  about  19  kilometers  per  hour.  A  peak  occurs  in  this  time  slot  due  to  the  bigger  traffic  volume  and  travel  speed. The reason a public holiday consumes more energy may lie in  the fast travel speed and a farther distance that people would travel  during holidays.   Figure  15  presents  the  total  emission  of (cid:1840)(cid:1841)(cid:3051)  in  Beijings  road   network, where weekends have the largest volume in the afternoon.   1034 i  /  d a o R n M / s e c h e V  i  l    .  #  20.0  19.6  19.2  18.8   Weekday  Weekend  Holiday  6  8  10  12  14  16 Time of Day  18  20  22  24  4200K  4100K  4000K  3900K  3800K  3700K  /  ) r u o h L (   s a G    f     o e m u o V  l   Weekday  Weekend  Holiday  1660  1640  1620  1600  1580  r u o h / G K   Weekday  Weekend  Holiday    Figure 13. The citywide traffic volume of Beijing           Figure 14. Citywide gas consumption                       Figure 15. Citywide NOx emission       6  8  10  12  14  16 Time of Day  18  20  22  24      6  8  10  12  14  16 Time of Day  18  20  22  24     Veh/ min  25  15  0  kg/km/ hour  240  150  0  g/km/ hour  120  90  0     Figure 16. Geo-distribution of Traffic Volume      Figure 17. Geo-distribution of energy consumption     Figure 18. Geo-distribution of NOx emission                      therefore   Beijing is running a traffic control policy based on the license ID  of a car on workdays. As this policy does not apply to weekends  and  holidays,  the  number  of  people  who  travel  by  car  is  even  bigger on a weekend. On public holidays, many people leave the  city  for  vacation,  the  emissions  are  not  heavy.  Combining  Figure  14  and  15,  we  find that  public  holidays  have  more  gas  consumption  but  less  emission  than  weekdays  and  weekends, i.e., the energy has been used in a cleaner way.   Figure  16  visualizes  the  mean  traffic  volume  (i.e.,  the  average  number of vehicles per minute) traversing every road segment in  Beijing from 6am to 10pm on workdays. The road segments with  relatively large volumes of traffic (marked red) are mainly located  in the south (e.g., the southern segments of the fifth ring road) and  some  highways  spreading  towards  rural  areas.  As  the  major  business and entertainment areas are located in the northern and  central part of Beijing, the average travel speed in these places are  generally slower than the southern part. The slow speed reduces  the  traffic  volume  on  corresponding  road  segments.  The  traffic  volume  on  the  northern  segment  of  the  fourth  ring  road  is  relatively larger than other road segments in the north part, which  well  matches  our  commonsense  knowledge.  Figure  17  presents  the average energy consumption of vehicles on each road segment  per  hour,  from  6am-10pm.  As  the  total  energy  consumption  depends  on  both  travel  speed  and  traffic  volume,  some  road  segments  marked  red  in  Figure  16  become  green  in  Figure  17.  Given this kind of visualization, urban planners and transportation  authorities  can  identify  the  road  segments  that  have  wasted  unnecessary  energy  (e.g.,  a  road  segment  with  small  traffic  volume  while  having  a  large  energy  consumption),  therefore   informing future urban planning. Figure 18 displays the total (cid:1840)(cid:1841)(cid:3051)   emission on road segments per hour in the same time slot, where  the  ring  roads  and  highways  have  more  emissions.  When  the  emission on some road segments exceeds a threshold, we can send  alerts to people passing by or living around. The information can  also guide drivers for finding the best route in terms of the energy  consumption, air quality, and travel time.   5.  RELATED WORK  5.1  Traffic Condition Modeling  Traffic  modeling  on  individual  roads:  Conventional  methods  use  traffic monitoring cameras (usually combined with a speedometer)  to observe speed and volume data where relevant instrumentation is  installed.  This  kind  of  approach  usually  employs  a  Fundamental  Diagram  [1,  3]  to  learn  a  specific  relation  among  travel  speed,  traffic  density,  and  volume  for  a  particular  road,  from  a  large  amount  of  data  collected  by  the  camera  and  speedometer.  As  the  number of vehicles traversing a road may not be perfectly detected  by  using  automatic  computer  vision  algorithms,  in  most  cases,  human  effort  is  needed  to  count  the  vehicles  so  as  to  generate  training data for the fundamental diagram. Consequently, this kind  of  methods  is  difficult  to  scale  up  to  an  entire  city,  let  alone  the  limited  coverage  of  traffic  monitoring  camera  and  speedometers.  Later, in-road loop sensors are widely deployed to detect both travel  speed  and  traffic  volume.  The  rich  data  enables  sophisticated  modeling to simulate traffic status between the instrument [7, 13],  or  predict  future  traffic  status  [5],  for  a  specific  road  where  the  device is installed. Unfortunately, the majority of these models do  not  incorporate  the  correlation  between  the  traffic  conditions  of  different  road  segments  (especially  those  that  are  geospatially  disconnected), when estimating the traffic on a road segment.  Some  methods [5] model several connected road segments simultaneously  with  a  Markov  Model.  However,  applying  these  methods  to  the  entire road network will result in a huge model that has very poor  efficiency and big issues with training parameters. Additionally, the  coverage  of  loop-sensor  systems  is  also  limited  due  to  the  high  expense for device installation and maintenance.  Traffic  modeling  on  a  road  network:  Recently,  more  traffic  modeling systems have turned to using Floating Car Data [10, 15],  which is generated by vehicles traveling around a city with a GPS  sensor. The trajectories of these vehicles will be sent to a central  system and matched onto the road network for deriving speed on  road  segments.  However,  due  to  the  uneven  distribution  of  the   1035 the  contribution  of   probing vehicles as well as the low sampling rate of GPS data (e.g.,  one point per minute), many road segments are not covered by any  trajectory [17]. To address this problem, some interpolation-based  methods,  such  as  KNN  and  Kriging  [18],  have  been  proposed  to  infer the traffic conditions of a road segment based on the values of  its  spatial  neighbors.  More  advanced  methods  model  the  traffic  conditions on a road network with a road-time matrix, where each  entry stands for the traffic conditions at a specific road segment and  in  a  particular  time  slot.  These  methods  then  adopt  Compressive  Sensing-based algorithms [16, 17] to fill in the missing entries in the  matrix.  The  interpolation-based  methods  consider  the  spatial  correlation  among  different  locations  traffic  conditions,  and  the  compressive  sensing-based  approach  considers  both  spatial  and  temporal  correlations.  Unlike  these  methods,  our  model  incorporates  two  additional  (but  very  helpful)  correlations  from  extra data sources. One is the correlation between road segments in  terms  of  their  geographic  features,  such  as  the  length,  POI  distributions,  and  number  of  connections,  learned  from  road  network and POI datasets. The geographic features capture the local  and  global  similarity  between  two  road  segments  simultaneously.  The other is the correlation between the current and historical traffic  conditions, learned from historical trajectories over a period of time.  Extensive  experiments  validate  these  correlations beyond the original correlation solely learned from the  road-time matrix.   5.2  Energy and Emission Estimation  Vehicular  fuel  consumption  and  pollutant  emission  is  a  critical  environmental issue nowadays. [9] studies the empirical relation  between  traffic  emissions  and  travel  speed  as  well  as  the  acceleration  for  a  single  vehicle.  [2]  exploited  a  framework  similar to ours to estimate macroscopic pollutant emissions. The  main concern with this method is the use of the historical average  to  deal  with  the  aforementioned  data  sparsity  problem.  Consequently,  irregular  conditions  (e.g.,  congestions  caused  by  accidents)  are  not  well  captured.  In  addition,  it  applies  a  homogeneous FD to different roads in the same cluster, which has  been compared with our method as a baseline (FD-SC).  There also exist crowdsensing-based approaches [4, 12] that sense  environmental  data  using  people  or  vehicles  carrying  air  quality  sensors. These methods cannot bypass the data sparsity problem  either when scaling up to a citywide application, as the number of  sensors is even smaller than the number of GPS-equipped vehicles.  These approaches also do not answer the questions, such as how  much pollutant is generated from traffic.   6.  CONCLUSION  In  this  paper,  we  instantly  infer  the  traffic  volume,  energy  consumption, and the emissions of vehicles traveling on a citys  road  networks,  based  on  the  GPS  trajectories  received  from  a  sample  of  vehicles,  e.g.,  GPS-equipped  taxicabs,  in current time  slot and over a period of history. The knowledge derived from our  research  can  enable  many  valuable  applications  for  social  good,  such  as  timely  road-level  pollution  alerts,  monitoring  citywide  traffic  conditions,  improving  urban  planning,  and  helping  study  the root cause of air pollution. This is a very challenging problem,  however, considering its efficiency, effectiveness, and scalability.  We address this problem through a three step approach, where we  first propose TSE model to compute the travel speed on each road  segment  based  on  incomplete  trajectory  data,  then  infer  the  volume  of  a  road  segment  by  using  TVI  model,  and  finally  calculate the energy consumption and pollution emission based on  the  inferred  travel  speed  and  traffic  volume.  We  evaluate  our  approach  based  on  extensive  experiments  that  use  GPS   trajectories  generated  by  over  32,000  taxicabs  over  a  period  of  two months. The results demonstrate the effectiveness, efficiency  and  scalability  of  our  method,  which  outperforms  baseline  approaches,  such  as  Linear  Regression,  Fundamental  Diagram,  and Kriging. Using five cores of a server, we can grasp the traffic  conditions,  energy  consumption,  and  emissions  of  the  past  10  minutes throughout Beijings road network within 1 minute.    REFERENCES  [1]  Greenshields, B. D., Bibbins, J. R., Channing, W. S., and Miller, H.   H. 1935. A study of traffic capacity. In Highway research board  proceedings (Vol. 14).   [2]  Ghnemann, A., Schfer, R. P., Thiessenhusen, K. U., and Wagner,   P. 2004. Monitoring traffic and emissions by floating car data.  Institute of Transport Studies Working Paper, (ITS-WP-04-07).  [3]  Helbing, D. 2001. Traffic and related self-driven many-particle   systems. Reviews of modern physics, 73(4), 1067.   [4]  Honicky, R., Brewer, E. A., Paulos, E., and White, R. 2008. N-  smarts: networked suite of mobile atmospheric real-time sensors. In  Proc. of the second ACM SIGCOMM workshop on Networked  systems for developing regions (pp. 25-30).    [5]  Kwon, J., and Murphy, K. 2000. Modeling freeway traffic with  coupled HMMs. Technical report, Univ. California, Berkeley.   [6]  Lou, Y., Zhang, C., Zheng, Y., Xie, X., Wang, W., and Huang, Y.   2009. Map-matching for low-sampling-rate GPS trajectories. In  Proc. of ACM SIGSPATIAL GIS, 352-361.    [7]  Muoz, L., Sun, X., Horowitz, R., and Alvarez, L. 2003. Traffic   density estimation with the cell transmission model. In Proc. of the  2003 American Control Conference, Vol. 5, 3750-3755.    [8]  Ntziachristos, L., Samaras, Z., Eggleston, S., Gorissen, N., Hassel,   D., and Hickman, A. J. 2000. COPERT III. Computer Programme to  calculate emissions from road transport, methodology and emission  factors (version 2.1). European Energy Agency (EEA), Copenhagen.   [9]  Panis, L.I., Broekx, S., and Liu, R. 2006. Modelling instantaneous  traffic emission and the influence of traffic speed limits. Science of  the total environment, 371(1), 270-285.   [10] Schfer, R. P., Thiessenhusen, K. U., and Wagner, P. 2002. A traffic   information system by means of real-time floating-car data. In ITS  world congress (Vol. 2).   [11] Smit, R., Ntziachristos, L., and Boulter, P. 2010. Validation of road   vehicle and traffic emission modelsA review and meta-analysis.  Atmospheric environment, 44(25), 2943-2953.   [12] Steed, A., Spinello, S., Croxford, B., and Greenhalgh, C. 2003. E- Science in the streets: urban pollution monitoring. In UK e-science  all hands meeting.   [13] Wilkie, D., Sewall, J., and Lin, M. 2013. Flow reconstruction for  data-driven traffic animation. ACM Trans. on Graphics, 32(4), 89.  [14] Xie S., Song X., and Shen X. 2006. Calculating Vehicular Emission   Factors with COPERT Mode in China. Environmental Science,  27(3), 415-419.   [15] Yuan, J., Zheng, Y., Zhang, C., Xie, W., Xie, X., Sun, G., and   Huang, Y. 2010. T-drive: driving directions based on taxi  trajectories. In Proc. of the 18th SIGSPATIAL GIS, 99-108.     [16] Zhang, Y., Roughan, M., Willinger, W., and Qiu, L. 2009. Spatio-  temporal compressive sensing and internet traffic matrices. In ACM  SIGCOMM Computer Communication Review, 39(4), 267-278.    [17] Zhu, Y., Li, Z., Zhu, H., Li, M., and Zhang, Q. 2013. A compressive   sensing approach to urban traffic estimation with probe vehicles.  Mobile Computing, IEEE Transactions on, 12(11), 2289-2302.   [18] Zou, H. X., Yue, Y., Li, Q. Q., and Yeh, A. G. O. 2011. Traffic data   interpolation method of non-detection road link based on Kriging  interpolation. Jiaotong Yunshu Gongcheng Xuebao, 11(3), 118-126.   [19] Zheng, Y., Capra, Li, Wolfson, O., Yang, H. 2014. Urban   computing: concepts, methodologies, and applications. ACM Trans.  On Intelligent systems and Technology, 5(3).   [20] Data released: http://research.microsoft.com/apps/pubs/?id=217455  1036 '"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "re.sub('[\\s]',\" \",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall (r'(Abstract|ABSTRACT)([^]]*)',document[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-04468f768981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mabstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mr'\\n\\n(Abstract|ABSTRACT)([^]]*)\\n\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mabstract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mr'(Abstract|ABSTRACT)([^]]*)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    abstract = re.findall (r'\\n\\n(Abstract|ABSTRACT)([^]]*)\\n\\n',document[:2000])[0]\n",
    "except IndexError:\n",
    "    abstract = re.findall (r'(Abstract|ABSTRACT)([^]]*)',document[:2000])[0][1]\n",
    "except IndexError:\n",
    "    abstract = re.findall()\n",
    "else:\n",
    "    abstract = re.findall (r'(Abstract|ABSTRACT)([^]]*)',document[:2000])[0][1]\n",
    "    \n",
    "if isinstance(abstract, tuple):\n",
    "    abstract = re.sub('[\\s]',\" \",abstract[1])\n",
    "elif isinstance(abstract,list):\n",
    "    abstract = re.sub('[\\s]',\" \",abstract[1])\n",
    "elif isinstance(abstract,str):\n",
    "    abstract = re.sub('[\\s]',\" \", abstract)\n",
    "else:\n",
    "    abstract = re.sub('[\\s]',\" \",abstract)\n",
    "        \n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n",
    "document\n",
    "abstract[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall (r'\\n \\n([^]]*\\n)',a[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 901 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print 'there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder to see the output of the code above; make sure it does what I want; this will be converted and stored as json document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p279.pdf',\n",
       " 'ptest.pdf',\n",
       " 'p299.pdf',\n",
       " 'p309.pdf',\n",
       " 'p289.pdf',\n",
       " 'p259.pdf',\n",
       " 'p269.pdf',\n",
       " 'p59.pdf',\n",
       " 'p319.pdf',\n",
       " 'p29.pdf',\n",
       " 'p19.pdf',\n",
       " 'p39.pdf']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove semicolon to see output\n",
    "corpus.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how to access values in document store and attributes of each document for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title', 'Abstract', 'Entities', 'Stems', 'Lems', 'Stanford ER']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['p59.pdf'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAFDUAAABlCAIAAAB8JYuZAAAACXBIWXMAAA3XAAAN1wFCKJt4AAAAHXRFWHRTb2Z0d2FyZQBHUEwgR2hvc3RzY3JpcHQgOS4xNnO9PXQAACAASURBVHic7N1PbBzXfuD702z+pySqZYuicicR0x4bEymTTC4tZHbWAygM4ODtQmHeKnMRoAXMzHJuyF1udmLiZTKAepPM6uGJRnbXi6deSJuHCeS+mcx75iDX446YSWJL8lVLlvhH/PsWP/H48FTV6dP1p7u6+vuBYVBsdnd19amqc079fudXOj4+VgAAAAAAAAAAAAAAAAAAAAAAAAAAAADgYaTfGwAAAAAAAAAAAAAAAAAAAAAAAAAAAABgYJCfDAAAAAAAAAAAAAAAAAAAAAAAAAAAAMAX+ckAAAAAAAAAAAAAAAAAAAAAAAAAAAAAfI32ewMAAAAAAAAAAAAAAACQiVar1Wq1lFKLi4tKqUql0u8tAgAAAAAAAAAAQBGUjo+P+70NAAAAAAAAAAAAAAAASFm9Xm80GsvLy+12u9FotFqtzz//vN8bBQAAAAAAAAAAgCIgPxkAAAAAAAAAAAAAAKCAbt68ef/+ffm53W5/+OGHX331VX83CQAAAAAAAAAAAMUw0u8NAAAAAAAAAAAAAAAAQMparVa1WtX/rFQq9+7d6+P2AAAAAAAAAAAAoEjITwYAAAAAAAAAAAAAACgaSU5eW1trtVrym8XFxb5uEQAAAAAAAAAAAIqjdHx83O9tAAAAAAAAAAAAAAAAQPoajUaj0Wi1WpVKpVarkaIMAAAAAAAAAACAVJCfDAAAAAAAAAAAAAAAUHDtdvvWrVv37t2rVCr93hYAAAAAAAAAAAAMvJF+bwAAAAAAAAAAAAAAAABStr6+3mq19D8rlcri4mKz2ezjJgEAAAAAAAAAAKAwyE8GAAAAAAAAAAAAAAAommazub6+bv6m1WotLi72a3sAAAAAAAAAAABQJKP93gAAAAAAAAAAAAAAAACkr91u3759u1KpKKUajUatVpOfAQAAAAAAAAAAgIRKx8fH/d4GAAAAAAAAAAAAAAAApK/dbjebTaXU0tJSv7cFAAAAAAAAAAAAxUF+MgAAAAAAAAAAAAAAAAAAAAAAAAAAAABfI/3eAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADg/xkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAL7ITwYAAAAAAAAAAAAAAAAAAAAAAAAAAADgi/xkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAL5G+70BAAAAAAAAAAAAAAAAWWlubra3tqxffvPy5dcvXjie9Y/t9s7+fvCX8sPLnZ39w0Ol1OHR0dabN+bfbO/t7R0e7h8cKKUOjo4Oj44Oj47MPzg8Ojo+Ppafj4+Pj5U61o8Zv1fm7wdBSSlVKpWUKpVK5ZGRcqlULpf1Q+WR7xfQHx99G6wyOjIyevI3Sqnp8XGl1MzExOTY2OzUlFLqB5WKUurCzMyvvPPO+5cuyZ8tXb3ai88DAAAAAAAAAAAAp5K+6QUAAAAAAAAAAAAAAERoUqun12/efPnNN90+6+tOGbP7h4fPT2/S3sGBz0bu7u8fRsQGvNzZOTo6khcPPnpkPOvISLI9jkqdDXuXY3WSbvv2T4hS6KlSqWT+k/0fxdpRqb3syauf+qfxdiOlkvy+ZKRwK6VGSyX5m/LIyNT4uLV556enz05Oys9j5bKkc5sktdt0YWbmwsyM/Pz+/PyZiYng1lZmZhavXPH9bAAAAAAAAAAAYLiRnwwAAAAAAAAAAAAAqWk9e9Z69izTt7ByX1/t7n755EkWb7S7v//Ny5ehD33z3Xf6572Dg6PE9523T1egFUfHxzpp9uDw0CpCCwwcM8W0dPo35ZERVXobwlEeGTk+Pj4+Ph4plVSptLu3F/pq/+zChX9x+bJSqjI9XZ2bk1/q2sKLCwuV6emoLWlsbHzz8uXDv/3b9tbW862t//cf/uHw+Lj9+nXijwiE6Db32zhO7Lxuy+jIyMjIyEjE64+USpPj42bad7lcPj81pSt4h7xguXx2cvIHlYpU8w4y07zFmclJXdzbrXrxYvXiRZ+/BAAAAAAAAABgIJCfDAAAAAAAAAAAAPRfe3u7+fhxj9+0sbER+vvNb7/N6B1/fjqN9nnc4rQdHR0f7x0cyFvs7e9n9C4ACmB0ZKQ8MqKUKp9kOUruYqlUunTunP6zS7Oz8sNYuXxhZub9S5d09VorO1EnBpsndn2+bT192t7eVrKWwdOnoZu0uLBQmZlRSlUvXqycZEJ6Jh4npxdZkG1uPX361bNnr3d3fx4oCT4zMVEeGfluZyfqpSbGxpRSxycn5OyUR0ZKpdJBWA1woPCC6d+lk6Lc7j8bKZVKSpVOKnUHHx0tl0dKpfLIyOTYWPl0fW9xZnJy7OT3k2NjUxFJ3Zb3L10Kpnl//2hEce+Osj43AgAAAAAAAACCyE8GAAAAAAAAAAAYYLlKavUUI/f16xcvXoXVVnVLkvv6Ynv7RWapswAAt7Fy+Z0zZ0IfGh8d/eGVK5NjY8GHLp8/f3l29reuXAk+lG7ZUp3B297aam5uvv1lrMTjyvT04sKCPKozkPOsubnZ3trSe0A6Ic3Hj9unL5qT4+Pzs7NKqcnR0d39/bFy+fWbN1+/eBH6mudnZs5PTx8cHY0opTOZpycmnn733evd3Uw/TqiZiYmRkRErX1Oq6e4dHGS3skY856enoyrYHx4dbXXffYph4vTx+IZlQVAgIyf52+Y5YeRkYQtLqVQK+e0JyfeWnyfHx8fKZfl5rFweL5fHRkejcrajnJmYmDmdy31mcvIDY72My+fPz58srpHQQFyhAAAAAAAAAPQe+ckAAAAAAAAAAAyphCmmMTQfP5a8nUyZua+vdne/fvkyozcKzU7Z3dv7JrN3BIC0jIyMSMHDNxkXNfU0Ecg1Jb0tny7MzIyPjpq5wWPl8tmpKaWUmRClzc/OToyNRSU1VWZmFsNyifsoNPFYrwMSzMLVlq5dkx90srHOiM7hx8yIXjNFunySxqyUanzxhfWXlyuVy7OzZycmSqXS7v7+/Ozs5NjY3337rZSkDv699sOT3fvBpUuPv/1WKTU5NjY/OytdvnNTU1LM+csnT15FV3UWo+Xy9Pj49t6ef9Xld86c+W5nZ7/LKs2XK5WJ0VHrl/Pnzimldvf3X5z0jafGx6fGxw+Pjrb39pRSXwaqVXdrenzcKma7s7cnL56W+dnZybB6uTt7eweHh1Pj46NhCZxirFz+5uXLV9nnn5+ZmjozMbHdKU+7PDJSLpX2j47kny+zH7MAUEqNlcsjpZJO1fZhpnmbP5suzMxUZmbGA+feUME07yj/26/9WoprnWjD008AAAAAAABAIZGfDAAAAAAAAADojtRM6+U76kSRntHZFEGvdne7zUnw8Xp39+eJkxAwQMojIzpa+jhwt6Z8UqTLtHtwcJhB2wOgTh+SSqlSqRSVUtVVJlt2psbHp8bGDo+D54+3jo+PD06SrMROqjlpWZsYHR0ZGVFKHRweZnHZ1WYmJgpwdj0/PX1+elp+vnC65vDl2VlJ+FRKTY6NXTKKKC5euVKJqNO4uLBQOXnBwtA9WLNjqROPoxJiKzMzOt94mBOPUyF7Xid+S7np9taW/hY0SfauXrw4Uiq92N7+4ZUrr3Z3X+3uykIG+u8ddaqrc3Nvv6Pp6ercnCxe8/6lS2cnJ1/t7j579Wr2pIVb3X5HarRm5f0eHB3557JaVcFfv3nT7VoMv/Luu+8GSovL6gDfvHy5e/Jq5mlBKfXzJ0+UUsHSrI6Ue0+6UPZO4PqoTz5KqRfb2y9Szfj9YH7+jPH6SqmDw8PvTrKdz09NhZZYF794/VpWVYgiO8qnMSS34JfrOH/unCyBtHdwEFUuWyk1PTGhi/omT3EHMOjOROddT09MhKZ2h5oYHTXHSv/swoXQ9/JM8xbnp6dnT/c2HV3TJHS3DQAAAAAAABkhPxkAAAAAAABAjwxDUqsywuXjiZH7+rNk74hCmhgdNcM6D46O9jIoj3l8fHyk1Fb2Rc9yYqxcHi2Xj46PKek5KEZGRkpKHZ5O0YQP6xyivTk46Lg/R0dGzhk5P7v7+3moKK6zpxyOjo9f7eyYH3A6rCakkozZbrLR8sYqp2klY3/XqeJoEpPj4zOn3/1Yqe92dlJP+R4fHc3iwteVybGxD+bnR8PqAZ6dmLh8/vyVd98NPlSZntZJsBaSK6I0NjbkB6nZq39++2g3icc6MYa93XvyPeoR3Pd1mE8PIfUXJ/+Xb+r1mzc6BUs3AzPxOF7+ufmyKjC6lPzq77ffI5dVVxuWVF6dvtvVtVK/iBSIHi2Xp04Scc38ZE86kdsku0KSusXl8+cvn1xGv3758usXL5RSwZNY1Fg4NAu9W1F5vOenppRSocnP56amRsvl1NeBsnba89NNVM7wwWfpb2ch7OSv7e7vv+5U6lk5k/NTdHZq6v1Ll6Ie3dnb29nfV0pNjo6e91vSYs95udfFtOXQ6PsCXucCSeyHR0dbHt8OgGEwWi7PTExMjI76p3lrZ0+vr2G6MDPzq913Qa1FiEItXb3a7cv6KOSqRgAAAAAAoFvkJwMAAAAAACDv+lI3VQo69VLyaF0fO/v7unTel0+evMoy/6QwpMLVdzs7mdbuGzgds7zcRkZGxkdHfVqgI2jPIUZo/uAKhk0rpQ6PjoJltQarcibcrFqvpuPj41KpNEBf98zERHlkJNOUyISmx8d/cOHC9t6eo8LqSMQ38mpnp9vz2GMjHaiPgmUJhc5FCQrWKnyxvS1n44Ojo6gEVF3AsABV/iRIvVwqSWNwrA0xPjoqKcHbe3uZNn5JY3NfcA+PjtKtaamUOjc1NVYu64tRrg7w0LZ9bnJytFyOSgxWzoD+jGL9ocISj3XGqSPd0SqcK7/UXxNJFIOovb0tX7c0Cd0MginBiwsLlZkZ/dVLwrmZba7XzDJH/T4FmeWVVUS7shLarUkMM3NenR77eybu/sYv/7KuDCy5oPoKOzU+PjU+3lUm5ztnzljVg3VtXiGv+eU337zqch0iR7bzqT8zdteXT5683t1VSv3W6VLkjmkZKzPclLzicfAa8WpnZ//oSCk1f+5c8O939/ffHBxMRSxoUkp7qid0D2tm4xQvT5et/mFEvfdXu7tfPnkyPzs7EV10Wnh+nN6UntZHpfY8bEW8D6JTrB0lx0O92t399vVr/759Kpn5SbwTqLUugtMFewcH+ZlCGS2Xg4sEvdnff9PvpWcGRalEOCgG3pnJSUf1b5NV3PvtL8fGQudnotYQsfhcEE2OFaYSYqQJAAAAABgUTEgBAAAAAIDC0gGsvaTjp3um958xWL8IoSQrw/OPd/b2tgcnkawH3p+fj3pIIkFDo05jCEYY7+7vp56io5S6cOZM34v/9NJkRBxYDFKrluTwYaND/EdKpbJR1bOj7b291ItwZmSsXA7NLRe/eP26lxvTFUnWNf8Z+h1FZbGGpnZo7uKBUgTP+uXXL15IEb/+MtNFDo6OPLMxP7h06cXpvBG3F9vbpVLJyoHZ3tsLrWlcgHRfk0+A8vbe3kipdGZycjT6vJHpAhZRVZrN9GCz0KXoqg14mh4fj8qVSnHJFXmXVPqxl8+f15HiU2Nj5sZXL14MreatnBVuyUHNM3OorkfQOuHQJ0HUbBUkHkNSjnU6q7Sl0Ia0dO2aOmk/OpMktOWYrTTFgsyqU56JldhsTTGZ8z8+5XOt4rdHR0fmMiJnJifNYfWFmRn/nNLLlYoupyzpu1YH7xevX1sp0K2nT7u92MXIdtas/exY9s4xjxc14ZZ8Wkx/tODMhplMa3ZaJsfGrD7Gq93dr1++VCdLbFivk3pmbLep0RZdnd6ks9Mvnz/vWAHNyvCPYh6hDr0pPW2eCtysP9uMWKgoKrf85yf7UHTMqfPcS+bf9zfF2iycvuMx2A9mj+dq9bqu5spytb7PYBkrl0uBmsalUukwes0sYKhcmJkJPReVR0bM5SGi0ryjXJ6dDZ6EfYp7uzlG/UlUZmYWI66tAAAAAIAYyE8GAAAAAMA2JEmtjmIjWb1jT8K/CsCRSxAbua+WH2aznn0wEcudgtUVd77WhYiKKD5i1EQaXAvOWJaDw0Or3OjR8XFoxldQsLSLUmrv4CCtPGoUSWjgdbdn6VKpdNZIwNvd33efJXKlq+UbRJ6TdUNDz81i9W5mBkK3VXPnZ2fbW1uv3rzp6ln5WStBcoR86P3pqH6mWamewVwO09cvXoTuQJ3m8Wp3V2dy/qyvofmZeufMGasv8ebgYG9/Xyk1Wi6bGS9m38a9ooe8YNbtTYoc6sKGoayakEFZnELPz8zoEnyhtYslbDfFt7aWPNg/PEwlpeG333svqkhgVNaNo3gUEcCFpzMAzcKn8RKPzYZE3TAkIRNuOr9RZvyC+aU691IaniRC+Jy1dEFmMwP2VG5zxJDQXZC523x7vRnCnGa00hF9cmulfxvsgElndeHdd/Vf/t2335qXCf/E3crMzG/+yq+Ylyp5F51JaHbhfv7kiTqdhRsjQzjFbOcojillR4K06ymJ51Gj+tvVixej6uVKHuzXL19aCwBZ+UXuyfN06yd3zPXt8GhYarQWlfXkf4PAc1bf89V6syhksPR0KMcaMdafmfvwryMqn5+ZnHw/bDTnmX+uDVaKddTqRRZzvOBfoDtXqdcy/HHnkB8rZT06MTZWPkkkfr61tZfXEtn6fk1ag6yslcvlybExdXx84DetfXx8nNudDwwcfdqX9Ry7TfOOIl3lbot7d+TuJsWWUVY5AAAAgDwjPxkAAAAA0tSXuqk9TjHtNv4jlXfs7yL9g8KMgNdCQ+HTogt/DVZOVA94xniZ/IvsmXxSdFT3yU5B87Ozk2H3vHWplrToYNOhOvBDD95uhR7sZnW+oy7DjPIcE4Y88wm7NG3v7ZVKpWCVy6nxcUfpS1OuwjHdrLDUGNdofVAnP7Fnx79OlEWS+T0vbcL69qOuVhZJb7BYtTotvYkR7yhGByOqjtlLZ7HW9y9dMkOirZJcoc5PT89OTyvvsHvVp2u9zo1PsX5sR//80iWzdtPE6GhoYOLzra2Oy5pIl3usXD4bXXk702VHrDKMmrlEy+ToaLBjExwsmOnQWeQwR2UC6Ij50AtNimfXdyLWjklltQXH2cBxBnZEnZL8iY5CE499MjB1alywkCz56ug73bBlRlfmPEO7KHLi1T0rOW12FXYfWjZcz7I6+kXugszJjyMrk7lpJBZak8A+GadWDvCv/+AHug9wZnLyg0uXdMcyqvfYVcfbTL49ODqaGR+38vrOTE6a/Vh50+Cuzme2s0PUPQjrGzRFrVOZSp88qmcSNRh58vLlL1+4EJWEOTs97b77UPjUaB/WkgRRHInxJs87Pj0bwXmuY+Vbodov88pcFaLb23zd3qTrdt3Y/q76KmPA4KKcDubA1ue20bmpKasIfK6WBpufnZ2MmC8KrnSpRU1s7h0cHB0fq3wvamktfWXJ8wKCpovnzr3xa7QyO3R0Ooh6pFQaGRlRSm0NzbquQP6dnZx8f34+rVczbwfEu53RUUbp390uZQUAAAD0BvnJAAAAQC54BhOkyDMuIUUkteaW5wruoWLnvvqvAa/IfQ2IkZoS+42eZJb0Zda188wm8head6ROF1qJJyfpSb0RrDB8cHj4XRrRGGaI0ovt7W7bmCPPdnRkZGd/f1BCZIaKhDS9OTjwjArKJx36sL23dxiR1RYVr2Y6PzWllHJkBvoYrIuju2y1cHcq3D2HQibrCsdzO16jrRRTpdSr3d0vIy6RFp0toLpJN9X6Gzurxdv5MZ5SvXhxenzcKi/mIFkZV4y6cw6Dku5r6mXq7w8XFoK55cHi1WcnJi6fP2/+5kVEhvb56WkztzaqV6lOgtiy3u3S83cvZHN5dvbw6Mh9Wdk/PHTfDkw9/ltnMkeFXHe8Gn77+nXHxHhPshZMVOz42cnJqPbQFcc5x1F6zpGXQrUZ9Ia79GtUllfWCZNAHsjRoQ8NOS5CO7qSSifHgi79HTsHNXlBZvO6E7sgs5tVWta612Cl3vnki1qzneYl9RevX5trGI2NjlpjYasz1tVgxEqD1LvuzcmI2xxV/fzJk4PDw0unJ9ILkO0cxXELyZEg7SgTnXBONXQviag+mD4etS9PMuTfn58/MzFh/X3Hu2bunn/q88buNF330NXdk8z6Su2Z3+v5Z57ZvL2Zt3e0w1N/5ld6OthEo3R1pPtX/9a6TckexBTrqEdDU687rh2mTqdeB1OsQ2WxMlcSPhO2llc7O13d3tWmxsf/xz/9U4wn9kbo7FaUnb297Yi89Fw5PzNzbmoq9Fba9ps3Pq8wbcy27R0cHJ7EmR8rdXh0tH9wwPq2QJFcPn/emj/vyoWInk/UikXJZTQOYg1HAACA2MhPBgAAGGzDkNSqYgXEJ5TuCusFFuPOZVeCaSrx7nq6DVZ6Tw94Blik8EZ+IRpBb7r8yoLJOQ4/iygx4WN+dnYiOsk2uxT9oUrFv1ypXI6VTt9xKfrQOm8Ou/v7/jkMjvAUs7rdl3mKTUmLLhxXmJzhmYmJcljpg8Jk3mrBM6dPgvr5qSn3cgP+J/ALEVUHc1VAwy1JZWzpBZkVsP0NZ7JuR/9ifv7Zq1fdPks6Bmaybkcxrvj5uZR7FikyxejR+QTgfvPypZXuGxo+LroqVZTzdN+ogqtaz66n/kdr9eJFR+qs9vjbb63U36CvX7x49eaNcq4pk2nQueNTm53JYJXv4KBy4XT++avd3a8DV0DzY2YxCxFca+bVzs7+0ZH8HOz9Wh9hanxcJ35//eKFfwa+W3B5LHPgb9aYSmuo7jizORp5VCwaWZcYIDrPxLxQxks81jV/SJsHhE790seX/DN4ZOmJVjmg5GhK5WqS24LMbtYNJqsnb26zZ2/cvNBbse/6Q/315qYyBhTBm1xWol1XAwErszoYf7945crY6Kie9DszOSlpcqGjmAJnO0dxJFI6BnpRT0meAxlvxZmo/WbuZPfdVUfta0FqdFo8b3P73w33PF305r5zX0pPZ9E/JMXa0u19MVmj7ZtuVh/Wkxih0xdB1rxNfuY2hTkfYs6EuAXz0n1W1426/ZfiRErqzkxOToyOxnvu1Pj4weHhoERW+ISymAsiW5nbE2Nj5VLJ/+0ki/vw8PC1XwY4gOHxwfz8Ge+ApeB6rFFiB1y5+a+h093L9nsgAAAAskZ+MgAAQ6ovdVPdN1az0Pu7IENVUzGJYIysqWMKWQyh6xxneuPEDOQdoCyaHsh/7muMN5JPpJfeT93XL19+/eJFV4kx/rI7VQ7VKVGHfaR+Bps7ezZ5IS+LnP3GyuWzU1OpvOCX33zzKpvG30eO5dILnGc7UiqFZt4OynrwUX7zV34l9HP5kxCWjpm3DlYgS1TmrUOew1mCgp290EoUDlbnLUa3TQcG5bkn1sdkXZ8Qw7+OGMFdPn9+PiIkLt5IM0ZvJCfdjBg923irxXuGhJ56o9N3+rv6aoqU7rtw8aK7NLd2dHzcs0bl33JCBzUvwwq9WivyfB1I8NbMus0dv5HeFAd2/43shE3nygvnpqbcOdKvdne/ff3asWhRFmeVG7/2a46tKinlKM7zYnu7VCqFxiGlW3ApKlJT6gyHrpHRVYhzlBjl75TzZJhuTUgg54KJxz4Zifq4M3sjGRVWBYac7nvL0SoZUKGHp/SFdJdPDsnUj0d90khekNkMU+7xecMa0Vh5aHYx504pZNZg3Op1W12OpatXrZWCg3c8k2Q4B/tFVnfIyv17/eZNcOUmsp07ispddAyWo9IXUxklReWROiYNojrDHQP9hyc1umMqRa7aZCjPJFvPeRvPFNzeZN56zoT4z5t5fpv9+tJJsbZENYCom6qSYh31aqGrc1rrxAXpRfGEY2k8U3/3m8VdDFzELgkuYhQGF3krD24JTn95zhiriNXzU5kc64Hq3NxRsgQBaTzPt7Z8lqcMmhgbGzeS4Qu5TjeAvnPHoEYV9+4oiyRtldnij6wpCQDIA/KTAQDdiTGNnly3E/HJkdSaW12tJxelq8yxJFko8XJfY2SL5TnjovcKnPsaz+s3bzxn+R15JlGyOz9TZjYVXR0OO/v7O97Jh+67wiJ2qav52dmoE69157hbwXVGC9kexsrlc97Xke92dvYPDzPdnt6YGBuLKqjY0aBn3joCtro6ri/PzgZvscc7kK0okJ8/edLtKwh9zPamuEQq/DurUcm6np1Px/fSsTOZ565jzpN1o+jeWozU3HirOHUbfKZyE0cV7yuO8ZR4XeiuAhaHOd3X/KcjkMus/v0iLJ82I/59YP+m9Y7H+eFnm5uTY2OXnEMqn4O3X8WBTaF/8+R01N0PA+HvPwuczeZnZyeMi1qPg9pVIPk5OB2kyyCH9nkmx8ZkjBxVO0j6KiluuXQkDg4Pvwtb+kfCAUP7AGPl8us3b5KvY+JoIY4Ycccpl5gYoCuhpVD1tcPRnQsmECoSj4Ece5u0fDKg+L4O8+kehb4uy//1VTW7PCtzjBM8C/ksf6BUSN31vpdIslKLzZsa1m0In36d1V+y+k7mt9NxxSjr9krwnoj/hFjHDOdg0qa+OoTe+ifbOTarvZmibqg5boclnxSNsSqQow8fo1PRMbbEfZ/RPYhOfbLLvX6W+75wAVKjO/KcCvOf7cxV6Wmf1dOU91SS51g450PmbmPDYkx0dzux2d+oqq5uux8cHR0fHXW8mW754ZUrwek1Bz3zFuN+ger3/rR0WyRcSMRCaL66m76P2dUdTCunPVc70DI/OzvZqfhq1MS+Y3lHU+xQkB5zZPV7hg660/t39/fNGx+hWes+EYD/+Pz5QIcrAEOlPDKiV17YOzg4PDrq7/Zk6uzk5Pvz8/qfnsu7+Mgo/TtJyIdDzvvtAJAf5CcD6JEhSWqNN+WX6B3zEWGcf9W5uYtnz/Ym/UZKq02Ojp7POOjHqsCWYglESyErIsaWMGWiizeKVVMr3hv19v5mdQAAIABJREFU6BOdDsVw3KFPKNPa4JSZTYV77fNuHRwd6bVaP+i0YLCn4Hq3OjA9NsfNrXiLNQ5Qtp6/d7qvJqoVJs/2/MzM+enpnb29gzQ+zkip9OzVq+Sv0y+eESFB1g1Fn4x6S9TN7I7rr2vudPpgtnzQAHX1pYP0anc39mG4s7c3m6ArK7fAY1QkViTrRj03jWTdjuJNFHSV5/n2jWKte5KTS22MM2G8ZXRiREmmm+tCuq/l4PDQWmPCTPc19bJWg3+D9DwFhQ5Ivwkr/GutpuQZ8ujzhWZ6sPtELvocs5Xp6XNTU6+dkzMb//RP7uxo997IouPh+PiyikrUCE56YlGjMD22CnaoUvwUwbBImfGTn624NCsaz+yTpNLTcBx6jmPNcWIvQGQ8MFh0P8e8fsVLPDYvnRzLQPHoYbIMefRgNthllY6WvpEko/ieZQLHLsisbw3koSBzR1YmszkAseYZfMYUVt/Y7MVZw6KoeZWOGc4q0Of3v/EUnIPyz3A2ke3cG44pFMeESdSQMPkNSsccpmP9oxgJ0l0hNVob6NbuzzP2wHNS0XM+uTc3cfxvE3j+mWeTyNt1OYZu40ZIsbaExiy9dC5DGVzQULza3f0yLFjiSqe7rvGm63MVexO62zveUQ1dVFo4bgd0jGmJWoTRJ14lz7etJb6i22fJLZio2y4+YuTG94W7tGyQOQ2ulIodAavnzK1i7F3FoD5//foXr1/HeHcAg2JidHRkZCT0If9iDAMqoyJM2YWdZzS0LMC4A4BGfjIGQF/qpvY4xTS7CoGOdyxepbgs+Pf/ksTimzrmTmQRdRqaZZGwPqGbuZBSrqYF+47c1/hvlEbURaYrKVBmNueyq7rsONyeJD6lv3/pknlb4uuwOP54zk9Pz05PqwxSsvN83yK2c1NTYyktEKgGv5SrNjk+HnoDLF7mbfDO0KAsyhslduatxTzJuG8Jd/T+pUupVF37u2+/9VxZOdRgXX0c36PnACH0BnNXRSbPT09bNwW7rVc8Vi7rbchJQmaowifr+ojRpYy3dEvMtOEcjOzideriVPTtvlX0uGYU6b4O0hvxiTvpZeqv5yI+/sN5//PPNy9fdlyLx6eR+Czbl/VwwGc3ehUQDhzjwazp9+fnz0xM6H923EXuwyGL46XjKVF2xZvofvUPr1xxDDMnx8b+od2OevF0P1FUENXO3t7E6Ohk2LEsxSus4CeRykp8jt3riB13XD64AQ8MotDE464y9PRVSV+4+15oFEBuyTlHn3Ck+x3awZaTjPRJ9H263nc23AWZHUODnBdkdrNuNVpjc2vQ5DMRZ00/OhKbO37FwdugwVFM7AxnFRiOBXvFViRrx0Er2c59FzUV6U6QDv19KiPEqCF/jCFYpmeShKnR7lv/qc8euKcOOk5DuRs/41zhGYWSeunp3szYe97u9FxS03M+M+edgRSRYm3p9vZ6V2u5vtzePjg66nZB/Nnp6XjxWvFO5rm6jev/dchSlfKzI/U6lMSExCsn4J6+dst5xILMlluJxJ7MlTe7jbexJtu/fvEirRC1TFXn5hIWGZIzQ1chHCarAftEZW/v7ZlVeafHx8unEzhf7+7+/JtvYmxMf5VHRkbL5Te9uvEKDJuxctmzwHVJqWLEpjqkFZZpiVcqoKPs8iyKOmGF3CpyfnJ2RfmiZFqsLxRJrbmVeoahOUqPkkrBwK4GUfOzs6GxXz7i5b76FBmz5CRCOj/SLVnp0LMk2wHKfY2NMrPBVx6e4zq7YzbJsePOfzszORnjkvQzv9skHddP1VIvaF/IXlAwfTRYpa1b5r2E2JOzeROVZxvkk3nrkwlD5q3wTL9xJFRoVjJ/kOdZaHJsLKoqXfJTxABd4GKMd6xk3a4KGkedTDxLGSepXp6ru7wWknV9xOvuxskB7r7jkZ+uRYwOZ4z2E2/slqu58q7GZV21opyn+/pHOcga6i+2t30SeqfGx//HP/1TKlvYkf8J0/9+kv/ZLBiI6XNqGsLiwB2/o+29vWnnrGAO04M7tr3QRzeNqgtWyRGr0ojVNXVfjFJsCbq3/zzsrPjBpUtRwxlZVCWqb3Z0dPTf/v7vk29e1HXNMbhwtMDhCXgFYNF9v9DSoFEnVfPMT+IxgB6Tcag+a31fh/l0n02fqeT/+hzV3wG4HkSbvfqOZ10VttzD4NaZt4aK1gDHHK14Dl7MjrHVGbaGtF0lEFozHsERrrVtXa1R1THD2ZqW7OraSrZzbkXNuTnmRhzj3+SDX8cdrhg1n3v/bbqnJd2TJ6RGDyfPeW/Puy2esay9mehOvfS0590xmp+JFGtLpinWKmKe88snT15Hr9X4WxG9qdghhTGO7vzcMxXxQvXMPb/pXVr58vnzl0/Hn/gErkRFrSSJlMtzsMoH8/NnwqJ9Dg4Pv+u0Dun5qSlHiLv7nubU+Lg7WH2AkoSjWnWSNfc1nwg3n9ieqBrv6vSC++bfh278z/J0PvF3bmpKKXV0fHx4dHR0fEwWd+qmxsdHSqX9w8O9g4N+b0s6RstlvXIBDSYLHfOVRkdGSqVS8PdvDg4K/41klNeQUUJQRpGK3PILlaP85JuffJLnwN+e6VnqoNab1L5T75gglDmeHgdAa42NjZt/8ie9f98+Kljuq+rh3YJhu8k0VIp3KuhLmdnksrv69Osqk9xA975SX+Aq3tJW/9df/dVj72nlnEj3Yp3iFXntpz9N66Uy1ePMWx9pnd9yNWbO7Qkq+RGU/KhJft1J8cpV+tGPUnmd5EjWHUL9OlHEuBDEO+fHGCTSohLqzTnN/1LSVcuJ+vb/enPzD+7d89247vkPD/372/7n1ZzPpWTRorIrDhz6Ov0KpEtr13XsHnRslh13VMJGmPxa5j4GHR/fnRMePKUknN2KEd6tnLs354c/gIEWehkKTTzWlwn64QByTqdlStKaJA4FcwBWfud37vzu7/ZjA32FVq3vWJA5/58rISt1xEpNtIs5O1OFe7OvOmY4W2kVnvkqPf6ie5btXPgG3DOOJCtHQm9U20uSwHP8538e74n5l//UaA6ogeNZelp5LxjqmbmXXZIejXAQdVtTJEZab7enuB7fHs1zu42x5LTyWOo0VLxaYv1Nve7Zd5ek9E6S4jpJCrx1tY5Spn64sLC2vBz76fGOAlPCJprPzPbkXe60yj4l/4JE7K/JzOL+8smTVzs7qWxPRuZnZ3+pUvH/+wHNRc+Vd86cCV2pJJj/n//2E2S2qJ29vZ1OOcOPe1s0tJD+7W//tq5AllEXKJ/XnRju//jHhQx4yFF+cv3hQ/e1vPc3d3MVoI9B1Hr2rP7woeMPyH0FhoHjVJBp/WcOfHQU1ftKPZe7wH2qqH2Y7gE4JIfz6qefBn9ZyMxb+AgeXKlcNIfkaOql4JFLsi56xjpRxGg/XB1gMc9pXbWoPNdDsAaknpdCjo5U6Bbl2Y2ho6LpXZd1enDf6WuZ45Pm5HjUJxPH6THPJ0MA8Lf66af6+sKZDcAwkFDy9tZWZWZm0DvYmlmQeXFhoTCfK11WFkFjY2Pp6tWB2FfWlku++qBsfChHtvNAf64h5Mil1BkOuU3xGmjutCi98zmgkC7PzCXzz2iE6IuEKda0276Il9NoPYvvLiP+y2eEPDdQJb568WLto49S2KzBlGRnitDLMV3u7CT/ykToF9evs1Za6egq4uxd++ij2LFwaaW4q4jlOfp1Ckpxn6uwU6vo+3UwyfodoaL2m/t7TH0zVHTLTNLa+yvdNunzsoO7r9xylJ8MAAAAAAAAAAAAAAAAAAAAAAAAAAAAIOdG+r0BAAAAg6rZbLbb7X5vBRLhG8wUxwgAAABia7fbzWaz31uBOBgFAAAAAADSxUgTAAAAAIA8aLVaa2tr/d4KoGhyeGQN6HQcgev9MhrvaY1GQ/+8uLhYqVSiHtWWlpaCj1ar1Wq1av1lq9VqtVryykop68V1XJp+Qf0U89XkXSqVirwI4MPRsBO2atV9w6ZVAz5CLwrK76jUz5U/aLfbcmCaAdDmqcDnqLTOFdYB63g06k1VRCcpuBlRb6q4dHav0Wg0Go3l5eWOu2J1dXVlZcVqfubr1Ov1arXabDaXlpZWVlY6vrVuh6mr1+utVqvdbtdqNbPFen7SeGJ8HHfL7Nhu3X3U4Obdvn1bH/537tzJegu72jxPrVarXq8rpTy3v8fcx0ge9LLJFRjDw/yQz241Uf2lxO6odOyNODaG4wuCEwWQkdCBbZIjLleazeba2tr9+/f7vSH9V6/Xm82mOZqL4ji/VSqVHlx8Ux9n9WazUxE67tZSH+8n7GsBQDHE7vZkcV9PMdAAgJ6LuttbmHFxPFFDyBg3LqP0eDwSb6QJT9YR4Y6VGra5enqbwDDL9MaWcp4EOAOgl+J1EUNDC4aqlaYes+qIHc0uZtXxpiqbmNWhaiTISLFvjg8QuXB0vPt5+/bt5eVlz72dt7jc3hjoG75Zx5+H6lm8dG8iNCwdjyzJXk4yp+cv9nRcVA+hl+05NHB9dXW11Wrdu3cvxgtml9wxiByzhXHyk1utVqPRWF9fX15elldvtVorKyu63ZiPChm6hD7abDbv3Lmjm1S9XpfzVLvdloCezz//XL+OHOdLS0vtdvvWrVv6TZvNZqPRaDab9+/fl8NY/lmtVu/evRvjM2IIORp2wlatYjVsWjXQUdRFwf+oXFpaqlQq8jqLi4vSeZKny7PMI67jUdlut80nSs/SfFMZa+l/mr2cqDeVTZXLtn5Z+b1sbcc35dIZg5zefdbOWV5eDp1JVCejoG47srdv347X9+2oVqsppVZXV83P5f9J44nxcdwt0/2ou48aJCMQeXR1dVXOCdlt4crKSleb56lard65c+fmzZtJXiQ7jmMkJ3rZ5IqK4WGuNBqNtbU1mfjTu/fu3buylxx9Bvej7t5IFI4vaJwogIyEDmxrtVrsIy5vqtWquZ3DrFarWaO5KI7z29LSUg8uvqmPs3qz2akIHXdrqY/3k/S1UtwMAOij2AONjO7rKQYaANBbUXd7k8xEFUPoEDLejcsoPR6PxBtpwoeOUmi3261WS3aymUDieLTw6G0CwyzTG1vKeRLgDIBeitdFjAotGJ5WmkXMqiN2NLuYVcebqmxiVoenkSAjhb85Plhqtdra2pojcqxery8tLfnv6rzF5fbGQN/wzTr+PFTP4qV7EKER9b6OI2tlZUWSbHsQlR1vOs7RQ+hlew4NXE/ScrJL7hg4HWYLj+NaWlrSPz9//tz8p/Xo8fHxysqK53Oth6rVqv7nvXv3arWa9cSvvvpK/nn//v2VlRXzjVZWVu7fv9/lx8Kw82ycx9206uCjng2bVg04uC8Kx86j8v79++Zz5dWsg/ru3bv37t1bXl42f+l5VEYdquY21Gq1zz//3PqD0DfVb2e+rLW1UW/KpTO2+/fvJ9wVsnu7fZZ1+Uhd8CtO/kkd4n0cd8vs2G7dV2TzIfPo6Or7SrKFnpvXraxbTrH1pskVHsPD/HDv/ONOuyKqbxN81Oe0yfEFEycKIF3ugW2SIw755H+Ocpzfsr74ZjTOGqw+g8+kUFoS9rUAoBhid3uyuK93zOkXAHql493eIR8Xh94QTPdj9mw8kmSkCX/uHTvMu53eJjDMMrqxFXxUnwQ4A6DHEl7io/qcxW6lmcashsaOHmccsxr1pp5RIqFvSlQ8ssDN8RwKnjpMMY7uHMbl9sBA3/DNNP7coTffb28iNIJSP7JiSD4dF7qdfW/PsVvOAJ1Seia0VcSpnxzkqKkta5M4cuXN51qp/JVKxcwyX19fN/9ZqVTu3r1br9f18gBLS0vr6+u9WQ8AwyCqYXfVqlWyhk2rBqJ0vCiYrKNyfX3d+rPl5WXroG61Wnfu3JGFKqUAjkhyVJpF3qrVavAME/qm5rtrob8M4tKZ0OrqarPZVEpVKpWV0+tp6YesZQ6VUu12+/bt261Wq91uy9/o6txifX19fX293W5XKhVZvkuWArp9+3az2dTL81jXC5+tlTeVl3XXtPT/pKFbKw/JNiul7t+/L3+mlFpaWqrVagk/jrtl+rdbdx9VPki73V5bW+t2qfVUttCxeTHIAoHtdlu+ffl08kXoFri+vl6v180GGdVs5C+VUvfu3ZOXkqKsSqm7d+/K53K0DeU8Rtxardba2lqr1VJKVatVWUVMv0Kz2ZT1g2VhLf1JV1dX9R/ICVYapOe796DJDRWGh8WTpDfC8YVQnCiA5HwGtiLJEdcXui8qlpeXzYuOuxfabDalZyiPqpN13Ds+6n5ZB8ewqOMruwdx5hO7rSPtOL9levHNbpzVsz6D+0uJN+7uOECOGub4SKuvBQDFELvbk+J9PcXpFwB6wn9QrAZwXBylXq/LqFNu58nlRq5KjiGk48ZlTu6tuCUcacrH7+rOqXvoF3UbK+HOdAwMO848OBoG0kVvExhmad3YUs6TAGcApMvRwegY2xZb4VtppjGrUQGrKsuY1ag3zS5mtfCNBBkp8M3xwbW8vBw8XyXU97hc9xC7Y6xCvHu+g37DN0b8uXuu49atWzLlIr83I6K10HhpvT2hEztdhXb0JUJDZHFkqS6nyBJOxzm494ZP4HrHiA6fwPVbt27JK+ij291s3NkQsY/9eJOQHV/WfQRZRaTTGgWIkVReRQ9RgmQG1tEcG42G7DKllLQYvROV0S2WnW49t1qtWjXT79y5o+d8gYSiGnZXrVolbti0aiDI86KgWUel9ACsvzF/o/+4VqsFzwOxj0q5frdarWazubKyYj0a9aahPTCfTiqXzoTW1taWlpZkeae7d+9KL1A/eufOnfv37y8uLgZbnXQ979y5s7y8LE+3kpMbjca9e/fu378vqw/KgKdarcoL3j/R7W3jlZUV/bKVSsUM6I/9SaO2Vsg2q5Mu8r179+7duyeNM/nHcbdMz3br6KNqt2/fXlpaitG9Tr6FPpvnSV5HvqlarabfWr4I/S7SJs03jWo2y8vL8lx9GpFxuPxedWobynmMOMgYWJ4rx06z2dSvIPkk8qistSmjRHm7ZrMpH7BSqTSbTfkb/wOhZ01uGDA8LJ7YvRHB8YUgThRAch0HtlqSI64v9EhKlts0B2Ide6G3b982H7U+eNSjHV/WwTEs6vjKjkGc9cR2u91oNLrYic7zWw8uvlmMs3rTZ3CPrOONu90DZMcwx1MqfS0AKIbY3Z507+spTr8AkD3/QbEawHFxKAnd02MKCZfUycmOIaTjxmVO7q14ijfSbDab6+vrEsjoyTH0c9zGSrIz3QPDjjMPUQ0DqaO3CQyztG5sqeiTAGcApMvdwXDHtiVU4FaaacyqO2BVZROz6njTTGNWC9xIkJ0C3xwfXMvLy5L8lq4+xuW6h9juW/8J7/kO7g3fePHn7rkOPZ0iL2tGRIuoeGkRNbHTVWhHXyI0REZHVowpMpUg8MPBsTc6Bq6rTjEbPoHreirPnEBzNxtHNkSSYz/eJGRHHY8g/VmUUt2m4rvFr5/carXM1R+DudqOQ0inj7dareXlZfMbunv3bqPR0OnjtVpNht86Bd9i7WJZ7mJ9fT3d3YTh4WjYsVu1StawadVAkM+x4z4q3awjLrh0ZZKjUuKhu33TGLh0JmSulCbL+K2trd29ezfhy1oLBMq7pLL/K5WKjKtlpUP/oZHjk3pubbVa1Ws1pTV9426ZjkfdfdTQl1paWup2JBl7C7vdPE+Li4v6K1hcXDRnt90czaZarcqqV7du3VpcXFxZWWk2m+ZSYVm05Hq9bq4qJwuq6X/W63W9LJa8qQzFZasWFxf1zXvZjEql0tWu6E2TKyqGh/nh3tt9wfEFwYkC6KUkR1yedeyFSidW/rm4uGiN4KIeTaVzGzoscr+yozduPbFWq3V7C8pxfuvBxTeLcVZv+gzukXXscbeDe5jjuc3x+loAUAyxuz3Z3ddTnH4BIAeKNy6u1+sSNCZWVlZu3bolPycZQvbr3koM8UaaEiPrWbREv1HU0M99Gyv2zvQcGIbOPDgaBlJBbxMYZhnd2FIRJwHOAEhX8pnn2ArcSjONWe0YO5pFzGrqAauKqHj0SfEmAQZFVKHXZrNpxpp2pY9xue4htvvWf8Ir7+De8E0Yfx4VfO6OiHY/2vGevk9oR88iNEI5SijL60h13K42L8YUmUoQ+OF+TcfecAeuq8QxG5JObB6tCV82ybEfexKyI8cxogOlJK06drX5UPHzk6WpyQ/BM7iuLh16OZf0caXU+vp6cHWKpaUleeV2u33r1i35tuRkFLoZ1m/kSsDSJojH0bCTtGqVrGHTqgGLz7HT8agUckS3221Z9Eh+Wa/X9TW+3W6vr69bS8fFPipXV1d1/8Ca0On4pt3i0pmQ1eWqVqv+N+MdGo2GzEKakg8aZaWcSqUi32+z2fTvMjo+qefWZjR57W6ZUY+6+6hBMZa5SrKF3W5eptzNRkaV1Wq1UqnIWdQ8a2XUkoNLdZqbpDfVfMduF/Ry6E2TKyqGh/mh97YIHqp9wfEFxYkCyFJwYJvkiMuzjr3Qu3fv1ut1We9W4rrMv4x6NJXObeiwyPHK7t54cN3TGHcFHOe3rC++GY2zerDZ7i8l9rjbIZVhTry+FgAUQ+xuT6b39RSnXwDoodC7vUUdF2uVSkXfskllCBlbz8YjsUeaXb27e+jnvo0Vm+fA0DOu0TM+Vbo38R4dKvQ2gWGW3Y0tFXYS4AyAdGUdYONW1FaaacyqT+xo6jGrqQesKu+Y1aI2EvTG8Nwcz79arXbz5s3Q/GQVUeDaR07icq0htjuoIPmVd0Bv+CaMP089+Nznnn7om/YrQiNU1JGllJI2GW9JkRjtJ0ngh4Njb7gD15PHbNTr9cXFRetoTfKysY/9vkxCqpMmdPv2bXOlRR8+c4kp5Ce7yfm90Wg0Go3guV7OL5J4rZRaX19fXFzUradSqcjCYHoo3m63zS+v0WiEXrdqtVrPxlEoGJ+G3VWrVik1bFo1YPG/KASPSvPPzCNafiPrrJgX9Zs3bwZnXmIclfIW5mLGepM837RbXDqTaDab5kDI2pOxLS0tZXE39/bt2ysrK7qnaDbpjhyfNKOt9edumaGPevZRNVmvK+b2db+F3W5eptzNZnFxUTZ+aWmp2WxKCod+NKO2IdMTUSPn4BRA1KKbsfWgyRUVw0N0xPEFThTor2az2W63Y6whmvC52XEPbFM54nLI3QuV7qIeSrfb7Zs3b37++ecdH81u4ON4ZXdvPHiyCnaGfTjOb5lefLMbZ2W62e4vJcm42yGtYU6MvhYAFEPybk9G9/UUp18AORN7bDuIg2JVxHGxda1ptVo63DOtIWRsvRmPJBxpenIP/dy3sWJLMjB0NIxu39T/0aFCb3OAFOxKhzzI4saWcp4EOAMgRT0IsHEraivNKGbVP3Y0xZjVjAJWFVHxhuLdoe6j4bw5PhCWl5el2Kn5y1qt1mq19DAnhr7E5bqH2D6xCqYYV950J1h6cwrKW/x57Hv6/YrQiBJ6ZCmlpOxwzyIqs5uOi9ob7sD15DEbd+/ebTabN2/eNIseJ3nZ2Md+XyYhhSRpd7s6gM9c4kii7UrD8vKyPnc3m01r1ZxWq6X3eK1WM5ctabfba2troV1hPVbPcsOBSGarVik1bFo1YPG/KKjAUVmr1W7fvh31yvV63briylos1p91e1S2220zITnem3aLS2cSjUbD3CGrq6upLNQUXBfHbJzVatV80+A30mq13nvvveCaUnLHQv8zdBnCKI5P6t7ajjp+nI7cLTNJu11cXJQPIuuliRivk90WZsRsGx2bTaVSaTQay8vLy8vLq6ur5pApYduIasnWWUsp1Ww26/W6/Ly0tBQ8pyUv2mwauC+0eBgeFhjHF9LCiQLx3Lp169atW/ECL5I8NzvugW1RuXuhZtdRBW4gOR716dxG9WBjb7C7N16tVs2tDZ7uPDnOb1mc+nowzsr0jO3+UpKMu1X0ADmtYU7Cvla8Fp78uQCQE1nc11MMNADkTOyxLYPinJCPLJeVdru9urqqr01pDSFjy3TuN+FIs9sBi3vo576NFXtjkgwMHQ3DTVehEXJD0PNRdIveZm8U7EqHIvE/CXAGQIp6EGDTcQMK2Uoziln1jx1NMWY1o4BVRVS8oXh3qPtoCOcBBsXy8rL/uNhfX8LM3ENsd1BBKlfedD91b05B2cWfxxP7nn7eIjRSP7K6miJLK/DDwbE3HIHrCWM2xOLi4p07d27duqXfvePLOrIhfI790J2ffBIyXpxGvV5vtVr6OL1165bnEzvOJSqlSsfHx11tjVKq1Wrdvn1b14++c+eOuV+sR0W73V5aWrpz5475qH5iq9W6devWysqKbG77ZNWERqNRq9XM7m+9Xm80Groouc4Xl1dQSlWrVVllod1uv/fee/fu3aPaEjw5GnaSVi2nRdV9w6ZVAx05Lgruo1Iptb6+vr6+rpcVaTabKysr0kWQ39dqNb2InfSef//3f/8v//IvVfRR2W635bCVxVoqlUq1Wr179668RaPRuH37trmQSavV+uqrr+Qtot50ZWWlVqvV6/X19XX9suYJyv2m7r3ESSbK2tra+vr6ysqKbiStVmtpaUmfutfX16WTp3e7Uuru3bv6j2WM2m635TfSFM3Xbzab8pB0Uu/cuSMv0mw29ZhWHjK/TfmDDz/8sFKpPH/+3Pz9+vq6XmhQVh2r1+vLy8u6tGDoBsuB4Pik7q1dW1trNBrm9dHqFnb8OEHultnxUUcfNWh1dXV5eVkfEXrPZLSF1Wq1q83zJCcBWdJSvu6bN2/KmmR6b6+urko/RNrk2tqa/LG72egnyuu89957d+/eNc8PjrbhPkZUdEtWp89a1stajzabTb0b5UQqGy+nUNnnFy5cuHPnjmNxgV42uaJieJgf+oQgqw/q3SsnBHefwadHEdUbicLxBY0TBfqh2YLZAAAgAElEQVRO+h4rKysxZsyTPDdroQNbd7fTfcT1ePt9BJevdvRCG41GvV7X/U9rdON+1PGyIqoH23FYFPXKnr1xa3V5Pa0RxT0k6cHFN/VxVm82W3QcWccYd5tHaNQAOWqYE3undexrBV/NMUbrKMlzASCJ2AMNiTFK/b6eYqABIMdij20HblDccZgwcONikwxsJR5uZWXFTDNwDCEdNy77cm8lxgePN9IU3Q5YOo7Wo25j+exMz7tj1sCw48yDo2E4tNvt27dvy84M3iB2Pzok6G0OlkJe6dBH2d3Y6ngS4AyAFDk6GB1j2xyiQguGp5WmHrPaaDQcsaNLS0vuHRsvZrVjwKpyRonEi1kdnkYiinqHuo+G4eb4gFpdXV1aWrIO5NBfOuQkLtc9xHYHFcS455vdBEsPTkEdI+1V9B5zzHUEI6JXV1dlTY07d+50jJd2TOx0nGDpcYRGxy8ilSNL63aKLN50nKOH4N+eHYHrSWI2bt261Wg05OO3Wi1J65XndpwPdGdDdDz2Q3d+7ElI98u6jyBJaTZ3eLPZ9GwSHecSK5VKnPzkrLXbbQkwjTps5GsgOhmDhYYNZCTJsdNsNmWWzZyCKSTOMLFJI1lcXPS/z+1JlhsMvrK+XkS9abPZlC679Xt5YsLDIepNo7a2o44fp4/a7fbq6qos8lStVq2Oe8FEfb8Jm41K0DaiWnLHl+3Yp0LB0IsG0BEnCnS0tra2trb21VdfxejvJXlubxR7YBvMT9a/V7G6i+5H3Z1bdw+24wcJvnLH3risHzxYX+6gj7PcX0rCAZRjgJyHYU6SFp7kuQCQWww0ABRJ7LEtg+I8u337thkJN4hDSE8JR5rdDlh8hn5Z3B1La2BoNQw3aTZRH8T9KBKit5muAl/pUFQdZ6o5AyAVeZh5LipiVn0M+dms2Heo+2h4jqABIklrknCora2tVavVbgsI503oEHsgQlt7fArKKP48niT39HM1vRZ6ZJlpw93qaoost4EfyYPe472sOxui47EfuvOTT0L2Pk7DPVuYx/xkAAAAAAAAAEjFrVu3Ypd5SfJcJJfk5goAAAAAQMQe2zIozq2o9bww5GgYGFpc6QAAQN5whxpDxSpSrU5SK5eXlwc3RXmgh9icgorBOrJWV1eVUgPaJjEMyE8GAAAAAAAAUFjBm2G9eS7iWV9fr9fr8vPi4iI3VwAAAAAgodhjWwbFudJut2/duiU/M16GRsMAFFc6AACQP9yhBgZRYYbYnIIA9B75yQAAAAAAAAAAAAAAAAAAAAAAAAAAAAB8jfR7AwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMDPKTAQAAAAAAAAAAAAAAAAAAAAAAAAAAAPga7fcGvNXe3m4+frx09Wq/NwSIr/XsWevZs+bjx+3t7b/9+uv/9r/+1/PXrw8OD6+8++6/+fVfnxgbW7p6tTIzs3jlSr+3FEDmGhsb+pyw+YtflJT6zV/+5erc3NLVq9WLF6sXL/Z7AwEAyKn6w4eNL75ob28vLiwsX79O5xmAZvax//4Xvzg4PKzOzVUvXpSBdmVmhmklIKi5uVmZnmYQCgAAhllzc7O9tSU/t7e2/rLZlJ8ff/vts1evtvb2Xu3sHB0f7x8eHhweKqXKIyPjo6MjpdLZycnJsbH52dmFd9+Vp1x5911z3MFdPwDIOSKRAORE69mz9UeP1h89Ojw6+jf/8l/WPvqI+Tqg8MxQ0ubjxwdHR09fvhwfHX337NnFhYXK9PTiwgKDSgCpa29vrz961Pjii2evXl08e1YCb+h4YBi0nj2rP3z42d/8zfjo6PL167R8AAB6rHR8fNzvbVBKqcbGxs0/+ZPjP//zfm8I0JnMGbW3tiSgQeaSWk+f6j+YGBs7OjraPzxcePfdnb29J999Z71CZWZmcWGBKGqgMJqbm62nT83/y+8lX2LjH/9xfGzsn8/NNb74Qn4vJwE5DywuLDDXDABAc3Oz/uDB+qNH7a2txYWF+dnZ/+d//k/5efn69dqNG5Xp6X5vI4DekYF2Y2NDKdV8/FjG4PKQ9KVf7+7+t7//+//9X/2r9va27markx64DuxgbSDg5iefLC4s3Pnd3+33hgAAAKTAyjRubm7qh1pPn7a3t59vbSmlXu/u/vybb7p65YnR0cnx8aOjo92Dg+nx8e03b/YPD7vdvA/m589MTl6YmZF/Li4s6IdkhKL/yVAFAHqDSCQA/dXe3pabX83Hj5VSH//Gb8xOT/+f//W/KqXk/hdZE0AxyFhV39Vqb23JUS/k1tXE6OhP/+Zv/u1v//a3r19bsab63pZSilBSAPHIYiiNjQ25db64sHDlnXc2f/ELOR0tLiwsXbtGhQAUktXl/j/+9b9+ub392X//70opafbL168TcgYAQA+Qnwy4uCePlFJL164ppST0eevNm//7iy/+6quvKjMztRs39GqXsiTP+qNHradPz05NLV65svDuu1tv3lhR1BJjXZmeliknHVHd0w8MwIMsUtDY2JAVCoJZxxJppCeLVz/9tP7gwfM//VNlZDI3Hz82p5vfPnFmZunqVY59AMDwkHsk9YcPW0+fSi/avCMivWi51NZu3Fi6enX5+vW+bi+ATEjXWrrK1kj57eLxJ5nGuo9985NPlFL3/9N/kn9KF10vQm8N3t8+nbE2hhL5yQAAIJ9kTSL9T7kT9/ahp0/b29vyc/DGXND0+Pj23l7oQ++ePauU2js42N3f3zs4kF+enZx8f37+w5MJebNc1eqnnzYfP5aBhjXK+KtW69XOjvzZpXPnJsbG9g4Ozk5NTYyO/n//8A+h7/7OmTP7h4ffnTzLQQY+5j/1z1YmM8MZAOgKkUgA+kLXLVx/9EgF8iKsR0lUBgaLvqWllLJCv5RxV0spZY03pVvy+U9+on8jgalR97YIJQXgo7m5uf7okUSnK6WWrl2TuBrdr9AdDzl9VWZmlq9fX7p6denaNU4pGGhWp3r5+nXpdesut5m0LI/WPvqov9sMAECxkZ8MKHUSBqErIetJH/0HjmXqpI+79tlnradPq3NzKx9/HLXWjlkUrjo3V/voo+Xr1yszM2/nqiLeWsaB1bk5qj8B/dLY2JCD1CrdZiYVO47N4BSzpiOc9IvL73Wq8+KVK9W5ORauAwAUT/3hQ3OaWP4L/UtzuZ/q3Nzy9et6JSAAA8cK8bfiNpauXatevBhMEgh6b2Vl+fp1d8qlXnFM1hUKFmGW96LLjWIjPxkAAGTNkWksXfHvHzKWIgp1ZnJSMoqVUq92ds5OTu7u73/z8mXwL89PT3/4q78qP//6D37wzcuX37x8OT87+/MnT6ziydZyRe4iVGZ+clDU0qXqZCyzd3Bw9Zd+6f35+b/9+mtJsda51ta9P21+dnZyfFwpNX/unHzSc1NTo+WyZwloWUZZyM1E/U8SmwFAEYkEoOckQcgz8didxgygv76/jfXsWfA2kzpd1cYnpNOzW2K+b1QoaVfvC6CQpFSyxKJLyrF0PNy9iPVHjySfWW7Q62dxGsFgMdt/xy63VTZD8vOpjQEAQBbIT8Zw+X61uYhF7IIrzzkmcSRTov7gQXtra+natZWPP3aHNWhWMoa5Zo+mF9sLneHSi+3JTJM7bhtAV3SJY/1/+b1ep6DbBIb29vaF//Af7iwvr3z8sc+7m+nK+sCX8Ka3G0AgEQBgYJlL9sg0ce3GDc/rmswv6+dKsWWuiUCeWRnCZvi+7l3LqLbbLm7pRz/y7GBb9NpDwVrN1iYR0oFiID8ZAAD4SzHTWBeMOjg6+m5n54NLl3Sm8eTY2He7u0qpqBRc/VydcCtddHmovbVl3j5Lt0vvzk8Okj3W2NhoPX0qs/rmRwgd78iWK8lY9sthXlxYGC2X9w8PP7h0SX6zu78/OTamlJqfnZ0YGzNLbFn3PUPpPSxk5abv3+7KFfOfnrc+ASCfiEQC0BtmjkSMlXZDy7txCwzoGV2yor29Hbx5pIzqMknqGK9++unaT38au1tihZJaQz+z9I4M4hjKAcVjrWwiXY7FK1diZFo2NzfldaTvsbiwIH0PotCRZ5JdLykbMbrcZrHxysyMhJzR5gEASBH5ySgsmY7RRZlUIFpCp/gqpTqWZrI0NjZkalhW01n5+OMYUcvm/LLnqjw6tluFJVdbM00kLQM+oioeWPFDCedtP/yjP1pcWLj7e78Xe/Os8CZJkJb/S6BVks0DACBr1oKUSeZ55aZL/cED3YuWjnTq2wygWzr19+26YEaIvA7dkEj3hMesTCLd//GPUzn2zbiT0JLOZtAJZxsMHPKTAQAYTvrWmNCpsPqfpx4Ky4k1mUV6zVzWybGxmfFxpdSr3d0vnzwxc2WtEYHmzj22Jgo69tVlY1IZZYhu85ODOq5/6jOyiJfDLN+LTjyW3fLlkyeXz58/MzEhv3TknPu0BHdis/mhuEcJICeIRAKQKXNNXsmRSJjkIHfTrETl2kcfpbbFwNCzYi+toasMeVIfaYqE+cmhuv041MMABlGmucQ651miZ3Ucu9wiT/76QHJSSU7nFUsZjCTt36yNESPPGQAARCE/GQPv7YJwz561nj0LLTWsw4hTmWqRgsnNx4+rc3O1jz7yr/bm/gi69xxjwtrKxO7lxBkwiMysCfN08TYbeWZm6erV1EulrX766fqjR1+trSV/qajtX7p2La1sagAAUlR/+FAv4Cod3Rirt4YK9qKZMgZ6RlcJU0pZ/VK90I9SKouutVKq/vDh7b/4i+d/9mfZ3RbV6QTBeQbrAxJ2j5wjPxkAgEHXm0xjdTq5VPrwkrwqBZrMt0sl9zhIT31bi3UqY8XhYDnidCXPTw4yp/TNFGtzEVL5f1cvm2IO89uHTu9SK5NZtwEVK7FZ7tWaW2I+SmIzgOwQiQQgC1btteQ5EkHWsr8+FS8AWGRQk58yMClGjrmZwbTuctAyxM7iRh6A5BobG5JFKeeu5evXFxcWlq9fz+6AXX/0SDo5PXtHwMGsAKeUqt24kXp/eP3RIylWp5SS1k6DBwAgCfKTMUisaaPQRNyMZk8k+aH+4EF7a0tWn8pifUpzVR7p7MbOfzYXlQ/ONJn7SvYSy+OhqDoWK4gX+tMtyaD46o//OPXh69tE5cAHfHsOnJvLKCcEAAA3c834hD3bjswpY9aSB7Ig6yVLb9MaXeo8gV6WF1799NP6gwfP//RPe/Be2vcV2/qaLwF0i/xkAAByxcz5lL6l/md2mcbByWH91voHnXFqRWx//zon+aX6vbrKPbboEk9R6wHJu/R+PaAs8pMtMrLQiw5bi6imO6ufdQ5z1KfT/7QauX53YYXIh9Lbo/+pf9YtUHAfBEAoIpEApKgvOcPBXGgSlQHL9wVdwtacVYE7OP0aO/RgvOngv5cUi/MC/SM34iWMvI/VjDOt2Ay46ZreugyGNL/sDgHrHeXtMn1HAACKivxk5JFZEDh0FTdrQkSdDrZIfWPqDx5ItkPtxo3U17wMCu1ep5JiYYVT64kn/Qcsj4dBJ61aRzXpU4cucdav8sKtZ8/e+4M/uPvv/l0P0qUaGxs6tim4B3qZNwIAGEJWcEbtxo2e3aUw187MaLl6YBhYsfJWcsLStWv9yhMw3fzkE6VUv2I4TObSYKG7S4bYEtBPJxx9QX4yAAAZ8cw0jkr3NZkZmLry8NuHTlJDlXcacCq5x/r2UPL7RNYQw1p6WGfk5mTiui/x4lH3NdTpIVhGqyD1Poc5lDux2Xwoqnx31Ebqf+qfrVbN8lJAsRGJBCA5ufOlU3T6tU6ulajcyxtwQH74VwaWbn+uQh/zc2/LpJcPU2HlgvSelBkJbnUBGWk9e9bY2NAR49W5ubdpyf0+4nQou0xb9StfGkNCSlOYZTB6XM3YqthMeQwAALpFfjL6yUyXlZvuVmyEOcfR+zK/9YcPZXAlE7srH3/c4zGVOcctQzsZ3aX+RroWls8igiyPh1xpbGzolACrzoA01/xUD35vZWX5+vXeB4XrAstWvoS5i4i/AQAkV3/40FxhR/7ry5ZIiEb9wYP21lZ1bq720UfZlW4GBp1VtcwM45DxeD4LAvera+3JGmKH7lWlVH6GKig28pMBAOgot5nGQXnLPQ7y6QzneYXc/taz0uT7bWxstJ4+lRl++b21EmvPhmk5yWEOFTxmzRLNMRKbzcrk1lFMYjMwiIhEAhCbJORI2JjqSek2T5K2IZkbkr9EojIKyVof1urPy+DIzJvNf/88n/nJoaydr5QaoDxwYIBIZEvjiy90mWLpb+Tzsr7+6JFssMxALl+/LhvM4Y+ErBCv5evXax991N92ZVXmkMSNfoXAAQAwQMhPRo9IeEfUWmsqULm3j0mw7e3ttc8+k3HU4sJC7caNvq9/Y66C2bP+t7U8XmjquA6qJmkZvdHc3Gw9fWr+X36vG+TilStSnay/2xnq9n/5L83Hjz//wz/s72boahVvI5zCCizLnuzvdgIABkVzc1PWj9QLWOYnGTg/KdNATpiL+1ij8sGq9Fv60Y/uLC+vfPxxvzfEl7k6W2jJOB1J0+N12TAMyE8GAAwVnUWpJBdxc1M/pNMplV+aok7rFWbx1VQyjYOCKaB5yz22WPHK1kbqwr8DMcTQcpKfHNTx5kjfC1DHaMA6h7kvDdg8XajT6xSo7tcmkDGd/qf+RMI8aSilBuVwAIqBSCQA3dJ1AuXuUt7ufJnMEnM5yeUA4ukqRlENbI960Ofqg4WIKIEDxBNM9F26dk0Wtu73pnlpbm5KT0mnVcsaLhzy6Err2TOpIadzgGs3buStFZm5G1LojqYOAIAD+clImRmOINEeUTMR6uR2bH7mjFrPnklmcntrS/qR+dk2IZPL9QcPlFKSO93jtTllQtB/bcK87UAMFmlmwWJuVomAQWlma599trq+/vzP/ixvN650aWWrBrUEkL1NVyZHAgBwmrVaZJ4nYQdoU4EU6XJbSimrm6e702owS/jKDNL9H/94UAYCUayAG2vyxEznyO0aTBgIgx7zBAAYWr3JNLY6w9n1MNMtP9uXPrxe7ciq6KsCIcgDPZmc2/zkIHP9KTN8X4YP5v/7u52m/BcA9+FIbNYf5+1fRhzdJndis3lSIrgfiIdIJAD+zHRfSUselJKAVizZAG05hpDEgEmnetgSXN9bWVm+fr14c/VW1SJHejnRpBhmsgBK8/Fj6WkUoyKrXtVFzu36Q8nC6P3eOuRUe3tbamDI9HLtxo2BOBBkmMDCQAAAuJGfjJi+T089mTCyJhfMVFW5Q5znoGfJWGh88YVkLOS84yjjOhnaqRzUggsmpes8UnXSEqQSF8Wg4GbG05hz0G9DmmZmBjF9Qmtubn74k5/kP4/CTAuXL0J+bxapltN7XzcTANA3g1uU2Cr13Pu1foDs6HiO4IjMqs2b876oj/rDh7f/4i9yuO5PKhxfpe6QS1zO4I6M0GPkJwMA+k4nIgozl28QM42D0s09zsMNFL2STjBe3Lz3t3T1asGCxdVA5SdbZGJfry9s3WGpXrxYnZsbiDssxchhDmVlMpvLLsRIbHacDxWJzYCBSCQAHQWrEA/oKrehlZ9JVEa/mLV2g/c7lFKSvVadmxueWx6lH/1o5Xd+Z0jm6n1K4BBNimEgi+lLWrJSaqB7Gm7BotDSFSn8uR2erJ6qlA0fxJAtFgYCAMCB/GR0ZpX0UUoFJ4zUyY3PwQpHkC7v2meftZ4+rc7NrXz88WD1d61acMvXr9du3MjJzg/OMwaLQQ3bPCMsEnNv/l9+b+bB5m11/4Qu/Mf/WLtxY+DmmqPyxpeuXRu4KtYAgNis5F7peQ5Qz1mz1voZlMU4Ac0KOrfis3XR3cEam3dl9dNP6w8ePP/TP+33hvSI+xvXmQaFyT9H6shPBgCkyJFpbCXXWXeRgqySoebPMt9oPtTHsWfxco8tVm/Tihgewt7m4OYnB5lLkbaePTOPSnPkmMNm2VGBc5iD5HvU/7TOw+YqD8rj3KuMc5T+p/7ZOv3mfM8AnohEAhBFUmgki6ZgyUJW+ofkfgxWOBwGi1nXJCoT1axwM4hjkFQMVX5yKJ9oUnUyeUI0KQaadDMaX3wh58OhSmJsbm5KJ0R/dumKFKOXhRjMxYAKcyzQ3wYAIBT5yfje28F/9BSAThpUJ+EUgzth1Hr2rP7wYf3Bg/bW1tK1aysffzzQcRUyoJWPI/PmuS0BrYtBBdfdV0ZpL5lmKmo8/XCKCoWRb3xI0lxvfvKJUmrQY5vkMtHY2AgmlktK+UAUYQAAeLIWxJGaw8XoocmIwAw9yW0XGsPMKlzmqKY7uMPzbhWjU53QMFe0Q7fITwYAhBrCTOMg/an1DzqEuhi5x0HWDRrH+GJoJ3iLlJ8cZM7tyzhCfm/dphmIxtzRUOUwh3InNpsP+ZSvV87EZmv/FKMJoTCIRAJgMe8NSR2IAi9i297elqWH5Vo/uHXqkB9WkRurJxmMLC12DFi3Sj/60f0f/5h9EmRNVlhDNrNdyd5jHyK3JA9TJl7kHDjMV16dwCnHuO53SV2rfm8dMjdASQ1JhPa3ax991O/tAgCgP8hPHlJ6VK/CZot0gqheE30Qb7tGaWxsSHdQBjwrH39cmI+mlJLVPQduSR5r+tI9zUR09aCIKrr7NrplZmYIs1hXP/107ac/Ld7FrrGxoVdCDWaeD09tDQAomPrDh3qtR+lVFjU+Q5bqrD94oAaqC41CMrvQ1jhdbtTJijBDHtLx3srK8vXrJFsG6fYjS86RbQJBfjIAFJ6VgabL/Op/nnooLOfWJJVqhM7QU7nPNA5y5B5HZVzrz64/qe51D2L32ypgZd120eVzGV9Yip2fHCQrkJr/l9/rEUSxp/fJYQ4VzGSOuqx4JjabVxaZ2dD/JLEZPUAkEgAhq/HqzIHajRsFTksOsj4+iRPw4U4Z1QVIFLF8fpqbmx/+5CfkJ/tzJ8Oba/UOepklDDorC1cquwxVN8PH+qNHkq0ql5Ll69eljm4xJlJgCi4GVLtxYxg6CVbxj2KvggQAQBTykwtOBuo6/kAFAi+s2SI1mGEWnqRgcvPx4+rcXO2jj2o3bhR1VkIGvfJh1cBOrFutt+M0U4Gb7kDoGMUilXWHYajpIBe7wk83v01KDzSGt8FMc3NLV68yLwwAudXc3JTVfNpbW3JLoMDdZpPZhZbJYpkv7vd2obB03SqllLWgj17nRSk1hGv6dFT60Y/uLC+vfPxxvzdkAHRMSiHpfRiQnwwAA6Q3mcbq9G2gQextknscZC5VY9bFVcZ9wCKVxs3OsOUnB5nLZpkjCBk4mP/v73b2DDnM/uTGrv6nPkW/fdQq5hy260w6gEFYFzJdu14U40yOjBCJBAw5CghbSJxA0Pe3D04WP7XmHGRAzfqnCQ1JwFjW3jbUiLV6lXHni+aKrMkltbGxIY1wcWFB+hjDM2EST3NzU8okSN+M/VYYVq97QHMWUiGp+DpDu3bjBi0cADA8yE8uCHOqSG6LWlNFuhLyEK4ZJuvx1B88aG9tyWBmeNaAtNYiKkBP14yuDk4zBUt/D08777G3lXI3NuSEEyyZK9N8TKoGDWE2hbQWfZEKLbAsGez93U4AGHJWREIB+o2xmcMHWdiIdVuRnF5mPjiK0dkCxS5LlRYCOJLTCwkFp4+s3HgqHhQD+ckA0C9mXlawFqX58zBnGgeRe9yRriAU1Z2TRkJ3Lh7yky16ev/7H07am7kgaTHOP7Glm8M8hEeuI7FZ78m3f+lx0XQnNpvXhSHc1cOJSCRgOOlKhuuPHimlJFRsmNOSg6zECRKVhwRBd30kfZLPf/ITuqCp+77yTdidL0W5b6TKvIAqpZauXZML6DDPisRj1Z3WvRFZZaDfWwdfVq+bxYBMjY0NOV1I7JmkrnCuAAAUG/nJg8cqsmQVlVUsA2aQ4m/1Bw+UUrUbN2o3bgzt5IJZB6945aN9lnI0D4pCxiRlrbm5KTs5GIAis3gEoHi6+cknlenpe//+3/d7Q/pJZ0SENqfqxYtL164N7ekaAHqv/vChOVks//V7o3JBZorNafThWecICcm6v1EVa8kWSKL+8OHtv/iL53/2Z4UZz+aBOaYOTjSZBffoqA8i8pMBIBU6dcqRaexTDVIurPKzTFl//5BRCrKoHUUzYFR+IzsweJ9LmDlmQ5J7HGQOLoL9NMkOZamjFJGf3FHU8rXq9ICXBmmR/abkjNflOVBfL+QuZ1GvETFYmcx6x6pYic06aVyYSc7KuOiQpTNwiEQCho15Z2dxYUHueRHH4kCFt6LS/XYVFl8arHNDBz5r9El6T6/vpjyOAplj6du2IvekVLJEX0smrXQzGB6mYv3RI+mQyOy67N4ixbcXkpl8S6/bTU4gkski+4rmDQAoqrzkJ0uJKkLlfKx99tnq+roKrOylhiYaw1/94cPV9fXajRsrH39MZ07o/JOv/viPCz8Y0DXKzLXxqnNzX62t9XvTBs/qp5+u/fSnMjcnpW6rc3Pck4hh7bPPKjMzZDeZzHgmyVheunaNCDAA6JkP/+iPlFJMgEZpb2/LQj9Kqc//8A/7vTkYDDc/+aTxxRe68ywBxASwpkJudN39vd/r94YUn7U6niRc0VEfRPWHD0lYAoDkpINn/mbIM43jkWBc+Tkq706x004LHVywVGh2GhsbrWfPmMDvih47tJ4+lZtx3ImLxzOHmXFZQno/C2vlEVkIW//Tuvorpe7/+McMrwYLkUjAsPnwj/6ovb1NdbIYdJJJ7cYNTpsF0Nzc/PAnP1EnSZhUju27xsZGY2ODg6vvzCriMi6QPv/K7/wO3w4cdAdj8coVlvvPjizUuP7oUfPx42GIbx9ot/7zf25ubtLr9mfWmqZ5AwCKKi/5yfAnt8QIa/bR3t5mR4Ua5j3TevaMnn0M7Df0Eu0NAHppmHuGXWFHwV9zc5PwDhQSbRsAMLRaz561t7e5Durb7/EAABuxSURBVCbU3t5uPXvGbuwKHTAMImb4s8OJtI8kgYHl5wAg57iVkxz7sDDolgOe2tvb7a0tjhc4cHHsMXZ4/vEdxcauAwAUGPnJAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHyN9HsDCqvZbLbb7X5vBQAAAAAAQFI5nOXI4SYNnIz2IV9NKHYLAHjihImhkl2D51ACUpfDwyqHmzRwGBf3ErsFAAAUDN2b5HK4D3O4SfDEd9df7H8AAIAhV7p//778tLi4WKlUzMfq9Xqr1Wq327VabXFxUf++0Wg0Go3l5WXzl2lpt9vWZvhotVqtVqtarVarVflNo9FQSlUqlcXFRfej8rMI7oQg8+/lFUL/7ObNmysrK0tLS1EvUq/Xq9Vqs9lcWlpaWVnp+BlT3zOVSsWxW9TpT+qzZ/zfOknLabVa9XpdKXXnzp3YLxL1yv3aV0HtdrvZbMZ4wdXV1Varde/evW7fsZcHkZs5TDXf0S3JeSlXX31ww6z30u8SuiXyT0f7kdc0f693uPzG/ESaeSqz/sDniE7SulTGO1l12s89ls99pV9WWoK0Gf/DM3X5OV8BQOqs62wOz1T5uVSZL5XpValerzebTWtQHJSfPQOVYDwloiZD/v/2zu7KUV2Jwpq7JgFOCEwInBDoEOwQ7BBwCHYIJoQmBBNCK4QmBCsE34dao6XDT0lICIR7fw+zpo0RUEil2oVcCF9hzrOOHmHkg+N58lmOTZg6pcVvU9QBHqhHmO7qgsdtdUk7zG32DSL8USndm578BlHgLXY8hMtMJxLOnwAA9oUO1chpDCfuBKOO1UjK0+oGA5/p9NjqGl0m602I1+FntbympB22pj+MHSSsEFmZbJsoCNHFvKH2JbhMoItDiKraQnRx+Liee1sdn8UvqIt3obYc51mPQbSO60YGGIDFseo+b/jldnMX4yXifredChfkDdK8VhxXjS5IF22dZI+Us8SOe83yAEsZNkGN0CN2AAOdFcJPcJuO0MWK6RWtju0M7533amoiqZsugsOPkJDDhamxs3KiiSeR8C8e1l60/kG3EsseC91dQJoCAAAAYPhNs4uUMs/z+/1ubjudTkKIy+XSK2lD4WOkOjfn89lDDEgp27aVUj4eD4oR6U+6KGZrVVVt2zZNczgchBBt23ZdV1XV1IxO++rvCyEul8toSH04HHqPW8xG6rqee5mLW6YsS8ZovSu1WmbWoXs9bRZ5nl+v14+PD+8WptjQVkOoTTExNhm8jbPaILLSNA39S4OIHJGVEL+U1K03adv2drvRj671se73e1mWXdeRobSQoBMrikL/Kcb6j5TycrkcDgellD5tpVTTNJ+fn1mW9Vwc7aJdnFLKbJlkufV6vXvXCkbm7bzUIdxJ0FZmsyRWm6ap6/p6vToOz8VJx18BAMCy6BlcKdV1HXmnpB7FiWSmqqEuk1Jer9cYLv10Og1F8ZBELAMIbz1FTCVDhK8w51lBj/DywfE8mSzHVkyd0uK3KeoAD9QjTHd1weO2uqQd5ja79wh/OCuJv0/TzbVNfoMo8BY7HsKx/WTzJwCAHVHXddu2ZVlmWUYLLIqi6K0ETTDqWI10PK0ZQAoh9Jrd8BUqm1yj42S9CfE6/KyW15S0UkpaMm4qtfP53HVd7LT8CpGVybaJghBdzBtqX4JLA10cSFTVFqKLw8f13Nvq+Cx+QV2cvtpyn2c9BtE6rhsZYACWxUX3+cEvt/NYjJeI+912KlyQvad5rbivGl2QeOskeySbJXbca64HWMqwCWqEHlEDGOisQN7ebboj2RWtId0pcKSnc9MXCT8Cn0pbmRo7KyeaeBIJ/+LB96JNDrqVWD6fz2aaogsoVWCCNAUAAADA8Xq97vf75+fn4XB4jVFV1ePx6H34eDyGHy5CWZZ+Oz4ej6qqqqrSn5hnzm81D/p8Pq3n0PvClOn4U521y/Cgcw83eu28WV7zLeN+6EC8rcGzoa1G4cfmFLsYRFY8WgjxS6nd+tHGe38Or7fnWKb6z+l0Gh7I/LB30FF/NXcsh/SuV2Qjv1g7r0+attLtUJtfX1+LNOtNUv4KAAAWx08vrEY6U9VqLt0x8knHMoDw01Oa0fu+XylqlQ/vRIzbFHWAh+uRpZItjqRm4UT8Z++4y87msW+xe/vJ5k8AALvg8Xj0MpOfn59vHJP4kY6n7QWQX19fo4llv5Y3ucaok/UbsKakrarqdDp9f3/Tn5+fn7QUcpELsbJm8Lx5oiBEF08ZKjU58IIuHiO122S9R4G6+A1E8SulGMCPXYti90Ns7tgBSJ+ouo/3LX6eJxH3u6+pkOEN0rxWAleNLnLQSKScJbbu5ecBku1myxI1gIHOCuQnuE1HrCtavVlwgl6EbTXFhqtk10w08SQS/sXDehXrH3QTw5qNnE6nZRc8I00BAAAAjPJbCNF13fV6VUrVdT3rXYiXy0VKKYTIsqz6b82MpmmapqGqqFSxSVdV77rufD4LIR6PB31NCFGWZVmW5/NZSqnrFWVZNqtaSVmWTdN0XTdag4ffqnF5F+hwF/NPbZbh+7uUUlQCXClF3zGLRE4ZjSwWyTKOZhFelrG2T1XSu66jt7D2qu9fLheyFRmkV02TKm4qpWiTuSPV06JzpuO6V+Lc0FZDpsbm1CDqjd/j8UjWc+8tWw0id/heIVi/xJPUrV+Eqf6jiyodj0eyoZRy9MUXVNFwqQJpi/QusbqRGTdFBqT3CYu/xTVNS9Z1retEVlVFF+gyHpO1FVmDXrU9/NzDSt4mEnvwVwAAsCCMvOJDX34r0yxPglPVsCn+6vio0tzXLKhpJUHL/GSYXIdVVoy2ZhXmvMLl2VaP8DHbVJajaRp6k57ObJAIFULc73c6W4/sEN0s3n1NnRJ/m5RSx+NRCHE6nWhoUzuOr+/YaoB7+2o/GwoHpWN+s5d2YJq18jYRPp0kldmmTxax9ihT3szarPdMJ7b2VwCAXdM0zfAdembukZ9HPJweTYXi7+tDi6Kg75jtM5EhH650XXe73bquo4OS59fN7jcynKIoiizLKHaiT7yjFLH1NfYma+sDF6aTWOdcpp/wHZ6P5fju5x2SrRnxVlVV1zVdFL2qhWxIMCOIv18eWk/Dd2nvJ4/bJgqmdLGfoaLq4m0NZR3LMXSx1fksrosDRbHYTrUlq4tHn8VH0sU7UltDUSyi6eKQORoZYAAiYdV91qBrNJbgl9vxW62k7349QiwXOez98JHnbdK8jvTuhV/s5zIbMuskpyZEa8C50yxxby+rB/BbgOqSK/ALb/iFUt6P1Xg2CWCgsxLXWalhXdHKj2UXITal4BgX+pY5EIZRazjm2D2EsNXIIQt3edIP/wLhr2LKhWr3q5cH0zu3heF+vQ+6vmF1I3VdU9c1t/KqxDvJjDQFAACAn87397cujDFabWi0Asfj8SjLUn9ONTPMQtdmU19fX8NacWVZVlV1vV51g/pzv19aUy2u5/Opj9UrAcJsnVv/Q3/h+Xxer9fRol9M5ZLRgm1Wo8WwDG+WV3BlFL79r6+vsiyfz+fon3RE/f/r9Xq/3/WfWZbpP4dl+4ui6DUbfsKxbTXEOjb5QUSnOqvkz5qDyMpUC0yv4P0ST1K33oSpWMYXIGT6D13I8/msqooafDwepiX1UZhrmVv/KaR3veJXaZqys9VNMb6oVwa4qirHkn5p2qosy6+vL9O7aryt5G2iV2L+CgAAFqenF3ilwIe+zFYX1TZ1eolMVb3QyDx/69UxUWVv3/v9XhSFS+STjmXAy6anmA6gGY14mftiDYoYVtAjvHx42VT28LjE9/f3qNwgQrJDLrreo8ry6Am73KaoA5z509FXj5oixIZ8f7CmHTwKBr9BhG+V0n7W5vf1S515z3SvhPMnAIBd4Djwl3V6lNR6Gamn5/NpfsEaGY6GK+TH9L7k/fRpJx4ZOjIMIB+Ph7aDt6J8bXeN/GQ9FZe+bJ2E6X58Pxm9QA0Ty7k0y7Q8xZqSlsTI6XR6Pp9fX1/0p3ta/jV9v7y1nrVL+z153DZRwOhib0O94ujidQzF62LvsDxQFzPOJ4Yu9hbFr8iqLVAXe/hS6758dPGyPYtfVhfvQm2FPF/2y0q9AuZoZIABiAffsXmvbo0lHnHen5yC+2WmQpcQa+pxBiOHQx4+MkQNGBKBWTUaEvvxsyG/lZ8Qpw66ryyxdS/GA/gllPRxp24ZMTe84RdKhTxWY4gawEBnTZ1tCjprX1hXtAY+359ScFYXOnXCiedApuAfUk9Zw5pjHz1Vx61TlxCycJcnkfAvHvxV8C50aMbPz8/R4TbroBsaduiiX2ErygikKQAAAIBRfjdNY5bZcKmQQZgv1aQp83a73e93IUTTNGYNG/pm70BCiDzPdWGqcqH3c1L1juGx+K1d15k1fqyVTszvu1uMx9Fo3jCWYTbNtcysQ/dewlkUxeFwaJpG94osy6iyHZWuadtW71sUhf5aURRUJF6T53nbtnS4oiioW4afML9pEVuZuIzNqUFEld6G7zh1YZ1B5A3TKwTrlxwbT+HWTzU+C6b/5HnedV3btlTrqOu6Xu/yPqgVv94l4newqUu2uinGF9V1/Xg89J9VVVG5REdSs1XXdU3TlGV5Pp/v97vpW7ytFGgikby/AgCApeCVAh/6MlsDBUgKU5UupNp13eFwMC/HenVMVNnb93Q6NcZLnKykYBkgbHqKlxV+WIMiK9vqEV5lT5HnuVKKargKIbTKIEKyQ4G6njlhYfSHtm3zPHcXzpEGOCPBQnx1iA2t/SEk7cCw6wjfW0r7jT7CL3UWONOJrf0VAODH4uf0iqLQ8Qm5pizLzC+4RIbDcKWu68ooqE9vvDHfhLPryJBBv8kk/JHW+tdonaynHrhYn0owKWKmn/AwsVxIs1bWlLSHw+F2uymlqqoyP3ccQaP3y1vrWbt0SHS9VaKA0cUxRLEI9n7bZlS8w/JwXTzlfGLo4kBRLKKptt3p4kiiWCQcA1gJeb7sPQC952hkgAHYCt6rhyspbzZ3v4wX9TYLL4dDHj5a2XWa1wqzajQk9uNnQ36rNbwfPei+ssQh3cN7ASrht8LZb6FU1EXXmwQw0FmOvLfbdMS6ojUklcEoOO9md5oD4YXblDWsOfYYhCzcdWHz8C82U1fhEgSWZXk8HouiqKpKSrnIcw1+azzDns/n3pvPRdiKMh6kKQAAAPxwftd1rec/pVTTNL3HwFOYkk/8lQf0/7ZtaZm4yXBWi5RAJN0+pb1Ht2ZZRp9kWeYyueZ5bn6truvL5RI4KzsaLQTGMlOb5lpm1qGzLOvpPVqLQP9XSp3PZ/0dKWWvyzHc73e6KV3XZVnm0dM2tJXGZWxOXVpd10VReD8QXWEQzYWGmLVXMH7JkRRuvUnP2wy9xBR8/+m6TkpJKba2bbuuM02nDxrjV8oevUvE72BTdubd1CyyLJtbzCIpW+nWKGFn5meXspKHiUSS/goAADw4Ho/DfKiGVwp86MtsDRcgm09VRVHQE9ymaaSU5ib+6vioUi+4Nw8068Q2twwQbDwcIjYZFgmKUtMjLpxOp9vtRodumsY8h5DsULiun6KqKl3Hqq7ruSsPYgxwRveF+Op4NhTBaQeG/Ub4UaX0KN7eLHymE/v0VwCApCBvqZTqus5clzlFpBDOsdnhNCql7KXrzR3fODLU6btFHmmtfI3WyXo0Xgrpe3w/4WFiuZBmXVhN0tKqL2H0K92Uywga3q+Qm2Xt0oHR9SaJgildHMmjiiW8304zKoG6eKo7RdJ0gaJYxFFtu9PF8USxSDUGsLIjUSyQAQZgLYa6j/fqCy7P8GBb98tMhZHMEvLw0YX9pnmtMKtGQ2I/b1wmxCm12/sk5Syxd/cIlz9RSyT0FkrFXnS9rwAGOsu6dS9u0x1mRWvgWJ5ScCHN7jQHwoQc8fJFfqwQGe5UfbszehW8Cy3LUhdZoFVYc9/hl9Rcc7lcdGVP80JCVpQxIE0BAAAA/D6dTuZj7I+PD8ffJ0spTVGnq1UJIcqyZJbXrwCpU/eten71Ppz7jwanWMdojGVGNwVahm9/GE5JKXUvOp/PVVXpAKttW8cKNNSsufT84+Pj6+sr/IT5TQvaSghBNYf8xqYQ4n6/09vkvMs2rzyIrJDUsfYKxi+5s+2tn0Xv19d6TPH9pyxLvePhcDgej1mWjYoZnUBv23ZB7TG3d4ntjMy7KZ7e16iq39wTSMdW+nJ0kUIt172ttIiJRHr+CgAAPBj6UhNGKfChL791EQGSyFRFEaBZNIq/Oj6qHH0uNfeUErHMj4WPh73FJk9I6GgST49MyYdAyrKks6IH+eYle/uZpXT9KLqKuVJqbv1yYs0BnqYNxRJpB4a9R/irPbrz9maLzHRiV/kTAEAimP7HTDy67BsphPNulipjTq3LST8y9MMs+rPUI61NrnHWZB3S9/h+wsDHct7NurNaxDv65mfvERRys/guvUh0vXKigNHFkTyqWMj7RTUUdLFYQhSLdVVbgjYUkUWxSC8GmEX6olggAwxATHjd5xJ0mfgpKW/SdL+RzOL98NGdvad5HTFXjW6yYvaHZIm9u0c8+eMHv1BqhS4UI4CBzhI71FkJwq9oDRzLUwoupNn0cyBzSc1hrhMZphn+LcjwKngXWhQFfb8sSykleeDwg1q3xjAsdWDdbF3Xi6woY0CaAgAAAPhfrwQU1T5x2bNtW3Pyu1wuuqlhlRr3Hx3leW4266dXy7JUSk3ty2/1oG3b8EJBVqPFtsziZrG2X5alWT1XKXW73cy6mKZVqYa6C1LKuq71n96CZENbCSHquvYem0RRFNfr9Xg87mIQOWLtFYxfcmfbW+9OURRmlzBPzNp/qMaVuW/kk/0PafauUXg3xXM6nc7nM12IUupyuXjMFGnaioo+mqfhZ6VFTCRStRIAAMxCF54k2rY1HSmjFPjQl98aoto06Tjhw+Fgnj9/dXxUmee5aTcppbsY0aRjmZ8JHw97i03BCvOQ0LF3qjH0CCMfwjkcDnVd3263ntm9/UygrrfmTyigNX9gM4s1B/hWNnQhMO3AABfqiLc3W2SmE/vJnwAA0oFyQX77hoRwMZo9nU69dwOak2/ikaEfdV1nxlt9FlGUIrFrHCWk7/H9hIGP5bybdWe1eGx0za73CAq5WXyXXiS6XjnKZXRxoEeNrYvjGQq6WBMoigV0sRAipigWe5gfUyAwxYcMMACR4HUf79WXUlLepOl+I5nF++GjOz/ET5qrRpdSyrNAlpgnUkLJG36h1ApdaPGBCZ2l2ZfOShNmRWv4WB5VcNZm95sD8WArhzll5HUiw8RnsXCGV2F1oVmW0aK1w+FwuVw8QsEUOrZSyvxBco+QFWUMSFMAAAAAv8qyPJ1O+n1T9Os+qldNU51ZgOp+v+d5rnVU0zS68hO1o9u93W5SStpKk9n1eqVGbrdb27ZSSj0NX69X/X8ppRbetOP9frdeRtd1x+NRCJHnORU1UUr9+fPn8/OT6ipNbc3z/Hw+65Mxz2TqQOb3iTzP9dU1TTNlN707TfD0Cckeq9FiWCbPc95osywz69BmQRqtKqWU5lGapmnbli5fSlmWZV3Xh8Ohqqrj8Uhlv8l0Hx8f9NZcMkjbtrRQhvYdds4EbdXjcrnQ4Bodm1TDZmoQHY/Htm2fzyddEdVoPBwO1kLFqw0iK5QF6I0yIcTj8ZjqFdfr1cUveVz7yrfeRClFXZ1qNelj6a4uhGjb9na70UGllFTgzdp/hBC/fv36/v4mQ1F3ejweYsLFKaXKsqQuRGclDBeX57nVF3n3rthGdrHzlJvSO2pfdLlcaMWPHm7kjiiHUlUVo3hTtpXZrOlqlFJ6dvO2koeJQqy0uL8CAIClUEqdz2eaW0djmCmlwIe+1sCYFyCjJDJVjU5PdPSqqigEYq6OiSqp/cvlopQyTdG2rW45ZcsA4aCn+A7Ai3pemDMKl2E1PTIqH4QtZuMNovn333+1ajDxyw7x7st6Si75E/K6jq/0iTfAXXQf782mTOFtQ2sMz6QdHHvLghZOJMLn73KItXmTuqfOhnLVY6YTqeZPAAD7omkanb8VQkgpq6qi5wUxnB5FhjRPUUxILuuff/65Xq/WyJB/mGXGfkM9lXhk6H4mdEWUB+7FTh6Kcqtr5PflbzTTSVxSxFP9hO/wVjnPdD+/kGxNSTuUbPoW0MAU7Ahi7leI1hNsl/Z78rhhooDXxZRQ8jbU4rp4TUON6uLAsFwzVxfzzie2Lp4likNuk1W1hejiEF/qrdT4Z/ExdHH6ast6Dt7W9osPHedoZIABiAej+4RNR0zFEvxyO34rQwru12UqnDIL4yetcpi5FzHW3e0izWvFumpUeMV+/LQ13NpbJ8kvpWMCTrGTLLF1L94DeC9AteYKvNP+/EIp70XXHvdrqQAGOkuTjs7aKVMrWkVAzseq4Ph1I7vOgfSwhhxT1qBNfI6dF27eIytk4a7HLUhffbvA9yL6Dh+QU3hAd+HPnz/3+720vV83QbHctu35fDbnlK7rvr+/9Z9+K8qQpgAAAAB4fr1er5D9pZRKqaIozBlRQ8WxprZOoZSSUnrs+B4wRntLy+iLGoawtCn7b0WZ8GbBrnHpFbxfej9I0kAbxGMpf3I+n13qSuyURaz03iYCAAArXdd1XcfEMFNKgXfCVhftp9r2Am80Joii25HnuXX5INgji4hNXrYnK0U3kQ+B2SEPY1rzJ5fLhdblz215K9a3IdgFId4MMx0AYEMofzvXBYU4vXjNujzQee+J+L0VJRHe9yLFcu9tfL8RFPVmvdOgDjQUdLHfQUVKunh3olhAF4MxAr0ZdDEAUeF13w8JuhYknln8Hj4CnpXFGrLEPJESSksxulBqj3ofOkvsU2ftiK2Sw3vPgcxiK4fJGPnNLJwUe5xrFsd7RdkUSFMAAAD44YT+PhkAAAAAVtq2bdvWvUTiDwQmAgAAAAAA69B1Xa8gPQAAAAAAAAAA8EOAKAYAAAAAACAFsFDqnYDOAgAAAAAAAPxwfm99AgAAAMB7opQ6Ho/0/6IokIIcAhMBAAAAAIA1OR6PSqmu67Isa5rmcDhsfUYAAAAAAAAAAMBKQBQDAAAAAACwLVgo9X5AZwEAAAAAAACAwPuTAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAO78b+sTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAOwG/D4ZAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA4Ap+nwwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABwBb9PBgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALiC3ycDAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAXPk/gK9If4EoR/YAAAAASUVORK5CYII=",
      "text/plain": [
       "Tree('S', [Tree('PERSON', [('Albert', 'NNP')]), Tree('PERSON', [('Bifet', 'NNP'), ('Noahs', 'NNP'), ('Ark', 'NNP'), ('Lab', 'NNP')]), Tree('ORGANIZATION', [('HUAWEI', 'NNP'), ('Hong', 'NNP'), ('Kong', 'NNP')]), ('bifet.albert', 'NNP'), ('@', 'NNP'), ('huawei.com', 'NNP'), Tree('PERSON', [('Jesse', 'NNP'), ('Read', 'NNP')]), ('HIIT', 'NNP'), Tree('PERSON', [('Aalto', 'NNP'), ('University', 'NNP'), ('Helsinki', 'NNP')]), (',', ','), Tree('GPE', [('Finland', 'NNP')]), ('jesse.read', 'NNP'), ('@', 'NNP'), ('aalto', 'NN'), ('.', '.'), Tree('PERSON', [('Gianmarco', 'NNP'), ('De', 'NNP'), ('Francisci', 'NNP'), ('Morales', 'NNP'), ('Aalto', 'NNP'), ('University', 'NNP'), ('Helsinki', 'NNP')]), (',', ','), Tree('GPE', [('Finland', 'NNP')]), ('gdfm', 'NN'), ('@', ':'), ('acm.org', 'JJ'), Tree('PERSON', [('Geoff', 'NNP'), ('Holmes', 'NNP')]), (',', ','), Tree('PERSON', [('Bernhard', 'NNP'), ('Pfahringer', 'NNP'), ('University', 'NNP')]), ('of', 'IN'), Tree('ORGANIZATION', [('Waikato', 'NNP'), ('Hamilton', 'NNP')]), (',', ','), Tree('GPE', [('New', 'NNP'), ('Zealand', 'NNP')]), ('{', 'NNP'), ('geo', 'NN'), (',', ','), ('bernhard', 'NN'), ('}', ':'), ('@', 'IN'), ('waikato.ac.nz', 'JJ')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['p59.pdf']['Entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing/building individual compents happens below; then I paste it above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Using TF-IDF to Determine Word Relevance in Document Queries \\n\\nJuan Ramos \\nDepartment of Computer Science, Rutgers University, 23515 BPO Way, Piscataway, NJ, 08855 \\n \\n \\n\\nJURAMOS@EDEN.RUTGERS.EDU \\n\\nAbstract \\n\\nIn this paper, we examine the results of applying \\nTerm  Frequency  Inverse  Document  Frequency \\n(TF-IDF) to determine what words in a corpus of \\ndocuments might be more favorable to use in a \\nquery.    As  the  term implies, TF-IDF  calculates \\nvalues for each word in a document through an \\ninverse proportion of the frequency of the word \\nin  a  particular  document  to  the  percentage  of \\ndocuments  the  word  appears  in.    Words  with \\nhigh  TF-IDF  numbers \\nstrong \\nrelationship  with  the  document  they  appear  in, \\nsuggesting that if that word were to appear in a \\nquery, the document could  be  of interest to the \\nuser.    We  provide  evidence  that  this  simple \\nalgorithm  efficiently  categorizes  relevant  words \\nthat can enhance query retrieval. \\n\\nimply \\n\\na \\n\\n1.  Introduction \\nBefore  proceeding  in  depth  into  our  experiments,  it  is \\nuseful  to  describe  the  nature  of  the  query  retrieval \\nproblem  for  a  corpus  of  documents  and  the  different \\napproaches used to solve it, including TF-IDF. \\n\\n1.1  Query Retrieval Problem \\nThe task of retrieving data from a user-defined query has \\nbecome so common and natural in recent years that some \\nmight  not  give  it  a  second  thought.    However,  this \\ngrowing  use  of  query  retrieval  warrants  continued \\nresearch and enhancements to generate better solutions to \\nthe problem. \\nInformally, query retrieval can be described as the task of \\nsearching  a  collection  of  data,  be  that  text  documents, \\ndatabases,  networks,  etc.,  for  specific  instances  of  that \\ndata.    First,  we  will  limit  ourselves  to  searching  a \\ncollection  of  English  documents.    The  refined  problem \\nthen  becomes  the  task  of  searching  this  corpus  for \\ndocuments  that  the  query  retrieval  system  considers \\nrelevant to what the user entered as the query. \\nLet us describe this problem more formally.  We have a \\nset of documents D, with the user entering a query q = w1, \\nw2, (cid:133), wn for a sequence of words wi.  Then we wish to \\n\\nreturn  a  subset  D*  of  D  such  that  for  each  d    D*,  we \\nmaximize the following probability: \\n \\n\\nP(d | q, D) (1) \\n\\n \\n\\nframework \\n\\n(Berger  &  Lafferty,  1999).    As  the  above  notation \\nsuggests,  numerous  approaches  to  this  proble'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert document from unicode to string \n",
    "\n",
    "import unicodedata\n",
    "document = unicodedata.normalize('NFKD', a).encode('ascii','ignore')\n",
    "document[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   In this paper, we examine the results of applying  Term  Frequency  Inverse  Document  Frequency  (TF-IDF) to determine what words in a corpus of  documents might be more favorable to use in a  query.    As  the  term implies, TF-IDF  calculates  values for each word in a document through an  inverse proportion of the frequency of the word  in  a  particular  document  to  the  percentage  of  documents  the  word  appears  in.    Words  with  high  TF-IDF  numbers  strong  relationship  with  the  document  they  appear  in,  suggesting that if that word were to appear in a  query, the document could  be  of interest to the  user.    We  provide  evidence  that  this  simple  algorithm  efficiently  categorizes  relevant  words  that can enhance query retrieval.   imply   a   1.  Introduction  Before  proceeding  in  depth  into  our  experiments,  it  is  useful  to  describe  the  nature  of  the  query  retrieval  problem  for  a  corpus  of  documents  and  the  different  approaches used to solve it, including TF-IDF. '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting title\n",
    "title = re.findall(\"^[^\\\\n\\\\n]+\",document)[0]\n",
    "title\n",
    "\n",
    "# Getting the abstract\n",
    "abstract = re.findall (r'\\n\\n(Abstract|ABSTRACT)([^]]*)\\n\\n',document[:2000])[0]\n",
    "\n",
    "if isinstance(abstract, tuple):\n",
    "    abstract = re.sub('[\\s]',\" \",abstract[1])\n",
    "else:\n",
    "    abstract = re.sub('[\\s]',\" \",abstract)\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Juan Ramos  Department of Computer Science, Rutgers University, 23515 BPO Way, Piscataway, NJ, 08855       JURAMOS@EDEN.RUTGERS.EDU '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracts section with names and email addresses only\n",
    "\n",
    "section  = re.findall (r'\\n\\n([^]]*)\\n\\n(Abstract|ABSTRACT)',document[:2000])\n",
    "\n",
    "type(section[0][0])\n",
    "\n",
    "if isinstance(section, list):\n",
    "    section = re.sub('[\\s]',\" \",section[0][0])\n",
    "else:\n",
    "    section = re.sub('[\\s]',\" \",section)\n",
    "section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = re.findall (r'\\n\\n([^]]+)\\n\\n(Abstract|ABSTRACT)',document[:2000] )\n",
    "\n",
    "if isinstance(test, str):\n",
    "    print \"Wow\"\n",
    "elif isinstance (test,int):\n",
    "    print \"I'm surprised!\"\n",
    "\n",
    "elif  isinstance (test,list):\n",
    "    print \"We got it RIGHT!\"\n",
    "\n",
    "else:\n",
    "    print \"Nothing fits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tree.collapse_unary of Tree('S', [Tree('PERSON', [('Juan', 'NNP')]), Tree('PERSON', [('Ramos', 'NNP'), ('Department', 'NNP')]), ('of', 'IN'), Tree('ORGANIZATION', [('Computer', 'NNP'), ('Science', 'NNP')]), (',', ','), Tree('ORGANIZATION', [('Rutgers', 'NNP'), ('University', 'NNP')]), (',', ','), ('23515', 'CD'), Tree('ORGANIZATION', [('BPO', 'NNP'), ('Way', 'NNP')]), (',', ','), Tree('GPE', [('Piscataway', 'NNP')]), (',', ','), Tree('ORGANIZATION', [('NJ', 'NNP')]), (',', ','), ('08855', 'CD'), Tree('ORGANIZATION', [('JURAMOS', 'NNP')]), ('@', 'NNP'), ('EDEN.RUTGERS.EDU', 'NNP')])>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to extract entities from top section of pdf and store a relationship tree\n",
    "\n",
    "import nltk\n",
    "\n",
    "tagged = nltk.pos_tag(nltk.word_tokenize(section))\n",
    "entities = nltk.chunk.ne_chunk(tagged)\n",
    "entities.collapse_unary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Juan', u'ORGANIZATION'), (u'Ramos', u'ORGANIZATION'), (u'Department', u'ORGANIZATION'), (u'of', u'ORGANIZATION'), (u'Computer', u'ORGANIZATION'), (u'Science', u'ORGANIZATION'), (u',', u'O'), (u'Rutgers', u'ORGANIZATION'), (u'University', u'ORGANIZATION'), (u',', u'O'), (u'23515', u'O'), (u'BPO', u'MISC'), (u'Way', u'MISC'), (u',', u'O'), (u'Piscataway', u'LOCATION'), (u',', u'O'), (u'NJ', u'LOCATION'), (u',', u'O'), (u'08855', u'O'), (u'JURAMOS', u'O'), (u'@', u'O'), (u'EDEN.RUTGERS.EDU', u'O')]\n"
     ]
    }
   ],
   "source": [
    "# Use another entity extractor\n",
    "\n",
    "\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('/Users/linwood/stanford-corenlp-full-2015-04-20/classifiers/english.conll.4class.distsim.crf.ser.gz',\n",
    "\t\t\t\t\t   '/Users/linwood/stanford-corenlp-full-2015-04-20/stanford-corenlp-3.5.2.jar',\n",
    "\t\t\t\t\t   encoding='utf-8')\n",
    "\n",
    "text = section\n",
    "tokenized_text = word_tokenize(section)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "print type(ENGLISH_STOP_WORDS)\n",
    "print type(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a= [l for l in ENGLISH_STOP_WORDS]\n",
    "b = [l for l in nltk.corpus.stopwords.words('english')]\n",
    "\n",
    "len(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TFIDF processing\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(abstract) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(abstract) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates the json document format to store the files\n",
    "\n",
    "corpus = {}\n",
    "corpus[str(fileName)]={}\n",
    "corpus[str(fileName)]={'Title':title,'Abstract':abstract,'Entities':entities}\n",
    "corpus['p99.pdf']={'Title':\"Test title\",'Abstract':\"test abstract langauge.  Just adding test to make it longer\", 'Entities':\"Linwood Creekmore\"}\n",
    "\n",
    "corpus.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('/Users/linwood/stanford-corenlp-full-2015-04-20/classifiers/english.muc.7class.distsim.crf.ser.gz',\n",
    "\t\t\t\t\t   '/Users/linwood/stanford-corenlp-full-2015-04-20/stanford-ner-3.5.2.jar',\n",
    "\t\t\t\t\t   encoding='utf-8')\n",
    "\n",
    "st.tag(word_tokenize(section));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "full = re.sub('[\\s]',\" \", document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from http://brandonrose.org/clustering\n",
    "\n",
    "\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "lemmer = WordNetLemmatizer()\n",
    "wordnet_tags = ['n', 'v', 'a', 's', 'r']\n",
    "\n",
    "def tokenize_and_stem_n_lem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    lems = [lemmer.lemmatize(l) for l in filtered_tokens]\n",
    "    \n",
    "    return stems,lems\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abstracts = [i['Abstract'] for i in corpus.values()[:]]\n",
    "\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in abstracts:\n",
    "    allwords_stemmed = tokenize_and_stem_n_lem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 901 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print 'there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.8 ms, sys: 17.6 ms, total: 84.5 ms\n",
      "Wall time: 71.4 ms\n",
      "(5, 1295)\n",
      "[[  9.99200722e-16   9.97015780e-01   9.60432596e-01   9.84189594e-01\n",
      "    9.59554133e-01]\n",
      " [  9.97015780e-01  -4.44089210e-16   9.81368347e-01   9.89242031e-01\n",
      "    9.89661916e-01]\n",
      " [  9.60432596e-01   9.81368347e-01  -5.99520433e-15   9.94369123e-01\n",
      "    9.81712860e-01]\n",
      " [  9.84189594e-01   9.89242031e-01   9.94369123e-01  -1.55431223e-15\n",
      "    9.57102658e-01]\n",
      " [  9.59554133e-01   9.89661916e-01   9.81712860e-01   9.57102658e-01\n",
      "    1.88737914e-15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, tokenizer=tokenize_and_stem_n_lem, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(abstracts) #fit the vectorizer to abstracts\n",
    "\n",
    "print(tfidf_matrix.shape)\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "print dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58.4 ms, sys: 3.3 ms, total: 61.7 ms\n",
      "Wall time: 59.8 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 5\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#uncomment the below to save your model \n",
    "#since I've already run my model I am loading from the pickle\n",
    "\n",
    "joblib.dump(km,  'doc_cluster.pkl')\n",
    "\n",
    "km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests, unicodedata\n",
    "text = urllib2.urlopen('http://www.constitution.org/cons/constitu.txt')\n",
    "constitution = requests.get('http://www.constitution.org/cons/constitu.txt')\n",
    "\n",
    "const = unicodedata.normalize('NFKD', constitution.text).encode('ascii','ignore')\n",
    "type(const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = ' '.join(re.findall('[\\w]+',const))\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "def grey_color_func(word, font_size, position, orientation, random_state=None, **kwargs):\n",
    "    return \"hsl(0, 0%%, %d%%)\" % random.randint(60, 100)\n",
    "\n",
    "# read the mask / color image\n",
    "# taken from http://jirkavinse.deviantart.com/art/quot-Real-Life-quot-Alice-282261010\n",
    "from PIL import Image\n",
    "import requests\n",
    "from StringIO import StringIO\n",
    "\n",
    "response = requests.get(\"http://www.personal.psu.edu/sdh5174/Mario_png.png\")\n",
    "\n",
    "mario_coloring = np.array(Image.open(StringIO(response.content)))\n",
    "\n",
    "wc = WordCloud(background_color=\"white\", max_words=2000, mask=mario_coloring,\n",
    "               stopwords=STOPWORDS.add(\"said\"),\n",
    "               max_font_size=40, random_state=42)\n",
    "# generate word cloud\n",
    "wc.generate(text)\n",
    "\n",
    "# create coloring from image\n",
    "image_colors = ImageColorGenerator(mario_coloring)\n",
    "\n",
    "# show\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "# recolor wordcloud and show\n",
    "# we could also give color_func=image_colors directly in the constructor\n",
    "plt.imshow(wc.recolor(color_func=image_colors))\n",
    "plt.axis(\"off\")\n",
    "plt.figure()\n",
    "plt.imshow(mario_coloring, cmap=plt.cm.gray)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.datasets import cancer\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sm.datasets.get_rdataset(\"Duncan\", \"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print data.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "air = sm.datasets.get_rdataset(\"airquality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(air.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "air.data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
